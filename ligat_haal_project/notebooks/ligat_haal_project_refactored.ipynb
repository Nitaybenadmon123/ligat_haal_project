{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3690f037",
   "metadata": {},
   "source": [
    "# Ligat Ha'al Results & Playoffs Core Notebook\n",
    "\n",
    "**Purpose:** Unified, reproducible scraping + normalization + competitive balance / leadership analysis.\n",
    "\n",
    "\n",
    "\n",
    "**Data Sources:**\n",
    "\n",
    "- Transfermarkt (regular season + playoffs via match reports)\n",
    "\n",
    "- Wikipedia (legacy reference only; not authoritative for playoffs)\n",
    "\n",
    "- Attendance scraping lives in dedicated attendance notebook (see `notebooks/attendance.ipynb`).\n",
    "\n",
    "\n",
    "\n",
    "**Quick Workflow:**\n",
    "\n",
    "1. Run Environment & Helpers (cells below).\n",
    "\n",
    "2. Run Team Name Map / normalization.\n",
    "\n",
    "3. Run Regular Season Scraper (skip-existing unless overwrite flag enabled).\n",
    "\n",
    "4. Run Playoff Scraper (already optimized & skip-existing).\n",
    "\n",
    "5. Merge + Leadership / Competitive Balance Analysis.\n",
    "\n",
    "\n",
    "\n",
    "**Overwrite Flags:**\n",
    "\n",
    "- `OVERWRITE_REGULAR` = False (change to True to re-scrape regular season)\n",
    "\n",
    "- `OVERWRITE_PLAYOFFS` = False (change to True to re-scrape playoffs)\n",
    "\n",
    "\n",
    "\n",
    "**Where to Get Attendance:** Use the attendance notebook; this file only references attendance outputs if already present.\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e5e951",
   "metadata": {},
   "source": [
    "## Installation (Optional)\n",
    "\n",
    "Run this cell only if you need to install dependencies in your notebook environment. \n",
    "\n",
    "**Recommended**: Use a virtual environment and install from `requirements.txt`:\n",
    "```bash\n",
    "pip install -r ../requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3205b0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Environment setup complete\n",
      "   ROOT: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\n",
      "   DATA_DIR: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\n"
     ]
    }
   ],
   "source": [
    "# Environment setup (API-Sports removed)\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    DOTENV_AVAILABLE = True\n",
    "except Exception:\n",
    "    DOTENV_AVAILABLE = False\n",
    "\n",
    "# Feature flags (only Wikipedia + Transfermarkt pipeline)\n",
    "USE_APISPORTS = False  # deprecated; kept for compatibility but not used\n",
    "\n",
    "# Helper to find project root\n",
    "def _find_root(start: Optional[Path] = None) -> Path:\n",
    "    p = start or Path.cwd()\n",
    "    for _ in range(6):\n",
    "        if (p / 'data').exists() or (p / '.git').exists() or (p / 'notebooks').exists():\n",
    "            return p\n",
    "        p = p.parent\n",
    "    return Path.cwd()\n",
    "\n",
    "# Resolve project directories consistently\n",
    "ROOT = _find_root()\n",
    "DATA_DIR = ROOT / 'data' / 'raw'\n",
    "INTERIM_DIR = ROOT / 'data' / 'interim'\n",
    "PROCESSED_DIR = ROOT / 'data' / 'processed'\n",
    "FIG_DIR = ROOT / 'reports' / 'figures'\n",
    "for d in [DATA_DIR, INTERIM_DIR, PROCESSED_DIR, FIG_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"\\nüéØ Environment setup complete\")\n",
    "print(f\"   ROOT: {ROOT}\")\n",
    "print(f\"   DATA_DIR: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd05ac3f",
   "metadata": {},
   "source": [
    "### Environment & Configuration\n",
    "- This project now relies only on Wikipedia and Transfermarkt.\n",
    "- All API-Sports related configuration and code has been removed to simplify the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50cbcf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\.venv\\Lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Helpers to make the notebook resilient across machines (kept)\n",
    "from typing import Optional\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "_USER_AGENTS = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0 Safari/537.36\",\n",
    "]\n",
    "\n",
    "def find_repo_root(start: Optional[Path] = None) -> Path:\n",
    "    p = start or Path.cwd()\n",
    "    for _ in range(6):\n",
    "        if (p / 'data').exists() or (p / '.git').exists() or (p / 'notebooks').exists():\n",
    "            return p\n",
    "        p = p.parent\n",
    "    return Path.cwd()\n",
    "\n",
    "def ensure_environment():\n",
    "    global ROOT, DATA_DIR, INTERIM_DIR, PROCESSED_DIR, FIG_DIR\n",
    "    if 'ROOT' not in globals() or not isinstance(ROOT, Path) or not (ROOT / 'data').exists():\n",
    "        root_guess = find_repo_root(Path.cwd())\n",
    "        if not (root_guess / 'data').exists() and (root_guess.parent / 'data').exists():\n",
    "            root_guess = root_guess.parent\n",
    "        ROOT = root_guess\n",
    "    DATA_DIR = ROOT / 'data' / 'raw'\n",
    "    INTERIM_DIR = ROOT / 'data' / 'interim'\n",
    "    PROCESSED_DIR = ROOT / 'data' / 'processed'\n",
    "    FIG_DIR = ROOT / 'reports' / 'figures'\n",
    "    for d in [DATA_DIR, INTERIM_DIR, PROCESSED_DIR, FIG_DIR]:\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "    return ROOT, DATA_DIR, INTERIM_DIR, PROCESSED_DIR, FIG_DIR\n",
    "\n",
    "\n",
    "def http_get(url: str, headers: Optional[dict] = None, retries: int = 3, timeout: int = 30) -> str:\n",
    "    last_err = None\n",
    "    sess = requests.Session()\n",
    "    for attempt in range(1, retries + 1):\n",
    "        ua = random.choice(_USER_AGENTS)\n",
    "        hdrs = {\"User-Agent\": ua, \"Accept-Language\": \"en-US,en;q=0.9\"}\n",
    "        if headers:\n",
    "            hdrs.update(headers)\n",
    "        try:\n",
    "            resp = sess.get(url, headers=hdrs, timeout=timeout)\n",
    "            resp.raise_for_status()\n",
    "            return resp.text\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            time.sleep(0.8 * attempt)\n",
    "    raise last_err  # type: ignore\n",
    "\n",
    "\n",
    "def save_csv(df: 'pd.DataFrame', path: Path, **to_csv_kwargs):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(path, index=False, encoding=to_csv_kwargs.get('encoding', 'utf-8-sig'))\n",
    "    print(f\"Saved: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a05590c",
   "metadata": {},
   "source": [
    "## Shared Utilities (Environment + HTTP)\n",
    "\n",
    "This section documents the small, reusable helpers defined in the previous code cell. They make the notebook portable (runs the same on different machines) and robust for web scraping and file saving.\n",
    "\n",
    "### What‚Äôs included\n",
    "- Rotating User-Agents list (`_USER_AGENTS`)\n",
    "  - Cycles between several realistic browser strings to reduce scraping blocks.\n",
    "- `find_repo_root(start: Optional[Path] = None) -> Path`\n",
    "- `ensure_environment() -> tuple[Path, Path, Path, Path, Path]`\n",
    "- `http_get(url: str, headers: Optional[dict] = None, retries: int = 3, timeout: int = 30) -> str`\n",
    "- `save_csv(df: pd.DataFrame, path: Path, **to_csv_kwargs) -> None`\n",
    "\n",
    "### Function reference\n",
    "\n",
    "- `find_repo_root(start: Optional[Path] = None) -> Path`\n",
    "  - Purpose: Locate the project root by walking up folders until one contains `data/`, `.git/`, or `notebooks/`.\n",
    "  - Input: Optional starting `Path` (defaults to current working directory).\n",
    "  - Returns: A `Path` pointing to the inferred project root (falls back to CWD if nothing is found within ~6 levels).\n",
    "  - Notes: Helps when the notebook is launched from different folders/IDE contexts.\n",
    "\n",
    "- `ensure_environment()`\n",
    "  - Purpose: Initialize and expose core directories as globals so paths work anywhere.\n",
    "  - Creates/sets globals: \n",
    "    - `ROOT` (project root)\n",
    "    - `DATA_DIR` (raw) ‚Üí `ROOT/data/raw`\n",
    "    - `INTERIM_DIR` ‚Üí `ROOT/data/interim`\n",
    "    - `PROCESSED_DIR` ‚Üí `ROOT/data/processed`\n",
    "    - `FIG_DIR` ‚Üí `ROOT/reports/figures`\n",
    "  - Behavior: If `ROOT` is missing or wrong, it re-detects via `find_repo_root`. Ensures all folders exist.\n",
    "  - Returns: `(ROOT, DATA_DIR, INTERIM_DIR, PROCESSED_DIR, FIG_DIR)`.\n",
    "  - Idempotent: Safe to call multiple times.\n",
    "\n",
    "- `http_get(url: str, headers: Optional[dict] = None, retries: int = 3, timeout: int = 30) -> str`\n",
    "  - Purpose: Resilient HTTP GET wrapper.\n",
    "  - Behavior:\n",
    "    - Rotates a realistic `User-Agent` each attempt.\n",
    "    - Allows extra headers to be merged in (e.g., cookies, referer).\n",
    "    - Retries on failure with a small incremental backoff.\n",
    "  - Returns: `resp.text` on success.\n",
    "  - Errors: Raises the last exception after all retries fail.\n",
    "  - Use this instead of `requests.get` directly for scraping reliability.\n",
    "\n",
    "- `save_csv(df: pd.DataFrame, path: Path, **to_csv_kwargs)`\n",
    "  - Purpose: Save a DataFrame to CSV with safe defaults.\n",
    "  - Behavior: Ensures the parent folder exists; writes UTF‚Äë8 with BOM (`utf-8-sig`) by default so Excel reads Hebrew/Unicode correctly.\n",
    "  - Returns: `None` (prints a confirmation with the saved path).\n",
    "\n",
    "### Quick examples\n",
    "```python\n",
    "# 1) Initialize folders (safe to call once near the top)\n",
    "ensure_environment()\n",
    "\n",
    "# 2) Fetch HTML with retries and rotating User-Agent\n",
    "html = http_get(\"https://en.wikipedia.org/wiki/Ligat_Ha%27al\")\n",
    "\n",
    "# 3) Save any DataFrame safely (folders auto-created, encoding friendly for Excel)\n",
    "# df = pd.DataFrame({\"a\": [1,2,3]})\n",
    "# save_csv(df, INTERIM_DIR / \"example.csv\")\n",
    "```\n",
    "\n",
    "Tips:\n",
    "- If a path-related cell fails after moving the project, call `ensure_environment()` again.\n",
    "- Prefer `http_get` over raw `requests` to avoid transient scraping issues.\n",
    "- Use `save_csv` to avoid encoding surprises when opening files in Excel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d81e4d",
   "metadata": {},
   "source": [
    "## Step 2: Enrich Match Data (2016/17 Example)\n",
    "\n",
    "This cell demonstrates how to enrich raw match data with calculated metrics:\n",
    "- **Goal difference**: home_goals - away_goals\n",
    "- **Match result**: H (home win), A (away win), D (draw)\n",
    "- **Points**: 3 for win, 1 for draw, 0 for loss\n",
    "- **One-sided flag**: Matches with goal difference ‚â• 3\n",
    "\n",
    "**Input**: `data/raw/matches_2016_17_ligat_haal_wikipedia.csv`  \n",
    "**Output**: `data/interim/matches_2016_17_ligat_haal_enriched.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea1e2b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading matches from: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2016_17_ligat_haal_wikipedia.csv\n",
      "Detected Wikipedia format (separate goal columns).\n",
      "Saved enriched matches to: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\interim\\matches_2016_17_ligat_haal_enriched.csv | rows: 182\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>home_goals</th>\n",
       "      <th>away_goals</th>\n",
       "      <th>goal_diff</th>\n",
       "      <th>result</th>\n",
       "      <th>home_points</th>\n",
       "      <th>away_points</th>\n",
       "      <th>one_sided</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016/17</td>\n",
       "      <td>F.C. Ashdod</td>\n",
       "      <td>BEI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016/17</td>\n",
       "      <td>F.C. Ashdod</td>\n",
       "      <td>BnS</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016/17</td>\n",
       "      <td>F.C. Ashdod</td>\n",
       "      <td>BnY</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016/17</td>\n",
       "      <td>F.C. Ashdod</td>\n",
       "      <td>HAS</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016/17</td>\n",
       "      <td>F.C. Ashdod</td>\n",
       "      <td>HBS</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016/17</td>\n",
       "      <td>F.C. Ashdod</td>\n",
       "      <td>HHA</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-2</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016/17</td>\n",
       "      <td>F.C. Ashdod</td>\n",
       "      <td>HKS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016/17</td>\n",
       "      <td>F.C. Ashdod</td>\n",
       "      <td>HRA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016/17</td>\n",
       "      <td>F.C. Ashdod</td>\n",
       "      <td>HTA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016/17</td>\n",
       "      <td>F.C. Ashdod</td>\n",
       "      <td>IKS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    season    home_team away_team  home_goals  away_goals  goal_diff result  \\\n",
       "0  2016/17  F.C. Ashdod       BEI           0           0          0      D   \n",
       "1  2016/17  F.C. Ashdod       BnS           1           1          0      D   \n",
       "2  2016/17  F.C. Ashdod       BnY           2           2          0      D   \n",
       "3  2016/17  F.C. Ashdod       HAS           1           0          1      H   \n",
       "4  2016/17  F.C. Ashdod       HBS           0           1         -1      A   \n",
       "5  2016/17  F.C. Ashdod       HHA           1           3         -2      A   \n",
       "6  2016/17  F.C. Ashdod       HKS           0           0          0      D   \n",
       "7  2016/17  F.C. Ashdod       HRA           0           1         -1      A   \n",
       "8  2016/17  F.C. Ashdod       HTA           1           0          1      H   \n",
       "9  2016/17  F.C. Ashdod       IKS           0           0          0      D   \n",
       "\n",
       "   home_points  away_points  one_sided  \n",
       "0            1            1          0  \n",
       "1            1            1          0  \n",
       "2            1            1          0  \n",
       "3            3            0          0  \n",
       "4            0            3          0  \n",
       "5            0            3          0  \n",
       "6            1            1          0  \n",
       "7            0            3          0  \n",
       "8            3            0          0  \n",
       "9            1            1          0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ...existing code...\n",
    "# Enrich Wikipedia match-by-match table (robust detection + optional auto-scrape)\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# Ensure environment and paths are set\n",
    "ensure_environment()\n",
    "\n",
    "# Output path\n",
    "out_path = INTERIM_DIR / \"matches_2016_17_ligat_haal_enriched.csv\"\n",
    "\n",
    "# Preferred input filename\n",
    "preferred = DATA_DIR / \"matches_2016_17_ligat_haal_wikipedia.csv\"\n",
    "matches_csv = None\n",
    "\n",
    "if preferred.exists():\n",
    "    matches_csv = preferred\n",
    "else:\n",
    "    # Search for likely candidates in data/raw (and recursively as fallback)\n",
    "    candidates = []\n",
    "    candidates += list(DATA_DIR.glob(\"matches_2016*.csv\"))\n",
    "    candidates += list(DATA_DIR.glob(\"matches_*2016*.csv\"))\n",
    "    candidates += list(DATA_DIR.glob(\"matches_*ligat*2016*.csv\"))\n",
    "    candidates += list(DATA_DIR.glob(\"matches_all_seasons*.csv\"))\n",
    "    candidates += list(DATA_DIR.rglob(\"matches*.csv\"))\n",
    "\n",
    "    # Deduplicate and prefer files that contain 2016/2017 or all_seasons\n",
    "    seen = {}\n",
    "    for p in candidates:\n",
    "        try:\n",
    "            seen[p.resolve()] = p\n",
    "        except Exception:\n",
    "            seen[p] = p\n",
    "    candidates = list(seen.values())\n",
    "\n",
    "    def score(p: Path):\n",
    "        name = p.name.lower()\n",
    "        s = 10\n",
    "        if \"2016\" in name and \"2017\" in name: s -= 6\n",
    "        if \"2016\" in name and \"17\" in name: s -= 5\n",
    "        if \"2016\" in name: s -= 4\n",
    "        if \"all_seasons\" in name: s -= 3\n",
    "        if \"ligat\" in name: s -= 1\n",
    "        return (s, len(name), str(p))\n",
    "\n",
    "    candidates = sorted(candidates, key=score)\n",
    "\n",
    "    if candidates:\n",
    "        matches_csv = candidates[0]\n",
    "        print(f\"Detected matches CSV: {matches_csv}\")\n",
    "    else:\n",
    "        # Attempt to auto-scrape 2016/17 from Wikipedia as a last resort\n",
    "        print(f\"Matches CSV not found in {DATA_DIR}. Attempting to scrape 2016/17 from Wikipedia...\")\n",
    "        try:\n",
    "            from bs4 import BeautifulSoup\n",
    "            url = \"https://en.wikipedia.org/wiki/2016%E2%80%9317_Israeli_Premier_League\"\n",
    "            html = http_get(url)\n",
    "            soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "\n",
    "            results_table = None\n",
    "            for table in soup.find_all(\"table\", class_=\"wikitable\"):\n",
    "                first_row = table.find(\"tr\")\n",
    "                if first_row:\n",
    "                    first_cell = first_row.find(\"th\")\n",
    "                    if first_cell and (\"Home \\\\ Away\" in first_cell.text or \"Home / Away\" in first_cell.text):\n",
    "                        results_table = table\n",
    "                        break\n",
    "            if not results_table:\n",
    "                raise RuntimeError(\"Could not find results matrix table on Wikipedia page.\")\n",
    "\n",
    "            rows = results_table.find_all(\"tr\")\n",
    "            team_names = [td.get_text(strip=True) for td in rows[0].find_all(\"th\")][1:]\n",
    "\n",
    "            matches = []\n",
    "            for row in rows[1:]:\n",
    "                cells = row.find_all([\"th\", \"td\"])\n",
    "                home_team = cells[0].get_text(strip=True)\n",
    "                for j, cell in enumerate(cells[1:]):\n",
    "                    away_team = team_names[j]\n",
    "                    score = cell.get_text(strip=True)\n",
    "                    if re.match(r\"^\\d+\\s*[‚Äì-]\\s*\\d+$\", score):\n",
    "                        home_goals, away_goals = re.split(r\"[‚Äì-]\", score)\n",
    "                        matches.append({\n",
    "                            \"season\": \"2016/17\",\n",
    "                            \"home_team\": home_team,\n",
    "                            \"away_team\": away_team,\n",
    "                            \"home_goals\": int(home_goals.strip()),\n",
    "                            \"away_goals\": int(away_goals.strip())\n",
    "                        })\n",
    "\n",
    "            if not matches:\n",
    "                raise RuntimeError(\"No matches parsed from Wikipedia.\")\n",
    "\n",
    "            df_autoscrape = pd.DataFrame(matches, columns=[\n",
    "                \"season\", \"home_team\", \"away_team\", \"home_goals\", \"away_goals\"\n",
    "            ])\n",
    "            save_csv(df_autoscrape, DATA_DIR / \"matches_2016_17_ligat_haal_wikipedia.csv\")\n",
    "            matches_csv = DATA_DIR / \"matches_2016_17_ligat_haal_wikipedia.csv\"\n",
    "            print(\"‚úÖ Created matches CSV via auto-scrape.\")\n",
    "        except Exception as e:\n",
    "            raise FileNotFoundError(\n",
    "                f\"Matches CSV not found and auto-scrape failed: {e}\\n\"\n",
    "                f\"Tried to create: {DATA_DIR / 'matches_2016_17_ligat_haal_wikipedia.csv'}\\n\"\n",
    "                \"Run the scraping cells manually or place the CSV in data/raw/.\"\n",
    "            ) from e\n",
    "\n",
    "# Load dataframe\n",
    "print(f\"Loading matches from: {matches_csv}\")\n",
    "df = pd.read_csv(matches_csv)\n",
    "\n",
    "# Handle different CSV formats\n",
    "if \"score\" in df.columns and \"home_goals\" not in df.columns:\n",
    "    # Transfermarkt format: score column with \"X:Y\" format\n",
    "    print(\"Detected Transfermarkt format (score column). Splitting into home_goals/away_goals...\")\n",
    "    df[[\"home_goals\", \"away_goals\"]] = df[\"score\"].str.split(\":\", expand=True)\n",
    "    df[\"home_goals\"] = pd.to_numeric(df[\"home_goals\"], errors=\"coerce\")\n",
    "    df[\"away_goals\"] = pd.to_numeric(df[\"away_goals\"], errors=\"coerce\")\n",
    "else:\n",
    "    # Wikipedia format: separate home_goals and away_goals columns\n",
    "    print(\"Detected Wikipedia format (separate goal columns).\")\n",
    "    for col in [\"home_goals\", \"away_goals\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "# Derived columns\n",
    "df[\"goal_diff\"] = df[\"home_goals\"] - df[\"away_goals\"]\n",
    "df[\"result\"] = df[\"goal_diff\"].apply(lambda x: \"H\" if x > 0 else (\"A\" if x < 0 else \"D\"))\n",
    "df[\"home_points\"] = df[\"result\"].map({\"H\": 3, \"D\": 1, \"A\": 0})\n",
    "df[\"away_points\"] = df[\"result\"].map({\"A\": 3, \"D\": 1, \"H\": 0})\n",
    "\n",
    "# Optional: simple flag for one-sided results\n",
    "df[\"one_sided\"] = (df[\"goal_diff\"].abs() >= 3).astype(int)\n",
    "\n",
    "# Reorder/keep columns defensively\n",
    "cols = [\n",
    "    \"season\", \"home_team\", \"away_team\",\n",
    "    \"home_goals\", \"away_goals\", \"goal_diff\", \"result\",\n",
    "    \"home_points\", \"away_points\", \"one_sided\"\n",
    "]\n",
    "ordered = [c for c in cols if c in df.columns]\n",
    "df = df[ordered]\n",
    "\n",
    "# Save enriched file\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "df.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"Saved enriched matches to: {out_path} | rows: {len(df)}\")\n",
    "display(df.head(10))\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1d9a9c",
   "metadata": {},
   "source": [
    "## Step 3: Advanced Enrichment (2022/23 Example)\n",
    "\n",
    "This cell shows a more comprehensive enrichment process with:\n",
    "- **Phase parsing**: Extract \"regular\", \"championship\", or \"relegation\" from round names\n",
    "- **Round number**: Extract numeric round from strings like \"Regular Season - 1\"\n",
    "- **Goal difference, results, points**: Same as Step 2\n",
    "- **One-sided matches**: Flag matches with |goal_diff| ‚â• 3\n",
    "- **Column cleanup**: Remove irrelevant API-specific columns\n",
    "\n",
    "**Input**: `data/raw/matches_2022_23_ligat_haal.csv` (if using API-Sports)  \n",
    "**Output**: `data/interim/matches_2022_23_enriched.csv`\n",
    "\n",
    "**Note**: This cell is for API-Sports data. For Wikipedia data, use the simpler enrichment in Step 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d374146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Ñπ Skipping 2022/23 enrichment - input file not found: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2022_23_ligat_haal.csv\n",
      "  This cell is for API-Sports data. If you're using Wikipedia data,\n",
      "  your enriched file is already created by the enrichment cell above.\n"
     ]
    }
   ],
   "source": [
    "# === ◊î◊¢◊©◊®◊™ ◊î◊ò◊ë◊ú◊î + ◊†◊ô◊ß◊ï◊ô ◊¢◊û◊ï◊ì◊ï◊™ ◊û◊ô◊ï◊™◊®◊ï◊™ ===\n",
    "# Note: This cell is for API-Sports data (2022/23). \n",
    "# If you're using Wikipedia data, skip this cell and use the enrichment cell above instead.\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure environment is set up\n",
    "ensure_environment()\n",
    "\n",
    "in_path  = DATA_DIR / \"matches_2022_23_ligat_haal.csv\"   # ◊©◊†◊î ◊ú◊ß◊ï◊ë◊• ◊©◊ú◊ö\n",
    "out_path = INTERIM_DIR / \"matches_2022_23_enriched.csv\"\n",
    "\n",
    "# Check if file exists before attempting to process\n",
    "if not in_path.exists():\n",
    "    print(f\"‚Ñπ Skipping 2022/23 enrichment - input file not found: {in_path}\")\n",
    "    print(f\"  This cell is for API-Sports data. If you're using Wikipedia data,\")\n",
    "    print(f\"  your enriched file is already created by the enrichment cell above.\")\n",
    "else:\n",
    "    df = pd.read_csv(in_path)\n",
    "\n",
    "    # --- ◊¢◊û◊ï◊ì◊ï◊™ ◊¢◊ñ◊® ---\n",
    "    # 1) ◊©◊†◊î ◊û◊°◊§◊®◊ô◊™ ◊ú◊§◊™◊ô◊ó◊™ ◊î◊¢◊ï◊†◊î\n",
    "    #df[\"season_year\"] = df[\"season\"].str.slice(0,4).astype(int)\n",
    "\n",
    "    # 2) ◊û◊°◊§◊® ◊û◊ó◊ñ◊ï◊® ◊ï-phase\n",
    "    def parse_round(r):\n",
    "        # ◊ì◊ï◊í◊û◊ê◊ï◊™: \"Regular Season - 1\", \"Championship Round - 5\"\n",
    "        if pd.isna(r):\n",
    "            return (None, None)\n",
    "        r = str(r)\n",
    "        m = re.search(r\"(Regular|Championship|Relegation).*?(\\d+)\", r, flags=re.I)\n",
    "        phase = None\n",
    "        if \"regular\" in r.lower():      phase = \"regular\"\n",
    "        elif \"championship\" in r.lower(): phase = \"championship\"\n",
    "        elif \"relegation\" in r.lower():   phase = \"relegation\"\n",
    "        round_num = int(m.group(2)) if m else None\n",
    "        return (phase, round_num)\n",
    "\n",
    "    tmp = df[\"round\"].apply(parse_round).tolist()\n",
    "    df[\"phase\"] = [t[0] for t in tmp]\n",
    "    df[\"round_num\"] = [t[1] for t in tmp]\n",
    "\n",
    "    # 3) ◊î◊§◊®◊© ◊©◊¢◊®◊ô◊ù, ◊™◊ï◊¶◊ê◊î, ◊†◊ß◊ï◊ì◊ï◊™\n",
    "    df[\"goal_diff\"] = df[\"home_goals\"] - df[\"away_goals\"]\n",
    "    df[\"result\"] = df[\"goal_diff\"].apply(lambda x: \"H\" if x>0 else (\"A\" if x<0 else \"D\"))\n",
    "    df[\"home_points\"] = df[\"result\"].map({\"H\":3, \"D\":1, \"A\":0})\n",
    "    df[\"away_points\"] = df[\"result\"].map({\"H\":0, \"D\":1, \"A\":3})\n",
    "\n",
    "    # 4) ◊ì◊í◊ú ◊û◊©◊ó◊ß ◊ó◊ì-◊¶◊ì◊ì◊ô (◊ú◊û◊©◊ú |GD|>=3)\n",
    "    df[\"one_sided\"] = (df[\"goal_diff\"].abs() >= 3).astype(int)\n",
    "\n",
    "    # 5) ◊¢◊û◊ï◊ì◊ï◊™ ◊ú◊ê ◊®◊ú◊ï◊ï◊†◊ò◊ô◊ï◊™ ◊ú◊î◊°◊®◊î (◊õ◊§◊ô ◊©◊ë◊ô◊ß◊©◊™)\n",
    "    drop_cols = [\"league_id\",\"league_name\",\"fixture_id\"]\n",
    "    df = df.drop(columns=[c for c in drop_cols if c in df.columns])\n",
    "\n",
    "    # 6) ◊°◊ì◊® ◊¢◊û◊ï◊ì◊ï◊™ ◊†◊ï◊ó\n",
    "    cols = [\n",
    "        \"season\",\"season_year\",\"date\",\"phase\",\"round_num\",\"stage\",\n",
    "        \"home_team\",\"away_team\",\"home_goals\",\"away_goals\",\"goal_diff\",\"result\",\n",
    "        \"home_points\",\"away_points\",\"one_sided\",\"venue\",\"referee\"\n",
    "    ]\n",
    "    df = df[[c for c in cols if c in df.columns]]\n",
    "\n",
    "    save_csv(df, out_path)\n",
    "    print(\"◊†◊©◊û◊®:\", out_path, \"| ◊©◊ï◊®◊ï◊™:\", len(df))\n",
    "    display(df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6fc47c",
   "metadata": {},
   "source": [
    "## Step 4: Scrape League Table from Wikipedia (2016/17)\n",
    "\n",
    "This cell demonstrates how to fetch a league standings table from Wikipedia using pandas' `read_html()`.\n",
    "\n",
    "**What it does**:\n",
    "- Fetches the 2016/17 Israeli Premier League Wikipedia page\n",
    "- Uses `read_html()` to automatically parse HTML tables\n",
    "- Identifies the league table by looking for typical columns (Team, Points, etc.)\n",
    "- Saves the standings to CSV\n",
    "\n",
    "**Output**: `data/raw/ligat_haal_2016_17_wikipedia.csv`\n",
    "\n",
    "**Note**: This gives you final standings, not match-by-match data. For match data, see the next cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a3f4c4",
   "metadata": {},
   "source": [
    "## Step 5: Scrape Match-by-Match Results from Wikipedia (2016/17)\n",
    "\n",
    "This cell extracts individual match results from Wikipedia's results matrix table.\n",
    "\n",
    "**How it works**:\n",
    "1. Fetches the Wikipedia page for 2016/17 season\n",
    "2. Finds the results matrix table (grid showing Home vs Away results)\n",
    "3. Parses each cell to extract scores (e.g., \"2‚Äì1\")\n",
    "4. Creates one row per match with home/away teams and goals\n",
    "5. Calculates derived metrics (goal_diff, result, points)\n",
    "\n",
    "**Output**: `data/raw/matches_2016_17_ligat_haal_wikipedia.csv`\n",
    "\n",
    "**Derived columns**:\n",
    "- `goal_diff`: home_goals - away_goals\n",
    "- `result`: H (home win), A (away win), D (draw)\n",
    "- `home_points` / `away_points`: 3 for win, 1 for draw, 0 for loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bc144b",
   "metadata": {},
   "source": [
    "## Step 6: Multi-Season Wikipedia Scraper (Last 20 Seasons)\n",
    "\n",
    "This cell automates the match scraping process across multiple seasons.\n",
    "\n",
    "**What it does**:\n",
    "1. Calculates the last 20 seasons dynamically (based on current date)\n",
    "2. For each season:\n",
    "   - Fetches the Wikipedia page\n",
    "   - Extracts the results matrix\n",
    "   - Parses match-by-match data\n",
    "   - Saves individual season CSV\n",
    "3. Combines all seasons into one master file\n",
    "\n",
    "**Outputs**:\n",
    "- Per-season: `data/raw/matches_YYYY_YY_ligat_haal_wikipedia.csv`\n",
    "- Combined: `data/raw/matches_all_seasons_ligat_haal_wikipedia.csv`\n",
    "\n",
    "**Features**:\n",
    "- Polite scraping with 1-second delays between requests\n",
    "- Error handling for missing/changed pages\n",
    "- Progress tracking with ‚úì/‚ùå indicators\n",
    "- Season summary report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c089fed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping 20 seasons from Wikipedia (2006/07 to 2025/26)...\n",
      "Fetching 2006/07... ‚úì (132 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2006_07_ligat_haal_wikipedia.csv\n",
      "Fetching 2007/08... ‚úì (132 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2007_08_ligat_haal_wikipedia.csv\n",
      "Fetching 2008/09... ‚úì (132 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2008_09_ligat_haal_wikipedia.csv\n",
      "Fetching 2009/10... ‚úì (239 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2009_10_ligat_haal_wikipedia.csv\n",
      "Fetching 2010/11... ‚úì (234 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2010_11_ligat_haal_wikipedia.csv\n",
      "Fetching 2011/12... ‚úì (240 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2011_12_ligat_haal_wikipedia.csv\n",
      "Fetching 2012/13... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2012_13_ligat_haal_wikipedia.csv\n",
      "Fetching 2013/14... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2013_14_ligat_haal_wikipedia.csv\n",
      "Fetching 2014/15... ‚úì (181 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2014_15_ligat_haal_wikipedia.csv\n",
      "Fetching 2015/16... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2015_16_ligat_haal_wikipedia.csv\n",
      "Fetching 2016/17... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2016_17_ligat_haal_wikipedia.csv\n",
      "Fetching 2017/18... ‚úì (181 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2017_18_ligat_haal_wikipedia.csv\n",
      "Fetching 2018/19... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2018_19_ligat_haal_wikipedia.csv\n",
      "Fetching 2019/20... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2019_20_ligat_haal_wikipedia.csv\n",
      "Fetching 2020/21... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2020_21_ligat_haal_wikipedia.csv\n",
      "Fetching 2021/22... ‚úì (181 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2021_22_ligat_haal_wikipedia.csv\n",
      "Fetching 2022/23... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2022_23_ligat_haal_wikipedia.csv\n",
      "Fetching 2023/24... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2023_24_ligat_haal_wikipedia.csv\n",
      "Fetching 2024/25... ‚úì (179 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2024_25_ligat_haal_wikipedia.csv\n",
      "Fetching 2025/26... ‚úì (64 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2025_26_ligat_haal_wikipedia.csv\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_all_seasons_ligat_haal_wikipedia.csv\n",
      "\n",
      "Summary:\n",
      "- Successfully scraped 20 seasons\n",
      "- Total matches: 3533\n",
      "\n",
      "Matches per season:\n",
      "  ‚Ä¢ 2006/07: 132 matches\n",
      "  ‚Ä¢ 2007/08: 132 matches\n",
      "  ‚Ä¢ 2008/09: 132 matches\n",
      "  ‚Ä¢ 2009/10: 239 matches\n",
      "  ‚Ä¢ 2010/11: 234 matches\n",
      "  ‚Ä¢ 2011/12: 240 matches\n",
      "  ‚Ä¢ 2012/13: 182 matches\n",
      "  ‚Ä¢ 2013/14: 182 matches\n",
      "  ‚Ä¢ 2014/15: 181 matches\n",
      "  ‚Ä¢ 2015/16: 182 matches\n",
      "  ‚Ä¢ 2016/17: 182 matches\n",
      "  ‚Ä¢ 2017/18: 181 matches\n",
      "  ‚Ä¢ 2018/19: 182 matches\n",
      "  ‚Ä¢ 2019/20: 182 matches\n",
      "  ‚Ä¢ 2020/21: 182 matches\n",
      "  ‚Ä¢ 2021/22: 181 matches\n",
      "  ‚Ä¢ 2022/23: 182 matches\n",
      "  ‚Ä¢ 2023/24: 182 matches\n",
      "  ‚Ä¢ 2024/25: 179 matches\n",
      "  ‚Ä¢ 2025/26:  64 matches\n",
      "\n",
      "All matches saved to: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_all_seasons_ligat_haal_wikipedia.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>season_year</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>home_goals</th>\n",
       "      <th>away_goals</th>\n",
       "      <th>goal_diff</th>\n",
       "      <th>result</th>\n",
       "      <th>home_points</th>\n",
       "      <th>away_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>2006</td>\n",
       "      <td>Beitar Jerusalem</td>\n",
       "      <td>BnY</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>2006</td>\n",
       "      <td>Beitar Jerusalem</td>\n",
       "      <td>ASH</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>H</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>2006</td>\n",
       "      <td>Beitar Jerusalem</td>\n",
       "      <td>HAK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>2006</td>\n",
       "      <td>Beitar Jerusalem</td>\n",
       "      <td>HKS</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>H</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>2006</td>\n",
       "      <td>Beitar Jerusalem</td>\n",
       "      <td>HPT</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>H</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    season  season_year         home_team away_team  home_goals  away_goals  \\\n",
       "0  2006/07         2006  Beitar Jerusalem       BnY           0           0   \n",
       "1  2006/07         2006  Beitar Jerusalem       ASH           2           0   \n",
       "2  2006/07         2006  Beitar Jerusalem       HAK           0           0   \n",
       "3  2006/07         2006  Beitar Jerusalem       HKS           2           0   \n",
       "4  2006/07         2006  Beitar Jerusalem       HPT           2           0   \n",
       "\n",
       "   goal_diff result  home_points  away_points  \n",
       "0          0      D            1            1  \n",
       "1          2      H            3            0  \n",
       "2          0      D            1            1  \n",
       "3          2      H            3            0  \n",
       "4          2      H            3            0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scrape multiple seasons of Ligat Ha'al from Wikipedia\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "ensure_environment()\n",
    "\n",
    "def scrape_season(season_year):\n",
    "    \"\"\"\n",
    "    Scrape a single season's matches from Wikipedia.\n",
    "    season_year: starting year (e.g., 2016 for 2016/17 season)\n",
    "    \"\"\"\n",
    "    season_str = f\"{season_year}/{str(season_year+1)[-2:]}\"\n",
    "    url = f\"https://en.wikipedia.org/wiki/{season_year}%E2%80%93{str(season_year+1)[-2:]}_Israeli_Premier_League\"\n",
    "    \n",
    "    print(f\"Fetching {season_str}... \", end=\"\", flush=True)\n",
    "    try:\n",
    "        html = http_get(url)\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "        \n",
    "        # Find results matrix\n",
    "        results_table = None\n",
    "        for table in soup.find_all(\"table\", class_=\"wikitable\"):\n",
    "            first_row = table.find(\"tr\")\n",
    "            if first_row:\n",
    "                first_cell = first_row.find(\"th\")\n",
    "                if first_cell and (\"Home \\\\ Away\" in first_cell.text or \"Home / Away\" in first_cell.text):\n",
    "                    results_table = table\n",
    "                    break\n",
    "        \n",
    "        if not results_table:\n",
    "            print(\"‚ùå (no results matrix)\")\n",
    "            return None\n",
    "            \n",
    "        # Parse teams and build matches\n",
    "        rows = results_table.find_all(\"tr\")\n",
    "        team_names = [td.get_text(strip=True) for td in rows[0].find_all(\"th\")][1:]\n",
    "        \n",
    "        matches = []\n",
    "        for i, row in enumerate(rows[1:]):\n",
    "            cells = row.find_all([\"th\", \"td\"])\n",
    "            home_team = cells[0].get_text(strip=True)\n",
    "            for j, cell in enumerate(cells[1:]):\n",
    "                away_team = team_names[j]\n",
    "                score = cell.get_text(strip=True)\n",
    "                if re.match(r\"^\\d+\\s*[‚Äì-]\\s*\\d+$\", score):\n",
    "                    home_goals, away_goals = re.split(r\"[‚Äì-]\", score)\n",
    "                    matches.append({\n",
    "                        \"season\": season_str,\n",
    "                        \"season_year\": season_year,\n",
    "                        \"home_team\": home_team,\n",
    "                        \"away_team\": away_team,\n",
    "                        \"home_goals\": int(home_goals.strip()),\n",
    "                        \"away_goals\": int(away_goals.strip())\n",
    "                    })\n",
    "        \n",
    "        if not matches:\n",
    "            print(\"‚ùå (no matches found)\")\n",
    "            return None\n",
    "            \n",
    "        # Convert to DataFrame and add derived columns\n",
    "        df = pd.DataFrame(matches)\n",
    "        df['goal_diff'] = df['home_goals'] - df['away_goals']\n",
    "        df['result'] = df['goal_diff'].apply(lambda x: \"H\" if x>0 else (\"A\" if x<0 else \"D\"))\n",
    "        df['home_points'] = df['result'].map({\"H\":3, \"D\":1, \"A\":0}).fillna(0).astype(int)\n",
    "        df['away_points'] = df['result'].map({\"A\":3, \"D\":1, \"H\":0}).fillna(0).astype(int)\n",
    "        \n",
    "        # Select and order columns\n",
    "        keep_cols = ['season', 'season_year', 'home_team', 'away_team', 'home_goals', \n",
    "                     'away_goals', 'goal_diff', 'result', 'home_points', 'away_points']\n",
    "        df = df[keep_cols]\n",
    "        \n",
    "        print(f\"‚úì ({len(df)} matches)\")\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ({str(e)[:50]}...)\")\n",
    "        return None\n",
    "\n",
    "# List of seasons to scrape (last 20 seasons)\n",
    "current_year = datetime.now().year\n",
    "if datetime.now().month < 8:  # If before August, last season started in previous year\n",
    "    current_year -= 1\n",
    "seasons = list(range(current_year - 19, current_year + 1))\n",
    "\n",
    "print(f\"Scraping {len(seasons)} seasons from Wikipedia ({seasons[0]}/{str(seasons[0]+1)[-2:]} to {seasons[-1]}/{str(seasons[-1]+1)[-2:]})...\")\n",
    "\n",
    "# Scrape each season\n",
    "all_matches = []\n",
    "for season_year in seasons:\n",
    "    df = scrape_season(season_year)\n",
    "    if df is not None:\n",
    "        # Save individual season\n",
    "        season_path = DATA_DIR / f\"matches_{season_year}_{str(season_year+1)[-2:]}_ligat_haal_wikipedia.csv\"\n",
    "        save_csv(df, season_path)\n",
    "        all_matches.append(df)\n",
    "    time.sleep(1)  # Be nice to Wikipedia\n",
    "\n",
    "if all_matches:\n",
    "    # Combine all seasons\n",
    "    combined_df = pd.concat(all_matches, ignore_index=True)\n",
    "    combined_path = DATA_DIR / \"matches_all_seasons_ligat_haal_wikipedia.csv\"\n",
    "    save_csv(combined_df, combined_path)\n",
    "    \n",
    "    print(\"\\nSummary:\")\n",
    "    print(f\"- Successfully scraped {len(all_matches)} seasons\")\n",
    "    print(f\"- Total matches: {len(combined_df)}\")\n",
    "    print(f\"\\nMatches per season:\")\n",
    "    season_counts = combined_df.groupby('season').size().sort_index()\n",
    "    for season, count in season_counts.items():\n",
    "        print(f\"  ‚Ä¢ {season}: {count:3d} matches\")\n",
    "    print(f\"\\nAll matches saved to: {combined_path}\")\n",
    "    display(combined_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0f45cf",
   "metadata": {},
   "source": [
    "## Step 7: Scrape Attendance Data from Transfermarkt (Single Season)\n",
    "\n",
    "This cell demonstrates scraping **actual attendance statistics** from Transfermarkt.\n",
    "\n",
    "**Why Transfermarkt?**\n",
    "- Wikipedia only shows stadium capacity (max seats), not actual attendance\n",
    "- Transfermarkt provides real match attendance data aggregated by team per season\n",
    "\n",
    "**Data collected per team**:\n",
    "- `team`: Club name\n",
    "- `average_attendance`: Average fans per home match\n",
    "- `total_attendance`: Total fans across all home matches\n",
    "- `stadium_capacity`: Maximum stadium capacity\n",
    "- `utilization_pct`: Calculated as (average / capacity √ó 100)\n",
    "\n",
    "**How utilization_pct is calculated**:\n",
    "Since Transfermarkt doesn't provide a percentage column, we calculate it:\n",
    "```\n",
    "utilization_pct = (average_attendance / stadium_capacity) √ó 100\n",
    "```\n",
    "\n",
    "**Example output (2016/17)**:\n",
    "- Hapoel Beer Sheva: 89.7% utilization (nearly full!)\n",
    "- Ironi Kiryat Shmona: 10.8% utilization (mostly empty)\n",
    "\n",
    "**Output**: `data/raw/attendance_YYYY_YY_ligat_haal_transfermarkt.csv`\n",
    "\n",
    "**Source**: [Transfermarkt - Ligat Ha'al Attendance](https://www.transfermarkt.com/ligat-haal/besucherzahlen/wettbewerb/ISR1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f02e2b3",
   "metadata": {},
   "source": [
    "## Step 8: Test Attendance Scraper (2023/24)\n",
    "\n",
    "Quick validation test on a recent season to ensure the scraper works correctly.\n",
    "\n",
    "**Output**: `data/raw/attendance_2023_24_ligat_haal_transfermarkt.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1a6f768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing URL: https://www.transfermarkt.com/ligat-haal/besucherzahlen/wettbewerb/ISR1/saison_id/2023\n",
      "\n",
      "Found 2 tables with class 'items'\n",
      "\n",
      "First table structure:\n",
      "Headers (5):\n",
      "  0: #\n",
      "  1: Stadium\n",
      "  2: Capacity\n",
      "  3: Spectators\n",
      "  4: Average\n",
      "\n",
      "First 5 data rows:\n",
      "  Row 1: ['', 'Total:', '0', '1.101.572', '7.295']\n",
      "  Row 2: ['1', 'BloomfieldMaccabi Tel Aviv', '', 'Bloomfield', 'Maccabi Tel Aviv', '29.150', '213.565', '17.797']\n",
      "  Row 3: ['', 'Bloomfield']\n",
      "  Row 4: ['Maccabi Tel Aviv']\n",
      "  Row 5: ['2', 'Sammy Ofer StadiumMaccabi Haifa', '', 'Sammy Ofer Stadium', 'Maccabi Haifa', '30.780', '171.948', '17.195']\n"
     ]
    }
   ],
   "source": [
    "# Test: Inspect Transfermarkt attendance page structure\n",
    "from bs4 import BeautifulSoup\n",
    "ensure_environment()\n",
    "\n",
    "test_url = \"https://www.transfermarkt.com/ligat-haal/besucherzahlen/wettbewerb/ISR1/saison_id/2023\"\n",
    "print(f\"Testing URL: {test_url}\\n\")\n",
    "\n",
    "html = http_get(test_url)\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Find all tables\n",
    "tables = soup.find_all(\"table\", class_=\"items\")\n",
    "print(f\"Found {len(tables)} tables with class 'items'\\n\")\n",
    "\n",
    "if tables:\n",
    "    # Check first table structure\n",
    "    first_table = tables[0]\n",
    "    print(\"First table structure:\")\n",
    "    \n",
    "    # Get headers\n",
    "    headers = first_table.find_all(\"th\")\n",
    "    print(f\"Headers ({len(headers)}):\")\n",
    "    for i, h in enumerate(headers):\n",
    "        print(f\"  {i}: {h.get_text(strip=True)}\")\n",
    "    \n",
    "    # Get first few rows\n",
    "    rows = first_table.find_all(\"tr\")[1:6]  # Skip header, get first 5 data rows\n",
    "    print(f\"\\nFirst 5 data rows:\")\n",
    "    for idx, row in enumerate(rows):\n",
    "        cells = row.find_all([\"td\", \"th\"])\n",
    "        cell_texts = [cell.get_text(strip=True) for cell in cells]\n",
    "        print(f\"  Row {idx+1}: {cell_texts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eea184a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed row structure:\n",
      "\n",
      "--- Row 1 ---\n",
      "Non-data row: ['', 'Total:', '0', '1.101.572', '7.295']\n",
      "\n",
      "--- Row 2 ---\n",
      "Rank: 1\n",
      "Team: N/A\n",
      "Stadium: Bloomfield\n",
      "Capacity: \n",
      "Spectators: Bloomfield\n",
      "Average: Maccabi Tel Aviv\n",
      "\n",
      "--- Row 3 ---\n",
      "Non-data row: ['', 'Bloomfield']\n",
      "\n",
      "--- Row 4 ---\n",
      "Non-data row: ['Maccabi Tel Aviv']\n",
      "\n",
      "--- Row 5 ---\n",
      "Rank: 2\n",
      "Team: N/A\n",
      "Stadium: Sammy Ofer Stadium\n",
      "Capacity: \n",
      "Spectators: Sammy Ofer Stadium\n",
      "Average: Maccabi Haifa\n",
      "\n",
      "--- Row 6 ---\n",
      "Non-data row: ['', 'Sammy Ofer Stadium']\n",
      "\n",
      "--- Row 7 ---\n",
      "Non-data row: ['Maccabi Haifa']\n",
      "\n",
      "--- Row 8 ---\n",
      "Rank: 3\n",
      "Team: N/A\n",
      "Stadium: Teddy-Kollek-Stadion\n",
      "Capacity: \n",
      "Spectators: Teddy-Kollek-Stadion\n",
      "Average: Beitar Jerusalem\n",
      "\n",
      "--- Row 9 ---\n",
      "Non-data row: ['', 'Teddy-Kollek-Stadion']\n",
      "\n",
      "--- Row 10 ---\n",
      "Non-data row: ['Beitar Jerusalem']\n",
      "\n",
      "--- Row 11 ---\n",
      "Rank: 4\n",
      "Team: N/A\n",
      "Stadium: Toto Jacob Turner Stadium\n",
      "Capacity: \n",
      "Spectators: Toto Jacob Turner Stadium\n",
      "Average: Hapoel Beer Sheva\n",
      "\n",
      "--- Row 12 ---\n",
      "Non-data row: ['', 'Toto Jacob Turner Stadium']\n",
      "\n",
      "--- Row 13 ---\n",
      "Non-data row: ['Hapoel Beer Sheva']\n",
      "\n",
      "--- Row 14 ---\n",
      "Rank: 5\n",
      "Team: N/A\n",
      "Stadium: Bloomfield\n",
      "Capacity: \n",
      "Spectators: Bloomfield\n",
      "Average: Hapoel Tel Aviv\n"
     ]
    }
   ],
   "source": [
    "# Detailed inspection of attendance table rows\n",
    "from bs4 import BeautifulSoup\n",
    "ensure_environment()\n",
    "\n",
    "test_url = \"https://www.transfermarkt.com/ligat-haal/besucherzahlen/wettbewerb/ISR1/saison_id/2023\"\n",
    "html = http_get(test_url)\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "tables = soup.find_all(\"table\", class_=\"items\")\n",
    "if tables:\n",
    "    table = tables[0]\n",
    "    rows = table.find_all(\"tr\")[1:15]  # Skip header, get first 14 rows\n",
    "    \n",
    "    print(\"Detailed row structure:\")\n",
    "    for idx, row in enumerate(rows):\n",
    "        print(f\"\\n--- Row {idx+1} ---\")\n",
    "        cells = row.find_all([\"td\", \"th\"])\n",
    "        \n",
    "        # Check if this is a team row (has rank number)\n",
    "        if cells and cells[0].get_text(strip=True).isdigit():\n",
    "            rank = cells[0].get_text(strip=True)\n",
    "            \n",
    "            # Find team name - usually in a link with class 'vereinsname'\n",
    "            team_link = row.find(\"a\", class_=\"vereinsname\")\n",
    "            team = team_link.get_text(strip=True) if team_link else \"N/A\"\n",
    "            \n",
    "            # Find stadium name - usually earlier in the same cell\n",
    "            stadium_cell = cells[1] if len(cells) > 1 else None\n",
    "            stadium = \"\"\n",
    "            if stadium_cell:\n",
    "                # Get all text, then extract stadium (before team link)\n",
    "                all_text = stadium_cell.get_text(separator=\"|\", strip=True)\n",
    "                parts = all_text.split(\"|\")\n",
    "                stadium = parts[0] if parts else \"\"\n",
    "            \n",
    "            capacity = cells[2].get_text(strip=True) if len(cells) > 2 else \"N/A\"\n",
    "            spectators = cells[3].get_text(strip=True) if len(cells) > 3 else \"N/A\"\n",
    "            average = cells[4].get_text(strip=True) if len(cells) > 4 else \"N/A\"\n",
    "            \n",
    "            print(f\"Rank: {rank}\")\n",
    "            print(f\"Team: {team}\")\n",
    "            print(f\"Stadium: {stadium}\")\n",
    "            print(f\"Capacity: {capacity}\")\n",
    "            print(f\"Spectators: {spectators}\")\n",
    "            print(f\"Average: {average}\")\n",
    "        else:\n",
    "            print(f\"Non-data row: {[c.get_text(strip=True) for c in cells]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8eb57965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14 direct tbody rows\n",
      "\n",
      "First team row HTML:\n",
      "<tr class=\"even\">\n",
      " <td class=\"zentriert\">\n",
      "  2\n",
      " </td>\n",
      " <td>\n",
      "  <table class=\"inline-table\">\n",
      "   <tr>\n",
      "    <td class=\"zentriert wappen\" rowspan=\"2\">\n",
      "     <a href=\"#\">\n",
      "      <a href=\"/maccabi-haifa/spielplan/verein/1064/saison_id/2023\" title=\"Maccabi Haifa\">\n",
      "       <img alt=\"Maccabi Haifa\" class=\"\" src=\"https://tmssl.akamaized.net//images/wappen/verysmall/1064.png?lm=1684233681\" title=\"Maccabi Haifa\"/>\n",
      "      </a>\n",
      "     </a>\n",
      "    </td>\n",
      "    <td class=\"hauptlink\">\n",
      "     <a 0=\"1064\" href=\"/1064/stadion/verein/1064\">\n",
      "      Sammy Ofer Stadium\n",
      "     </a>\n",
      "    </td>\n",
      "   </tr>\n",
      "   <tr>\n",
      "    <td>\n",
      "     <a href=\"/maccabi-haifa/spielplan/verein/1064/saison_id/2023\" title=\"Maccabi Haifa\">\n",
      "      Maccabi Haifa\n",
      "     </a>\n",
      "    </td>\n",
      "   </tr>\n",
      "  </table>\n",
      " </td>\n",
      " <td class=\"rechts\">\n",
      "  30.780\n",
      " </td>\n",
      " <td class=\"rechts\">\n",
      "  171.948\n",
      " </td>\n",
      " <td class=\"rechts\">\n",
      "  17.195\n",
      " </td>\n",
      "</tr>\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Number of cells: 8\n",
      "\n",
      "Cell 0:\n",
      "  Text: 2\n",
      "\n",
      "Cell 1:\n",
      "  Text: Sammy Ofer StadiumMaccabi Haifa\n",
      "  Links: ['#', '/maccabi-haifa/spielplan/verein/1064/saison_id/2023', '/1064/stadion/verein/1064', '/maccabi-haifa/spielplan/verein/1064/saison_id/2023']\n",
      "\n",
      "Cell 2:\n",
      "  Text: \n",
      "  Links: ['#', '/maccabi-haifa/spielplan/verein/1064/saison_id/2023']\n",
      "\n",
      "Cell 3:\n",
      "  Text: Sammy Ofer Stadium\n",
      "  Links: ['/1064/stadion/verein/1064']\n",
      "\n",
      "Cell 4:\n",
      "  Text: Maccabi Haifa\n",
      "  Links: ['/maccabi-haifa/spielplan/verein/1064/saison_id/2023']\n",
      "\n",
      "Cell 5:\n",
      "  Text: 30.780\n",
      "\n",
      "Cell 6:\n",
      "  Text: 171.948\n",
      "\n",
      "Cell 7:\n",
      "  Text: 17.195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check actual HTML structure for one team row\n",
    "from bs4 import BeautifulSoup\n",
    "ensure_environment()\n",
    "\n",
    "test_url = \"https://www.transfermarkt.com/ligat-haal/besucherzahlen/wettbewerb/ISR1/saison_id/2023\"\n",
    "html = http_get(test_url)\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "tables = soup.find_all(\"table\", class_=\"items\")\n",
    "if tables:\n",
    "    table = tables[0]\n",
    "    tbody = table.find(\"tbody\")\n",
    "    \n",
    "    if tbody:\n",
    "        rows = tbody.find_all(\"tr\", recursive=False)  # Only direct children\n",
    "        print(f\"Found {len(rows)} direct tbody rows\\n\")\n",
    "        \n",
    "        # Look at first team entry (should be row index 1, row 0 is total)\n",
    "        if len(rows) > 1:\n",
    "            team_row = rows[1]\n",
    "            print(\"First team row HTML:\")\n",
    "            print(team_row.prettify()[:1500])\n",
    "            print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "            \n",
    "            # Try to extract data\n",
    "            cells = team_row.find_all(\"td\")\n",
    "            print(f\"Number of cells: {len(cells)}\\n\")\n",
    "            \n",
    "            for i, cell in enumerate(cells):\n",
    "                print(f\"Cell {i}:\")\n",
    "                print(f\"  Text: {cell.get_text(strip=True)[:100]}\")\n",
    "                links = cell.find_all(\"a\")\n",
    "                if links:\n",
    "                    print(f\"  Links: {[l.get('href') for l in links]}\")\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7954400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping attendance from: https://www.transfermarkt.com/ligat-haal/besucherzahlen/wettbewerb/ISR1/saison_id/2023\n",
      "  ‚úÖ Scraped 14 teams for 2023/24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>team</th>\n",
       "      <th>stadium</th>\n",
       "      <th>capacity</th>\n",
       "      <th>total_spectators</th>\n",
       "      <th>average_attendance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Maccabi Tel Aviv</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>29150</td>\n",
       "      <td>213565</td>\n",
       "      <td>17797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Maccabi Haifa</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>30780</td>\n",
       "      <td>171948</td>\n",
       "      <td>17195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Beitar Jerusalem</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>33500</td>\n",
       "      <td>144830</td>\n",
       "      <td>13166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Hapoel Beer Sheva</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>16126</td>\n",
       "      <td>122024</td>\n",
       "      <td>10169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Hapoel Tel Aviv</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>29150</td>\n",
       "      <td>101049</td>\n",
       "      <td>9186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Maccabi Netanya</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>13610</td>\n",
       "      <td>70127</td>\n",
       "      <td>5844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Hapoel Petah Tikva</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>11500</td>\n",
       "      <td>60759</td>\n",
       "      <td>5524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Hapoel Haifa</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>30820</td>\n",
       "      <td>42559</td>\n",
       "      <td>3869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Hapoel Jerusalem</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>33500</td>\n",
       "      <td>40070</td>\n",
       "      <td>3643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Maccabi Petah Tikva</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>11500</td>\n",
       "      <td>39337</td>\n",
       "      <td>3576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Hapoel Hadera</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>3000</td>\n",
       "      <td>34207</td>\n",
       "      <td>3421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Ihud Bnei Sakhnin</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>8500</td>\n",
       "      <td>24984</td>\n",
       "      <td>2271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Maccabi Bnei Reineh</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>5200</td>\n",
       "      <td>19400</td>\n",
       "      <td>1940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>FC Ashdod</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>8200</td>\n",
       "      <td>16713</td>\n",
       "      <td>2089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     season                 team  stadium  capacity  total_spectators  \\\n",
       "0   2023/24     Maccabi Tel Aviv  Unknown     29150            213565   \n",
       "1   2023/24        Maccabi Haifa  Unknown     30780            171948   \n",
       "2   2023/24     Beitar Jerusalem  Unknown     33500            144830   \n",
       "3   2023/24    Hapoel Beer Sheva  Unknown     16126            122024   \n",
       "4   2023/24      Hapoel Tel Aviv  Unknown     29150            101049   \n",
       "5   2023/24      Maccabi Netanya  Unknown     13610             70127   \n",
       "6   2023/24   Hapoel Petah Tikva  Unknown     11500             60759   \n",
       "7   2023/24         Hapoel Haifa  Unknown     30820             42559   \n",
       "8   2023/24     Hapoel Jerusalem  Unknown     33500             40070   \n",
       "9   2023/24  Maccabi Petah Tikva  Unknown     11500             39337   \n",
       "10  2023/24        Hapoel Hadera  Unknown      3000             34207   \n",
       "11  2023/24    Ihud Bnei Sakhnin  Unknown      8500             24984   \n",
       "12  2023/24  Maccabi Bnei Reineh  Unknown      5200             19400   \n",
       "13  2023/24            FC Ashdod  Unknown      8200             16713   \n",
       "\n",
       "    average_attendance  \n",
       "0                17797  \n",
       "1                17195  \n",
       "2                13166  \n",
       "3                10169  \n",
       "4                 9186  \n",
       "5                 5844  \n",
       "6                 5524  \n",
       "7                 3869  \n",
       "8                 3643  \n",
       "9                 3576  \n",
       "10                3421  \n",
       "11                2271  \n",
       "12                1940  \n",
       "13                2089  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def scrape_transfermarkt_attendance(season_year: int) -> 'pd.DataFrame':\n",
    "    \"\"\"\n",
    "    Scrape team attendance data from Transfermarkt for a given season.\n",
    "    \n",
    "    Args:\n",
    "        season_year: Starting year of season (e.g., 2023 for 2023/24)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with columns: season, team, stadium, capacity, total_spectators, average_attendance\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "    \n",
    "    url = f\"https://www.transfermarkt.com/ligat-haal/besucherzahlen/wettbewerb/ISR1/saison_id/{season_year}\"\n",
    "    print(f\"Scraping attendance from: {url}\")\n",
    "    \n",
    "    try:\n",
    "        html = http_get(url)\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        \n",
    "        # Find the attendance table\n",
    "        tables = soup.find_all(\"table\", class_=\"items\")\n",
    "        if not tables:\n",
    "            print(f\"  ‚ö†Ô∏è  No attendance tables found for {season_year}/{str(season_year+1)[-2:]}\")\n",
    "            return None\n",
    "        \n",
    "        table = tables[0]\n",
    "        tbody = table.find(\"tbody\")\n",
    "        if not tbody:\n",
    "            print(f\"  ‚ö†Ô∏è  No tbody found in attendance table for {season_year}/{str(season_year+1)[-2:]}\")\n",
    "            return None\n",
    "        \n",
    "        rows = tbody.find_all(\"tr\", recursive=False)\n",
    "        \n",
    "        attendance_data = []\n",
    "        season_str = f\"{season_year}/{str(season_year+1)[-2:]}\"\n",
    "        \n",
    "        for row in rows:\n",
    "            cells = row.find_all(\"td\")\n",
    "            if len(cells) < 5:\n",
    "                continue\n",
    "            \n",
    "            # First cell is rank (skip \"Total\" row)\n",
    "            rank_text = cells[0].get_text(strip=True)\n",
    "            if not rank_text.isdigit():\n",
    "                continue\n",
    "            \n",
    "            # Second cell contains inline table with stadium and team info\n",
    "            inline_table = cells[1].find(\"table\", class_=\"inline-table\")\n",
    "            if not inline_table:\n",
    "                continue\n",
    "            \n",
    "            # Extract stadium name (first link in inline table)\n",
    "            stadium_link = inline_table.find(\"a\", class_=\"hauptlink\")\n",
    "            stadium = stadium_link.get_text(strip=True) if stadium_link else \"Unknown\"\n",
    "            \n",
    "            # Extract team name (second row of inline table)\n",
    "            team_links = inline_table.find_all(\"a\", title=True)\n",
    "            team = \"Unknown\"\n",
    "            for link in team_links:\n",
    "                title = link.get(\"title\", \"\")\n",
    "                if title and \"spielplan\" in link.get(\"href\", \"\"):\n",
    "                    team = title\n",
    "                    break\n",
    "            \n",
    "            # Extract capacity, total spectators, average (last 3 cells)\n",
    "            # Note: Numbers use European format (dots for thousands)\n",
    "            capacity_text = cells[-3].get_text(strip=True)\n",
    "            total_text = cells[-2].get_text(strip=True)\n",
    "            average_text = cells[-1].get_text(strip=True)\n",
    "            \n",
    "            # Convert European number format (remove dots, handle empty values)\n",
    "            def parse_number(text):\n",
    "                if not text or text == \"-\":\n",
    "                    return None\n",
    "                return int(text.replace(\".\", \"\").replace(\",\", \"\"))\n",
    "            \n",
    "            capacity = parse_number(capacity_text)\n",
    "            total_spectators = parse_number(total_text)\n",
    "            average_attendance = parse_number(average_text)\n",
    "            \n",
    "            attendance_data.append({\n",
    "                \"season\": season_str,\n",
    "                \"team\": team,\n",
    "                \"stadium\": stadium,\n",
    "                \"capacity\": capacity,\n",
    "                \"total_spectators\": total_spectators,\n",
    "                \"average_attendance\": average_attendance\n",
    "            })\n",
    "        \n",
    "        if not attendance_data:\n",
    "            print(f\"  ‚ö†Ô∏è  No attendance data extracted for {season_year}/{str(season_year+1)[-2:]}\")\n",
    "            return None\n",
    "        \n",
    "        df = pd.DataFrame(attendance_data)\n",
    "        print(f\"  ‚úÖ Scraped {len(df)} teams for {season_str}\")\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Error scraping {season_year}/{str(season_year+1)[-2:]}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test the function\n",
    "ensure_environment()\n",
    "test_df = scrape_transfermarkt_attendance(2023)\n",
    "if test_df is not None:\n",
    "    display(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3922c964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping attendance from: https://www.transfermarkt.com/ligat-haal/besucherzahlen/wettbewerb/ISR1/saison_id/2023\n",
      "  ‚úÖ Scraped 14 teams for 2023/24\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\attendance_2023_24_ligat_haal_transfermarkt.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>team</th>\n",
       "      <th>stadium</th>\n",
       "      <th>capacity</th>\n",
       "      <th>total_spectators</th>\n",
       "      <th>average_attendance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Maccabi Tel Aviv</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>29150</td>\n",
       "      <td>213565</td>\n",
       "      <td>17797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Maccabi Haifa</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>30780</td>\n",
       "      <td>171948</td>\n",
       "      <td>17195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Beitar Jerusalem</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>33500</td>\n",
       "      <td>144830</td>\n",
       "      <td>13166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Hapoel Beer Sheva</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>16126</td>\n",
       "      <td>122024</td>\n",
       "      <td>10169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Hapoel Tel Aviv</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>29150</td>\n",
       "      <td>101049</td>\n",
       "      <td>9186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Maccabi Netanya</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>13610</td>\n",
       "      <td>70127</td>\n",
       "      <td>5844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Hapoel Petah Tikva</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>11500</td>\n",
       "      <td>60759</td>\n",
       "      <td>5524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Hapoel Haifa</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>30820</td>\n",
       "      <td>42559</td>\n",
       "      <td>3869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Hapoel Jerusalem</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>33500</td>\n",
       "      <td>40070</td>\n",
       "      <td>3643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Maccabi Petah Tikva</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>11500</td>\n",
       "      <td>39337</td>\n",
       "      <td>3576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Hapoel Hadera</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>3000</td>\n",
       "      <td>34207</td>\n",
       "      <td>3421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Ihud Bnei Sakhnin</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>8500</td>\n",
       "      <td>24984</td>\n",
       "      <td>2271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Maccabi Bnei Reineh</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>5200</td>\n",
       "      <td>19400</td>\n",
       "      <td>1940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>FC Ashdod</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>8200</td>\n",
       "      <td>16713</td>\n",
       "      <td>2089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     season                 team  stadium  capacity  total_spectators  \\\n",
       "0   2023/24     Maccabi Tel Aviv  Unknown     29150            213565   \n",
       "1   2023/24        Maccabi Haifa  Unknown     30780            171948   \n",
       "2   2023/24     Beitar Jerusalem  Unknown     33500            144830   \n",
       "3   2023/24    Hapoel Beer Sheva  Unknown     16126            122024   \n",
       "4   2023/24      Hapoel Tel Aviv  Unknown     29150            101049   \n",
       "5   2023/24      Maccabi Netanya  Unknown     13610             70127   \n",
       "6   2023/24   Hapoel Petah Tikva  Unknown     11500             60759   \n",
       "7   2023/24         Hapoel Haifa  Unknown     30820             42559   \n",
       "8   2023/24     Hapoel Jerusalem  Unknown     33500             40070   \n",
       "9   2023/24  Maccabi Petah Tikva  Unknown     11500             39337   \n",
       "10  2023/24        Hapoel Hadera  Unknown      3000             34207   \n",
       "11  2023/24    Ihud Bnei Sakhnin  Unknown      8500             24984   \n",
       "12  2023/24  Maccabi Bnei Reineh  Unknown      5200             19400   \n",
       "13  2023/24            FC Ashdod  Unknown      8200             16713   \n",
       "\n",
       "    average_attendance  \n",
       "0                17797  \n",
       "1                17195  \n",
       "2                13166  \n",
       "3                10169  \n",
       "4                 9186  \n",
       "5                 5844  \n",
       "6                 5524  \n",
       "7                 3869  \n",
       "8                 3643  \n",
       "9                 3576  \n",
       "10                3421  \n",
       "11                2271  \n",
       "12                1940  \n",
       "13                2089  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Quick test: scrape 2023/24 season attendance\n",
    "ensure_environment()\n",
    "season_year = 2023\n",
    "_df_2023 = scrape_transfermarkt_attendance(season_year)\n",
    "if _df_2023 is not None:\n",
    "    _csv_2023 = DATA_DIR / f\"attendance_{season_year}_{str(season_year+1)[-2:]}_ligat_haal_transfermarkt.csv\"\n",
    "    save_csv(_df_2023, _csv_2023)\n",
    "    display(_df_2023.head(20))\n",
    "else:\n",
    "    print(\"Failed to scrape 2023/24 attendance from Transfermarkt.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b7b8bf",
   "metadata": {},
   "source": [
    "## Scrape All 20 Seasons Attendance Data\n",
    "\n",
    "Now scrape attendance data for all seasons from 2006/07 to 2025/26."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "345fde91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping attendance data for 20 seasons (2006/2007-2025/26)\n",
      "\n",
      "================================================================================\n",
      "\n",
      "[2006/07]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2006_07_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 12 teams\n",
      "\n",
      "[2007/08]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2007_08_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 12 teams\n",
      "\n",
      "[2008/09]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2008_09_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 12 teams\n",
      "\n",
      "[2009/10]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2009_10_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 16 teams\n",
      "\n",
      "[2010/11]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2010_11_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 16 teams\n",
      "\n",
      "[2011/12]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2011_12_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 16 teams\n",
      "\n",
      "[2012/13]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2012_13_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 14 teams\n",
      "\n",
      "[2013/14]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2013_14_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 14 teams\n",
      "\n",
      "[2014/15]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2014_15_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 14 teams\n",
      "\n",
      "[2015/16]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2015_16_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 14 teams\n",
      "\n",
      "[2016/17]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2016_17_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 14 teams\n",
      "\n",
      "[2017/18]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2017_18_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 14 teams\n",
      "\n",
      "[2018/19]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2018_19_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 14 teams\n",
      "\n",
      "[2019/20]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2019_20_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 14 teams\n",
      "\n",
      "[2020/21]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2020_21_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 14 teams\n",
      "\n",
      "[2021/22]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2021_22_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 14 teams\n",
      "\n",
      "[2022/23]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2022_23_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 14 teams\n",
      "\n",
      "[2023/24]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2023_24_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 14 teams\n",
      "\n",
      "[2024/25]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2024_25_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 14 teams\n",
      "\n",
      "[2025/26]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2025_26_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 14 teams\n",
      "\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Successfully scraped/loaded: 20 seasons\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\attendance_all_seasons_ligat_haal_transfermarkt.csv\n",
      "\n",
      "üìä Combined attendance data:\n",
      "   Total records: 280\n",
      "   Seasons: 20\n",
      "   Teams: 29\n",
      "\n",
      "   Saved to: attendance_all_seasons_ligat_haal_transfermarkt.csv\n",
      "\n",
      "   Season Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teams</th>\n",
       "      <th>Total Spectators</th>\n",
       "      <th>Avg Attendance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>season</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006/07</th>\n",
       "      <td>12</td>\n",
       "      <td>119700</td>\n",
       "      <td>3136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007/08</th>\n",
       "      <td>12</td>\n",
       "      <td>362600</td>\n",
       "      <td>5738.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008/09</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009/10</th>\n",
       "      <td>16</td>\n",
       "      <td>939155</td>\n",
       "      <td>3926.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010/11</th>\n",
       "      <td>16</td>\n",
       "      <td>318450</td>\n",
       "      <td>4867.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011/12</th>\n",
       "      <td>16</td>\n",
       "      <td>911780</td>\n",
       "      <td>3891.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012/13</th>\n",
       "      <td>14</td>\n",
       "      <td>916940</td>\n",
       "      <td>5038.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013/14</th>\n",
       "      <td>14</td>\n",
       "      <td>970781</td>\n",
       "      <td>5444.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014/15</th>\n",
       "      <td>14</td>\n",
       "      <td>935937</td>\n",
       "      <td>7630.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015/16</th>\n",
       "      <td>14</td>\n",
       "      <td>1247497</td>\n",
       "      <td>6854.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016/17</th>\n",
       "      <td>14</td>\n",
       "      <td>1139400</td>\n",
       "      <td>6261.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/18</th>\n",
       "      <td>14</td>\n",
       "      <td>1079479</td>\n",
       "      <td>6072.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018/19</th>\n",
       "      <td>14</td>\n",
       "      <td>1142281</td>\n",
       "      <td>6298.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019/20</th>\n",
       "      <td>14</td>\n",
       "      <td>1345409</td>\n",
       "      <td>7392.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020/21</th>\n",
       "      <td>14</td>\n",
       "      <td>24790</td>\n",
       "      <td>1771.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021/22</th>\n",
       "      <td>14</td>\n",
       "      <td>1313511</td>\n",
       "      <td>7267.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022/23</th>\n",
       "      <td>14</td>\n",
       "      <td>1533006</td>\n",
       "      <td>8654.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023/24</th>\n",
       "      <td>14</td>\n",
       "      <td>1101572</td>\n",
       "      <td>7121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024/25</th>\n",
       "      <td>14</td>\n",
       "      <td>1245045</td>\n",
       "      <td>7337.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025/26</th>\n",
       "      <td>14</td>\n",
       "      <td>618435</td>\n",
       "      <td>9971.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Teams  Total Spectators  Avg Attendance\n",
       "season                                          \n",
       "2006/07     12            119700          3136.0\n",
       "2007/08     12            362600          5738.0\n",
       "2008/09     12                 0             0.0\n",
       "2009/10     16            939155          3926.0\n",
       "2010/11     16            318450          4867.0\n",
       "2011/12     16            911780          3891.0\n",
       "2012/13     14            916940          5038.0\n",
       "2013/14     14            970781          5444.0\n",
       "2014/15     14            935937          7630.0\n",
       "2015/16     14           1247497          6854.0\n",
       "2016/17     14           1139400          6261.0\n",
       "2017/18     14           1079479          6072.0\n",
       "2018/19     14           1142281          6298.0\n",
       "2019/20     14           1345409          7392.0\n",
       "2020/21     14             24790          1771.0\n",
       "2021/22     14           1313511          7267.0\n",
       "2022/23     14           1533006          8654.0\n",
       "2023/24     14           1101572          7121.0\n",
       "2024/25     14           1245045          7337.0\n",
       "2025/26     14            618435          9971.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scrape attendance data for all 20 seasons (2006-2025)\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "ensure_environment()\n",
    "\n",
    "# Define seasons to scrape\n",
    "start_year = 2006\n",
    "end_year = 2025\n",
    "seasons = list(range(start_year, end_year + 1))\n",
    "\n",
    "print(f\"Scraping attendance data for {len(seasons)} seasons ({start_year}/{start_year+1}-{end_year}/{str(end_year+1)[-2:]})\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "all_attendance = []\n",
    "failed = []\n",
    "\n",
    "for season_year in seasons:\n",
    "    season_str = f\"{season_year}/{str(season_year+1)[-2:]}\"\n",
    "    print(f\"\\n[{season_str}]\")\n",
    "    \n",
    "    # Check if already exists\n",
    "    csv_path = DATA_DIR / f\"attendance_{season_year}_{str(season_year+1)[-2:]}_ligat_haal_transfermarkt.csv\"\n",
    "    if csv_path.exists():\n",
    "        print(f\"  ‚ÑπÔ∏è  File already exists: {csv_path.name}\")\n",
    "        try:\n",
    "            existing_df = pd.read_csv(csv_path)\n",
    "            all_attendance.append(existing_df)\n",
    "            print(f\"  ‚úÖ Loaded existing data: {len(existing_df)} teams\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è  Error loading existing file: {e}\")\n",
    "            # Try scraping anyway\n",
    "            df = scrape_transfermarkt_attendance(season_year)\n",
    "            if df is not None:\n",
    "                save_csv(df, csv_path)\n",
    "                all_attendance.append(df)\n",
    "            else:\n",
    "                failed.append(season_str)\n",
    "    else:\n",
    "        # Scrape new data\n",
    "        df = scrape_transfermarkt_attendance(season_year)\n",
    "        if df is not None:\n",
    "            save_csv(df, csv_path)\n",
    "            all_attendance.append(df)\n",
    "        else:\n",
    "            failed.append(season_str)\n",
    "        \n",
    "        # Be polite to the server\n",
    "        time.sleep(1.2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"\\n‚úÖ Successfully scraped/loaded: {len(all_attendance)} seasons\")\n",
    "if failed:\n",
    "    print(f\"‚ùå Failed: {len(failed)} seasons: {', '.join(failed)}\")\n",
    "\n",
    "# Combine all data\n",
    "if all_attendance:\n",
    "    combined_attendance = pd.concat(all_attendance, ignore_index=True)\n",
    "    combined_path = DATA_DIR / \"attendance_all_seasons_ligat_haal_transfermarkt.csv\"\n",
    "    save_csv(combined_attendance, combined_path)\n",
    "    \n",
    "    print(f\"\\nüìä Combined attendance data:\")\n",
    "    print(f\"   Total records: {len(combined_attendance)}\")\n",
    "    print(f\"   Seasons: {combined_attendance['season'].nunique()}\")\n",
    "    print(f\"   Teams: {combined_attendance['team'].nunique()}\")\n",
    "    print(f\"\\n   Saved to: {combined_path.name}\")\n",
    "    \n",
    "    # Show summary by season\n",
    "    summary = combined_attendance.groupby('season').agg({\n",
    "        'team': 'count',\n",
    "        'total_spectators': 'sum',\n",
    "        'average_attendance': 'mean'\n",
    "    }).round(0)\n",
    "    summary.columns = ['Teams', 'Total Spectators', 'Avg Attendance']\n",
    "    print(\"\\n   Season Summary:\")\n",
    "    display(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eed36f8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Now that you have collected match and attendance data, you can:\n",
    "\n",
    "### 1. Multi-Season Attendance Collection\n",
    "Create a loop to scrape attendance for all 20 seasons (similar to the Wikipedia multi-season scraper).\n",
    "\n",
    "### 2. Data Merging\n",
    "Merge attendance data with match data by `(season, team)` to analyze:\n",
    "- Home performance vs attendance levels\n",
    "- Win rate correlation with fan support\n",
    "- Derby match attendance spikes\n",
    "\n",
    "### 3. Team Name Normalization\n",
    "Standardize team names between Wikipedia and Transfermarkt sources for accurate joining.\n",
    "\n",
    "### 4. Analysis & Visualization\n",
    "- Time series of attendance trends\n",
    "- Team performance over multiple seasons\n",
    "- Home advantage analysis\n",
    "- Goal-scoring patterns\n",
    "\n",
    "### 5. Statistical Modeling\n",
    "- Predict match outcomes based on historical data\n",
    "- Attendance forecasting\n",
    "- League position projections\n",
    "\n",
    "---\n",
    "\n",
    "**Current Data Available**:\n",
    "- ‚úÖ Match results: 20 seasons from Wikipedia (`matches_all_seasons_ligat_haal_wikipedia.csv`)\n",
    "- ‚úÖ Attendance: 2016/17 and 2023/24 from Transfermarkt\n",
    "- ‚úÖ Enriched data: Calculated metrics (points, goal_diff, results)\n",
    "\n",
    "**Files Generated**:\n",
    "```\n",
    "data/raw/\n",
    "‚îú‚îÄ‚îÄ matches_YYYY_YY_ligat_haal_wikipedia.csv (per season)\n",
    "‚îú‚îÄ‚îÄ matches_all_seasons_ligat_haal_wikipedia.csv (combined)\n",
    "‚îú‚îÄ‚îÄ attendance_2016_17_ligat_haal_transfermarkt.csv\n",
    "‚îî‚îÄ‚îÄ attendance_2023_24_ligat_haal_transfermarkt.csv\n",
    "\n",
    "data/interim/\n",
    "‚îú‚îÄ‚îÄ matches_2016_17_ligat_haal_enriched.csv\n",
    "‚îî‚îÄ‚îÄ matches_2022_23_enriched.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351c1949",
   "metadata": {},
   "source": [
    "## Analysis 1: League Leadership Changes\n",
    "\n",
    "This section calculates how many times first place changed hands during a season.\n",
    "\n",
    "**How it works:**\n",
    "1. Load match data for a specific season\n",
    "2. Calculate cumulative standings after each matchday\n",
    "3. Track which team was in first place after each round\n",
    "4. Count how many times leadership changed\n",
    "\n",
    "**Data source:** Wikipedia match results (not Transfermarkt - they don't have matchday-by-matchday data)\n",
    "\n",
    "**Example analysis:** 2016/17 season\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4dfd6c",
   "metadata": {},
   "source": [
    "### CRITICAL FIX: Team Name Normalization\n",
    "\n",
    "**Problem discovered:** The Wikipedia results matrix uses:\n",
    "- Full team names in rows (home teams)\n",
    "- Abbreviations in columns (away teams)\n",
    "\n",
    "This creates duplicate teams (28 instead of 14) and incorrect statistics!\n",
    "\n",
    "**Solution:** Create a mapping to normalize all team names to their full versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b79d0730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Team Name Mapping Loaded:\n",
      "  ‚Ä¢ 32 abbreviations\n",
      "  ‚Ä¢ 31 unique teams\n"
     ]
    }
   ],
   "source": [
    "# Team Name Mapping - Normalizes abbreviations and variants to full names\n",
    "# This mapping consolidates Wikipedia's inconsistent team naming across 20 seasons\n",
    "\n",
    "TEAM_NAME_MAP = {\n",
    "    # Abbreviations to full names\n",
    "    'ASH': 'F.C. Ashdod',\n",
    "    'BEI': 'Beitar Jerusalem',\n",
    "    'BnS': 'Bnei Sakhnin',\n",
    "    'BnY': 'Bnei Yehuda',\n",
    "    'HAS': 'Hapoel Ashkelon',\n",
    "    'HBS': \"Hapoel Be'er Sheva\",\n",
    "    'HHA': 'Hapoel Haifa',\n",
    "    'HKS': 'Hapoel Kfar Saba',\n",
    "    'HRA': \"Hapoel Ra'anana\",\n",
    "    'HTA': 'Hapoel Tel Aviv',\n",
    "    'IKS': 'Ironi Kiryat Shmona',\n",
    "    'MHA': 'Maccabi Haifa',\n",
    "    'MPT': 'Maccabi Petah Tikva',\n",
    "    'MTA': 'Maccabi Tel Aviv',\n",
    "    'HPT': 'Hapoel Petah Tikva',\n",
    "    'HRG': 'Hapoel Ramat Gan',\n",
    "    'HRH': 'Hapoel Ramat HaSharon',\n",
    "    'HRL': 'Rishon LeZion',\n",
    "    'MAN': 'Maccabi Ahi Nazareth',\n",
    "    'MBR': 'Maccabi Bnei Reineh',\n",
    "    'SNZ': 'Sektzia Ness Ziona',\n",
    "    'HAK': 'Hapoel Acre',\n",
    "    'MHE': 'Maccabi Herzliya',\n",
    "    'MNE': 'Maccabi Netanya',\n",
    "    'HAR': 'Hapoel Raanana',\n",
    "    'HAC': 'Hapoel Acre',\n",
    "    'IRH': 'Ironi Ramat HaSharon',\n",
    "    'HAH': 'Hapoel Hadera',\n",
    "    'NES': 'Ness Ziona',\n",
    "    'HJE': 'Hapoel Jerusalem',\n",
    "    'HNG': 'Hapoel Nof HaGalil',\n",
    "    'ITI': 'Ironi Tiberias',\n",
    "    \n",
    "    # Name variants to canonical names\n",
    "    'Ashdod': 'F.C. Ashdod',\n",
    "    'F.C. Ironi Ashdod': 'F.C. Ashdod',\n",
    "    'Ness Ziona': 'Sektzia Ness Ziona',\n",
    "    'Ironi Nir Ramat HaSharon': 'Ironi Ramat HaSharon',\n",
    "    'Hakoah Amidar Ramat Gan': 'Hapoel Ramat Gan',\n",
    "    'Hapoel Rishon LeZion': 'Rishon LeZion',\n",
    "    'Hapoel Raanana': \"Hapoel Ra'anana\",\n",
    "    \n",
    "    # Full names map to themselves\n",
    "    'F.C. Ashdod': 'F.C. Ashdod',\n",
    "    'Beitar Jerusalem': 'Beitar Jerusalem',\n",
    "    'Bnei Sakhnin': 'Bnei Sakhnin',\n",
    "    'Bnei Yehuda': 'Bnei Yehuda',\n",
    "    'Hapoel Ashkelon': 'Hapoel Ashkelon',\n",
    "    \"Hapoel Be'er Sheva\": \"Hapoel Be'er Sheva\",\n",
    "    'Hapoel Haifa': 'Hapoel Haifa',\n",
    "    'Hapoel Kfar Saba': 'Hapoel Kfar Saba',\n",
    "    \"Hapoel Ra'anana\": \"Hapoel Ra'anana\",\n",
    "    'Hapoel Tel Aviv': 'Hapoel Tel Aviv',\n",
    "    'Ironi Kiryat Shmona': 'Ironi Kiryat Shmona',\n",
    "    'Maccabi Haifa': 'Maccabi Haifa',\n",
    "    'Maccabi Petah Tikva': 'Maccabi Petah Tikva',\n",
    "    'Maccabi Tel Aviv': 'Maccabi Tel Aviv',\n",
    "    'Hapoel Petah Tikva': 'Hapoel Petah Tikva',\n",
    "    'Hapoel Ramat Gan': 'Hapoel Ramat Gan',\n",
    "    'Hapoel Ramat HaSharon': 'Hapoel Ramat HaSharon',\n",
    "    'Rishon LeZion': 'Rishon LeZion',\n",
    "    'Maccabi Ahi Nazareth': 'Maccabi Ahi Nazareth',\n",
    "    'Maccabi Bnei Reineh': 'Maccabi Bnei Reineh',\n",
    "    'Sektzia Ness Ziona': 'Sektzia Ness Ziona',\n",
    "    'Hapoel Acre': 'Hapoel Acre',\n",
    "    'Maccabi Herzliya': 'Maccabi Herzliya',\n",
    "    'Maccabi Netanya': 'Maccabi Netanya',\n",
    "    'Ironi Ramat HaSharon': 'Ironi Ramat HaSharon',\n",
    "    'Hapoel Hadera': 'Hapoel Hadera',\n",
    "    'Hapoel Jerusalem': 'Hapoel Jerusalem',\n",
    "    'Hapoel Nof HaGalil': 'Hapoel Nof HaGalil',\n",
    "    'Ironi Tiberias': 'Ironi Tiberias',\n",
    "}\n",
    "\n",
    "def normalize_team_names(df, name_map=TEAM_NAME_MAP):\n",
    "    \"\"\"\n",
    "    Normalize team names by converting abbreviations and variants to full names.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with 'home_team' and 'away_team' columns\n",
    "        name_map: Dictionary mapping abbreviations/variants to standardized names\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with normalized team names\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['home_team'] = df['home_team'].map(lambda x: name_map.get(x, x))\n",
    "    df['away_team'] = df['away_team'].map(lambda x: name_map.get(x, x))\n",
    "    return df\n",
    "\n",
    "def apply_season_specific_fixes(df, season):\n",
    "    \"\"\"\n",
    "    Apply season-specific Wikipedia data corrections.\n",
    "    Wikipedia sometimes uses incorrect team names in their results matrices.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with match data\n",
    "        season: Season string (e.g., '2006/07')\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with season-specific fixes applied\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    if season == '2006/07':\n",
    "        df.loc[df['home_team'] == 'Hapoel Ramat Gan', 'home_team'] = 'Hapoel Acre'\n",
    "    elif season == '2008/09':\n",
    "        df.loc[df['home_team'] == 'Hapoel Ramat Gan', 'home_team'] = \"Hapoel Ra'anana\"\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"‚úÖ Team Name Mapping Loaded:\")\n",
    "print(f\"  ‚Ä¢ {len([k for k in TEAM_NAME_MAP.keys() if len(k) <= 3])} abbreviations\")\n",
    "print(f\"  ‚Ä¢ {len(set(TEAM_NAME_MAP.values()))} unique teams\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03c7916a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATA SOURCES COMPARISON\n",
      "================================================================================\n",
      "\n",
      "üìä Match Data Files:\n",
      "  Transfermarkt: 20 seasons\n",
      "  Wikipedia: 21 seasons\n",
      "\n",
      "üîç Sample Analysis: matches_2006_07_ligat_haal_transfermarkt.csv\n",
      "  Total matches: 198\n",
      "  Columns: ['round', 'home', 'score', 'away']\n",
      "  Rounds: 1 to 198\n",
      "  Unique teams: 12\n",
      "\n",
      "  üìù For 12 teams:\n",
      "     Expected regular season: 132 matches\n",
      "     Found in Transfermarkt: 198 matches\n",
      "     ‚ö†Ô∏è  Match count doesn't match expected regular season\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üí° RECOMMENDATION:\n",
      "   Use WIKIPEDIA for complete match data (regular season + playoffs)\n",
      "   Use TRANSFERMARKT for attendance data\n",
      "\n",
      "   Your existing Wikipedia data already includes:\n",
      "   ‚úÖ Regular season matches\n",
      "   ‚úÖ Championship playoff matches\n",
      "   ‚úÖ Relegation playoff matches\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Summary: Compare data availability between Transfermarkt and Wikipedia\n",
    "import pandas as pd\n",
    "ensure_environment()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DATA SOURCES COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check what files we have\n",
    "transfermarkt_files = list(DATA_DIR.glob(\"matches_*_transfermarkt.csv\"))\n",
    "wiki_files = list(DATA_DIR.glob(\"matches_*_wikipedia.csv\"))\n",
    "\n",
    "print(f\"\\nüìä Match Data Files:\")\n",
    "print(f\"  Transfermarkt: {len(transfermarkt_files)} seasons\")\n",
    "print(f\"  Wikipedia: {len(wiki_files)} seasons\")\n",
    "\n",
    "# Sample one season to show the difference\n",
    "if transfermarkt_files:\n",
    "    sample_file = transfermarkt_files[0]\n",
    "    df_transfermarkt = pd.read_csv(sample_file)\n",
    "    \n",
    "    print(f\"\\nüîç Sample Analysis: {sample_file.name}\")\n",
    "    print(f\"  Total matches: {len(df_transfermarkt)}\")\n",
    "    print(f\"  Columns: {list(df_transfermarkt.columns)}\")\n",
    "    \n",
    "    # Check if it has round info\n",
    "    if 'round' in df_transfermarkt.columns:\n",
    "        print(f\"  Rounds: {df_transfermarkt['round'].min()} to {df_transfermarkt['round'].max()}\")\n",
    "    \n",
    "    # Count teams\n",
    "    teams_home = set(df_transfermarkt['home'].unique()) if 'home' in df_transfermarkt.columns else set()\n",
    "    teams_away = set(df_transfermarkt['away'].unique()) if 'away' in df_transfermarkt.columns else set()\n",
    "    all_teams = teams_home.union(teams_away)\n",
    "    \n",
    "    print(f\"  Unique teams: {len(all_teams)}\")\n",
    "    \n",
    "    # Calculate expected matches\n",
    "    num_teams = len(all_teams)\n",
    "    expected_regular = (num_teams - 1) * 2 * (num_teams // 2)\n",
    "    \n",
    "    print(f\"\\n  üìù For {num_teams} teams:\")\n",
    "    print(f\"     Expected regular season: {expected_regular} matches\")\n",
    "    print(f\"     Found in Transfermarkt: {len(df_transfermarkt)} matches\")\n",
    "    \n",
    "    if len(df_transfermarkt) == expected_regular:\n",
    "        print(f\"     ‚úÖ Confirmed: Regular season only (no playoffs)\")\n",
    "    else:\n",
    "        print(f\"     ‚ö†Ô∏è  Match count doesn't match expected regular season\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nüí° RECOMMENDATION:\")\n",
    "print(\"   Use WIKIPEDIA for complete match data (regular season + playoffs)\")\n",
    "print(\"   Use TRANSFERMARKT for attendance data\")\n",
    "print(\"\\n   Your existing Wikipedia data already includes:\")\n",
    "print(\"   ‚úÖ Regular season matches\")\n",
    "print(\"   ‚úÖ Championship playoff matches\")  \n",
    "print(\"   ‚úÖ Relegation playoff matches\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a6dc8d",
   "metadata": {},
   "source": [
    "### Fix All Existing Wikipedia Data Files\n",
    "\n",
    "This cell will re-process all existing Wikipedia match data to normalize team names.\n",
    "It reads the existing CSV files, applies the name mapping, and saves corrected versions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043ff866",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ DATA NORMALIZATION COMPLETE\n",
    "\n",
    "All Wikipedia match data has been updated with consistent team names:\n",
    "\n",
    "**Before:**\n",
    "- `home_team`: \"Hapoel Be'er Sheva\" (full name)\n",
    "- `away_team`: \"HBS\" (abbreviation) ‚ùå\n",
    "\n",
    "**After:**\n",
    "- `home_team`: \"Hapoel Be'er Sheva\" (full name)  \n",
    "- `away_team`: \"Hapoel Be'er Sheva\" (full name) ‚úÖ\n",
    "\n",
    "**Benefits:**\n",
    "- Correct team counts (14 teams, not 28)\n",
    "- Accurate statistics (26 games, 59 pts for regular season leader)\n",
    "- Easy to merge with attendance data\n",
    "- No need for mapping during analysis\n",
    "\n",
    "**Files updated:** All `matches_*_ligat_haal_wikipedia.csv` files in `data/raw/`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4865a640",
   "metadata": {},
   "source": [
    "### Diagnostic: Check Team Counts Per Season\n",
    "\n",
    "This cell identifies which seasons still have incorrect team counts (not 14)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e997ab00",
   "metadata": {},
   "source": [
    "### Build Comprehensive Team Name Mapping\n",
    "\n",
    "Since different seasons have different teams (due to promotion/relegation), we need to build a complete mapping that covers all abbreviations across all seasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "137203bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Ñπ Processing 2016/17: 182 matches, 14 teams\n",
      "\n",
      "üìä League Leadership Analysis - 2016/17 (REGULAR SEASON)\n",
      "============================================================\n",
      "\n",
      "üèÜ Leadership Changes: 3\n",
      "   (Initial leader doesn't count as a 'change')\n",
      "\n",
      "Round-by-round first place:\n",
      "  ‚Ä¢ Round  1: F.C. Ashdod\n",
      "  ‚Ä¢ Round  3: Beitar Jerusalem\n",
      "  ‚Ä¢ Round  8: Bnei Sakhnin\n",
      "  ‚Ä¢ Round 10: Hapoel Be'er Sheva\n",
      "\n",
      "üìã Final Standings After Round 26 (Regular Season):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>position</th>\n",
       "      <th>team</th>\n",
       "      <th>played</th>\n",
       "      <th>won</th>\n",
       "      <th>drawn</th>\n",
       "      <th>lost</th>\n",
       "      <th>gf</th>\n",
       "      <th>ga</th>\n",
       "      <th>gd</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Hapoel Be'er Sheva</td>\n",
       "      <td>26</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>13</td>\n",
       "      <td>41</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>Maccabi Tel Aviv</td>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>Maccabi Petah Tikva</td>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Beitar Jerusalem</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Bnei Sakhnin</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>Maccabi Haifa</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>Ironi Kiryat Shmona</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>35</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>Hapoel Haifa</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>29</td>\n",
       "      <td>36</td>\n",
       "      <td>-7</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>F.C. Ashdod</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>26</td>\n",
       "      <td>-11</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>Hapoel Ra'anana</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>29</td>\n",
       "      <td>-15</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    position                 team  played  won  drawn  lost  gf  ga  gd  \\\n",
       "5          1   Hapoel Be'er Sheva      26   18      5     3  54  13  41   \n",
       "13         2     Maccabi Tel Aviv      26   17      5     4  45  19  26   \n",
       "12         3  Maccabi Petah Tikva      26   13      9     4  36  23  13   \n",
       "0          4     Beitar Jerusalem      26   10     10     6  34  27   7   \n",
       "1          5         Bnei Sakhnin      26   10      9     7  26  26   0   \n",
       "11         6        Maccabi Haifa      26   10      8     8  30  25   5   \n",
       "10         7  Ironi Kiryat Shmona      26    9      8     9  35  33   2   \n",
       "6          8         Hapoel Haifa      26    8      4    14  29  36  -7   \n",
       "3          9          F.C. Ashdod      26    6     10    10  15  26 -11   \n",
       "8         10      Hapoel Ra'anana      26    7      7    12  14  29 -15   \n",
       "\n",
       "    points  \n",
       "5       59  \n",
       "13      56  \n",
       "12      48  \n",
       "0       40  \n",
       "1       39  \n",
       "11      38  \n",
       "10      35  \n",
       "6       28  \n",
       "3       28  \n",
       "8       28  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Season Statistics:\n",
      "  ‚Ä¢ Rounds analyzed: 26 (Regular Season only)\n",
      "  ‚Ä¢ Teams: 14\n",
      "  ‚Ä¢ Total matches: 182\n",
      "  ‚Ä¢ Leader after regular season: Hapoel Be'er Sheva (59 pts, 26 games)\n",
      "  ‚Ä¢ Runner-up: Maccabi Tel Aviv (56 pts, 26 games)\n",
      "  ‚Ä¢ Points gap: 3 pts\n",
      "\n",
      "‚ö†Ô∏è IMPORTANT NOTE:\n",
      "   Wikipedia results matrix only shows REGULAR SEASON matches (26 rounds).\n",
      "   Ligat Ha'al has additional Championship/Relegation playoffs (~10 rounds).\n",
      "   Full season totals: ~36 matches, ~87 points for champion (as you mentioned).\n",
      "   This analysis tracks leadership changes during the regular season only.\n",
      "\n",
      "‚úÖ All team names are now normalized (full names used throughout).\n"
     ]
    }
   ],
   "source": [
    "# Calculate league standings after each matchday and track leadership changes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ensure_environment()\n",
    "\n",
    "def calculate_league_table_by_round(matches_df, season_str=\"2016/17\"):\n",
    "    \"\"\"\n",
    "    Calculate league standings after each round/matchday.\n",
    "    \n",
    "    Args:\n",
    "        matches_df: DataFrame with match results (with normalized team names)\n",
    "        season_str: Season to analyze (e.g., \"2016/17\")\n",
    "    \n",
    "    Returns:\n",
    "        - standings_by_round: dict mapping round_num -> DataFrame of standings\n",
    "        - leadership_changes: list of tuples (round_num, new_leader)\n",
    "    \n",
    "    Note: Team names should already be normalized (full names, not abbreviations).\n",
    "    \"\"\"\n",
    "    # Filter for the specific season\n",
    "    season_matches = matches_df[matches_df['season'] == season_str].copy()\n",
    "    \n",
    "    # Get all unique teams - count ONLY home teams (each team has home games)\n",
    "    # This avoids duplicate counting from abbreviations in away_team column\n",
    "    teams = sorted(season_matches['home_team'].unique())\n",
    "    n_teams = len(teams)\n",
    "    \n",
    "    print(f\"‚Ñπ Processing {season_str}: {len(season_matches)} matches, {n_teams} teams\")\n",
    "    \n",
    "    # In Ligat Ha'al, 14 teams play 26 rounds in regular season, then split into championship/relegation\n",
    "    # For the regular season: each team plays 13 opponents √ó 2 (home/away) = 26 matches\n",
    "    # Total matches in regular season = (14 teams √ó 26 matches) / 2 = 182 matches\n",
    "    \n",
    "    # Assign round numbers by ordering matches\n",
    "    # Since we don't have dates, distribute evenly assuming each round has n_teams/2 matches\n",
    "    season_matches = season_matches.reset_index(drop=True)\n",
    "    \n",
    "    # Each round has 7 matches (14 teams / 2)\n",
    "    matches_per_round = n_teams // 2 if n_teams % 2 == 0 else (n_teams + 1) // 2\n",
    "    \n",
    "    # Assign rounds based on position in dataset\n",
    "    season_matches['round_num'] = (season_matches.index // matches_per_round) + 1\n",
    "    max_round = season_matches['round_num'].max()\n",
    "    \n",
    "    # Initialize standings tracker\n",
    "    standings_by_round = {}\n",
    "    current_leader = None\n",
    "    leadership_changes = []\n",
    "    \n",
    "    # Calculate standings after each round\n",
    "    for round_num in sorted(season_matches['round_num'].unique()):\n",
    "        # Get all matches up to and including this round\n",
    "        matches_so_far = season_matches[season_matches['round_num'] <= round_num]\n",
    "        \n",
    "        # Initialize team stats\n",
    "        stats = {team: {'played': 0, 'won': 0, 'drawn': 0, 'lost': 0, \n",
    "                        'gf': 0, 'ga': 0, 'gd': 0, 'points': 0} \n",
    "                 for team in teams}\n",
    "        \n",
    "        # Calculate stats from matches\n",
    "        for _, match in matches_so_far.iterrows():\n",
    "            home = match['home_team']\n",
    "            away = match['away_team']\n",
    "            home_goals = match['home_goals']\n",
    "            away_goals = match['away_goals']\n",
    "            \n",
    "            # Update home team\n",
    "            stats[home]['played'] += 1\n",
    "            stats[home]['gf'] += home_goals\n",
    "            stats[home]['ga'] += away_goals\n",
    "            stats[home]['gd'] = stats[home]['gf'] - stats[home]['ga']\n",
    "            \n",
    "            # Update away team\n",
    "            stats[away]['played'] += 1\n",
    "            stats[away]['gf'] += away_goals\n",
    "            stats[away]['ga'] += home_goals\n",
    "            stats[away]['gd'] = stats[away]['gf'] - stats[away]['ga']\n",
    "            \n",
    "            # Update points\n",
    "            if home_goals > away_goals:  # Home win\n",
    "                stats[home]['won'] += 1\n",
    "                stats[home]['points'] += 3\n",
    "                stats[away]['lost'] += 1\n",
    "            elif away_goals > home_goals:  # Away win\n",
    "                stats[away]['won'] += 1\n",
    "                stats[away]['points'] += 3\n",
    "                stats[home]['lost'] += 1\n",
    "            else:  # Draw\n",
    "                stats[home]['drawn'] += 1\n",
    "                stats[away]['drawn'] += 1\n",
    "                stats[home]['points'] += 1\n",
    "                stats[away]['points'] += 1\n",
    "        \n",
    "        # Convert to DataFrame and sort\n",
    "        standings = pd.DataFrame.from_dict(stats, orient='index')\n",
    "        standings.index.name = 'team'\n",
    "        standings = standings.reset_index()\n",
    "        standings = standings.sort_values(['points', 'gd', 'gf'], ascending=[False, False, False])\n",
    "        standings['position'] = range(1, len(standings) + 1)\n",
    "        \n",
    "        standings_by_round[int(round_num)] = standings\n",
    "        \n",
    "        # Track leader\n",
    "        new_leader = standings.iloc[0]['team']\n",
    "        if new_leader != current_leader:\n",
    "            leadership_changes.append((int(round_num), new_leader))\n",
    "            current_leader = new_leader\n",
    "    \n",
    "    return standings_by_round, leadership_changes\n",
    "\n",
    "# Load the combined matches data\n",
    "matches_path = DATA_DIR / \"matches_all_seasons_ligat_haal_wikipedia.csv\"\n",
    "if not matches_path.exists():\n",
    "    print(f\"‚ùå Combined matches file not found: {matches_path}\")\n",
    "    print(\"Please run the multi-season Wikipedia scraper first (cell 17)\")\n",
    "else:\n",
    "    all_matches = pd.read_csv(matches_path)\n",
    "    \n",
    "    # Normalize team names (convert abbreviations to full names)\n",
    "    all_matches = normalize_team_names(all_matches, TEAM_NAME_MAP)\n",
    "    \n",
    "    # Apply season-specific fixes\n",
    "    for season_name in all_matches['season'].unique():\n",
    "        season_data = all_matches[all_matches['season'] == season_name]\n",
    "        all_matches.loc[all_matches['season'] == season_name] = apply_season_specific_fixes(season_data, season_name)\n",
    "    \n",
    "    # Analyze 2016/17 season\n",
    "    season = \"2016/17\"\n",
    "    standings_by_round, leadership_changes = calculate_league_table_by_round(all_matches, season)\n",
    "    \n",
    "    print(f\"\\nüìä League Leadership Analysis - {season} (REGULAR SEASON)\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\nüèÜ Leadership Changes: {len(leadership_changes) - 1}\")\n",
    "    print(f\"   (Initial leader doesn't count as a 'change')\\n\")\n",
    "    \n",
    "    print(\"Round-by-round first place:\")\n",
    "    for round_num, leader in leadership_changes:\n",
    "        print(f\"  ‚Ä¢ Round {round_num:2d}: {leader}\")\n",
    "    \n",
    "    # Show final standings\n",
    "    print(f\"\\nüìã Final Standings After Round {max(standings_by_round.keys())} (Regular Season):\")\n",
    "    final = standings_by_round[max(standings_by_round.keys())]\n",
    "    display(final[['position', 'team', 'played', 'won', 'drawn', 'lost', 'gf', 'ga', 'gd', 'points']].head(10))\n",
    "    \n",
    "    # Calculate some interesting stats\n",
    "    print(f\"\\nüìà Season Statistics:\")\n",
    "    print(f\"  ‚Ä¢ Rounds analyzed: {len(standings_by_round)} (Regular Season only)\")\n",
    "    print(f\"  ‚Ä¢ Teams: {len(final)}\")\n",
    "    print(f\"  ‚Ä¢ Total matches: {len(all_matches[all_matches['season'] == season])}\")\n",
    "    print(f\"  ‚Ä¢ Leader after regular season: {final.iloc[0]['team']} ({final.iloc[0]['points']:.0f} pts, {final.iloc[0]['played']:.0f} games)\")\n",
    "    print(f\"  ‚Ä¢ Runner-up: {final.iloc[1]['team']} ({final.iloc[1]['points']:.0f} pts, {final.iloc[1]['played']:.0f} games)\")\n",
    "    print(f\"  ‚Ä¢ Points gap: {final.iloc[0]['points'] - final.iloc[1]['points']:.0f} pts\")\n",
    "    \n",
    "    print(f\"\\n‚ö†Ô∏è IMPORTANT NOTE:\")\n",
    "    print(f\"   Wikipedia results matrix only shows REGULAR SEASON matches (26 rounds).\")\n",
    "    print(f\"   Ligat Ha'al has additional Championship/Relegation playoffs (~10 rounds).\")\n",
    "    print(f\"   Full season totals: ~36 matches, ~87 points for champion (as you mentioned).\")\n",
    "    print(f\"   This analysis tracks leadership changes during the regular season only.\")\n",
    "    print(f\"\\n‚úÖ All team names are now normalized (full names used throughout).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b28b10e",
   "metadata": {},
   "source": [
    "### Visualization: Title Race Chart\n",
    "\n",
    "Visualize how the top teams' points progressed throughout the season.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1234dec",
   "metadata": {},
   "source": [
    "### Multi-Season Comparison: Competitive Balance\n",
    "\n",
    "Compare how competitive each season was by analyzing leadership changes across multiple seasons.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a37a719",
   "metadata": {},
   "source": [
    "## Analysis 2: Multi-Season Attendance Collection\n",
    "\n",
    "Scrape attendance data from Transfermarkt for all 20 seasons to enable trend analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c80ee750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping attendance data for 20 seasons from Transfermarkt...\n",
      "Seasons: 2006/07 to 2025/26\n",
      "================================================================================\n",
      "2006/07: ‚è≠ (already exists, loading...)\n",
      "2007/08: ‚è≠ (already exists, loading...)\n",
      "2008/09: ‚è≠ (already exists, loading...)\n",
      "2009/10: ‚è≠ (already exists, loading...)\n",
      "2010/11: ‚è≠ (already exists, loading...)\n",
      "2011/12: ‚è≠ (already exists, loading...)\n",
      "2012/13: ‚è≠ (already exists, loading...)\n",
      "2013/14: ‚è≠ (already exists, loading...)\n",
      "2014/15: ‚è≠ (already exists, loading...)\n",
      "2015/16: ‚è≠ (already exists, loading...)\n",
      "2016/17: ‚è≠ (already exists, loading...)\n",
      "2017/18: ‚è≠ (already exists, loading...)\n",
      "2018/19: ‚è≠ (already exists, loading...)\n",
      "2019/20: ‚è≠ (already exists, loading...)\n",
      "2020/21: ‚è≠ (already exists, loading...)\n",
      "2021/22: ‚è≠ (already exists, loading...)\n",
      "2022/23: ‚è≠ (already exists, loading...)\n",
      "2023/24: ‚è≠ (already exists, loading...)\n",
      "2024/25: ‚è≠ (already exists, loading...)\n",
      "2025/26: ‚è≠ (already exists, loading...)\n",
      "\n",
      "================================================================================\n",
      "‚úÖ Successfully collected: 20 seasons\n",
      "‚ùå Failed: 0 seasons\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\attendance_all_seasons_ligat_haal_transfermarkt.csv\n",
      "\n",
      "üìä Combined Attendance Data:\n",
      "  ‚Ä¢ Total rows: 280\n",
      "  ‚Ä¢ Seasons: 20\n",
      "  ‚Ä¢ Unique teams: 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>team</th>\n",
       "      <th>stadium</th>\n",
       "      <th>capacity</th>\n",
       "      <th>total_spectators</th>\n",
       "      <th>average_attendance</th>\n",
       "      <th>utilization_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>Bnei Yehuda Tel Aviv</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>6020</td>\n",
       "      <td>49000</td>\n",
       "      <td>3063</td>\n",
       "      <td>50.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>Hapoel Tel Aviv</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>29150</td>\n",
       "      <td>16000</td>\n",
       "      <td>5333</td>\n",
       "      <td>18.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>Hapoel Petah Tikva</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>11500</td>\n",
       "      <td>10250</td>\n",
       "      <td>2050</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>Beitar Jerusalem</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>33500</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>29.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>Maccabi Netanya</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>13610</td>\n",
       "      <td>9250</td>\n",
       "      <td>3083</td>\n",
       "      <td>22.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>Maccabi Haifa</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>30780</td>\n",
       "      <td>7700</td>\n",
       "      <td>3850</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>Hakoah Amidar Ramat Gan</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>8000</td>\n",
       "      <td>6250</td>\n",
       "      <td>1250</td>\n",
       "      <td>15.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>Hapoel Kfar Saba</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>5800</td>\n",
       "      <td>4500</td>\n",
       "      <td>2250</td>\n",
       "      <td>38.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>FC Ashdod</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>8200</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>30.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>Maccabi Petah Tikva</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>11500</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>17.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    season                     team  stadium  capacity  total_spectators  \\\n",
       "0  2006/07     Bnei Yehuda Tel Aviv  Unknown      6020             49000   \n",
       "1  2006/07          Hapoel Tel Aviv  Unknown     29150             16000   \n",
       "2  2006/07       Hapoel Petah Tikva  Unknown     11500             10250   \n",
       "3  2006/07         Beitar Jerusalem  Unknown     33500             10000   \n",
       "4  2006/07          Maccabi Netanya  Unknown     13610              9250   \n",
       "5  2006/07            Maccabi Haifa  Unknown     30780              7700   \n",
       "6  2006/07  Hakoah Amidar Ramat Gan  Unknown      8000              6250   \n",
       "7  2006/07         Hapoel Kfar Saba  Unknown      5800              4500   \n",
       "8  2006/07                FC Ashdod  Unknown      8200              2500   \n",
       "9  2006/07      Maccabi Petah Tikva  Unknown     11500              2000   \n",
       "\n",
       "   average_attendance  utilization_pct  \n",
       "0                3063             50.9  \n",
       "1                5333             18.3  \n",
       "2                2050             17.8  \n",
       "3               10000             29.9  \n",
       "4                3083             22.7  \n",
       "5                3850             12.5  \n",
       "6                1250             15.6  \n",
       "7                2250             38.8  \n",
       "8                2500             30.5  \n",
       "9                2000             17.4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Average Attendance by Season:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg Attendance</th>\n",
       "      <th>Avg Utilization %</th>\n",
       "      <th>Teams</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>season</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006/07</th>\n",
       "      <td>3135.8</td>\n",
       "      <td>22.2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007/08</th>\n",
       "      <td>5737.8</td>\n",
       "      <td>36.8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008/09</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009/10</th>\n",
       "      <td>3926.3</td>\n",
       "      <td>24.1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010/11</th>\n",
       "      <td>4866.6</td>\n",
       "      <td>28.2</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011/12</th>\n",
       "      <td>3890.8</td>\n",
       "      <td>26.9</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012/13</th>\n",
       "      <td>5038.1</td>\n",
       "      <td>30.5</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013/14</th>\n",
       "      <td>5444.1</td>\n",
       "      <td>36.7</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014/15</th>\n",
       "      <td>7630.2</td>\n",
       "      <td>43.1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015/16</th>\n",
       "      <td>6854.4</td>\n",
       "      <td>42.1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016/17</th>\n",
       "      <td>6260.6</td>\n",
       "      <td>37.3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/18</th>\n",
       "      <td>6071.6</td>\n",
       "      <td>36.8</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018/19</th>\n",
       "      <td>6298.4</td>\n",
       "      <td>41.2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019/20</th>\n",
       "      <td>7392.3</td>\n",
       "      <td>48.6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020/21</th>\n",
       "      <td>1770.7</td>\n",
       "      <td>11.4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021/22</th>\n",
       "      <td>7266.8</td>\n",
       "      <td>40.5</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022/23</th>\n",
       "      <td>8653.8</td>\n",
       "      <td>50.4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023/24</th>\n",
       "      <td>7120.7</td>\n",
       "      <td>42.8</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024/25</th>\n",
       "      <td>7336.7</td>\n",
       "      <td>41.3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025/26</th>\n",
       "      <td>9970.6</td>\n",
       "      <td>49.4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Avg Attendance  Avg Utilization %  Teams\n",
       "season                                           \n",
       "2006/07          3135.8               22.2     12\n",
       "2007/08          5737.8               36.8     12\n",
       "2008/09             0.0                0.0     12\n",
       "2009/10          3926.3               24.1     16\n",
       "2010/11          4866.6               28.2     16\n",
       "2011/12          3890.8               26.9     16\n",
       "2012/13          5038.1               30.5     14\n",
       "2013/14          5444.1               36.7     14\n",
       "2014/15          7630.2               43.1     14\n",
       "2015/16          6854.4               42.1     14\n",
       "2016/17          6260.6               37.3     14\n",
       "2017/18          6071.6               36.8     14\n",
       "2018/19          6298.4               41.2     14\n",
       "2019/20          7392.3               48.6     14\n",
       "2020/21          1770.7               11.4     14\n",
       "2021/22          7266.8               40.5     14\n",
       "2022/23          8653.8               50.4     14\n",
       "2023/24          7120.7               42.8     14\n",
       "2024/25          7336.7               41.3     14\n",
       "2025/26          9970.6               49.4     14"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scrape attendance data for multiple seasons from Transfermarkt\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "ensure_environment()\n",
    "\n",
    "# Calculate seasons to scrape (last 20 seasons)\n",
    "current_year = datetime.now().year\n",
    "if datetime.now().month < 8:  # If before August, last season started in previous year\n",
    "    current_year -= 1\n",
    "seasons_to_scrape = list(range(current_year - 19, current_year + 1))\n",
    "\n",
    "print(f\"Scraping attendance data for {len(seasons_to_scrape)} seasons from Transfermarkt...\")\n",
    "print(f\"Seasons: {seasons_to_scrape[0]}/{str(seasons_to_scrape[0]+1)[-2:]} to {seasons_to_scrape[-1]}/{str(seasons_to_scrape[-1]+1)[-2:]}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "all_attendance = []\n",
    "success_count = 0\n",
    "fail_count = 0\n",
    "\n",
    "for season_year in seasons_to_scrape:\n",
    "    # Check if already scraped\n",
    "    existing_file = DATA_DIR / f\"attendance_{season_year}_{str(season_year+1)[-2:]}_ligat_haal_transfermarkt.csv\"\n",
    "    \n",
    "    if existing_file.exists():\n",
    "        print(f\"{season_year}/{str(season_year+1)[-2:]}: ‚è≠ (already exists, loading...)\")\n",
    "        try:\n",
    "            df = pd.read_csv(existing_file)\n",
    "            all_attendance.append(df)\n",
    "            success_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö† Error loading existing file: {e}\")\n",
    "            fail_count += 1\n",
    "    else:\n",
    "        # Scrape new season\n",
    "        df = scrape_transfermarkt_attendance(season_year)\n",
    "        \n",
    "        if df is not None and len(df) > 0:\n",
    "            all_attendance.append(df)\n",
    "            success_count += 1\n",
    "            time.sleep(2)  # Be polite to Transfermarkt\n",
    "        else:\n",
    "            fail_count += 1\n",
    "        \n",
    "        time.sleep(1)  # Rate limiting\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"‚úÖ Successfully collected: {success_count} seasons\")\n",
    "print(f\"‚ùå Failed: {fail_count} seasons\")\n",
    "\n",
    "if all_attendance:\n",
    "    # Combine all seasons\n",
    "    combined_attendance = pd.concat(all_attendance, ignore_index=True)\n",
    "    \n",
    "    # Save combined file\n",
    "    combined_path = DATA_DIR / \"attendance_all_seasons_ligat_haal_transfermarkt.csv\"\n",
    "    save_csv(combined_attendance, combined_path)\n",
    "    \n",
    "    print(f\"\\nüìä Combined Attendance Data:\")\n",
    "    print(f\"  ‚Ä¢ Total rows: {len(combined_attendance)}\")\n",
    "    print(f\"  ‚Ä¢ Seasons: {combined_attendance['season'].nunique()}\")\n",
    "    print(f\"  ‚Ä¢ Unique teams: {combined_attendance['team'].nunique()}\")\n",
    "    \n",
    "    # Calculate utilization percentage\n",
    "    combined_attendance['utilization_pct'] = (\n",
    "        combined_attendance['average_attendance'] / combined_attendance['capacity'] * 100\n",
    "    ).fillna(0).round(1)\n",
    "    \n",
    "    # Show sample\n",
    "    display(combined_attendance.head(10))\n",
    "    \n",
    "    # Summary statistics by season\n",
    "    print(\"\\nüìà Average Attendance by Season:\")\n",
    "    season_avg = combined_attendance.groupby('season').agg({\n",
    "        'average_attendance': 'mean',\n",
    "        'utilization_pct': 'mean',\n",
    "        'team': 'count'\n",
    "    }).round(1)\n",
    "    season_avg.columns = ['Avg Attendance', 'Avg Utilization %', 'Teams']\n",
    "    display(season_avg)\n",
    "else:\n",
    "    print(\"\\n‚ö† No attendance data was successfully collected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e07a7b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\n"
     ]
    }
   ],
   "source": [
    "print(DATA_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63750808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved 198 matches -> matches_2006_07_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2006\n",
      "‚úÖ Saved 198 matches -> matches_2007_08_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2007\n",
      "‚úÖ Saved 198 matches -> matches_2008_09_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2008\n",
      "‚úÖ Saved 240 matches -> matches_2009_10_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2009\n",
      "‚úÖ Saved 240 matches -> matches_2010_11_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2010\n",
      "‚úÖ Saved 240 matches -> matches_2011_12_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2011\n",
      "‚úÖ Saved 182 matches -> matches_2012_13_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2012\n",
      "‚úÖ Saved 182 matches -> matches_2013_14_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2013\n",
      "‚úÖ Saved 182 matches -> matches_2014_15_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2014\n",
      "‚úÖ Saved 182 matches -> matches_2015_16_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2015\n",
      "‚úÖ Saved 182 matches -> matches_2016_17_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2016\n",
      "‚úÖ Saved 182 matches -> matches_2017_18_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2017\n",
      "‚úÖ Saved 182 matches -> matches_2018_19_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2018\n",
      "‚úÖ Saved 182 matches -> matches_2019_20_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2019\n",
      "‚úÖ Saved 182 matches -> matches_2020_21_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2020\n",
      "‚úÖ Saved 182 matches -> matches_2021_22_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2021\n",
      "‚úÖ Saved 182 matches -> matches_2022_23_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2022\n",
      "‚úÖ Saved 182 matches -> matches_2023_24_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2023\n",
      "‚úÖ Saved 182 matches -> matches_2024_25_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2024\n",
      "‚úÖ Saved 69 matches -> matches_2025_26_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2025\n",
      "\n",
      "Summary:\n",
      "Regular seasons scraped: 20\n",
      "Playoff seasons scraped: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season_year</th>\n",
       "      <th>regular_matches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2011</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2012</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2014</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2016</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2021</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2022</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2024</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2025</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    season_year  regular_matches\n",
       "0          2006              198\n",
       "1          2007              198\n",
       "2          2008              198\n",
       "3          2009              240\n",
       "4          2010              240\n",
       "5          2011              240\n",
       "6          2012              182\n",
       "7          2013              182\n",
       "8          2014              182\n",
       "9          2015              182\n",
       "10         2016              182\n",
       "11         2017              182\n",
       "12         2018              182\n",
       "13         2019              182\n",
       "14         2020              182\n",
       "15         2021              182\n",
       "16         2022              182\n",
       "17         2023              182\n",
       "18         2024              182\n",
       "19         2025               69"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ‚ö†Ô∏è NOTE: This cell has been moved to after the function definitions.\n",
    "# Please scroll down to find the validation cell after cells 47-48.\n",
    "# This placeholder prevents execution errors.\n",
    "\n",
    "print(\"‚ö†Ô∏è Validation cell moved to bottom of notebook (after function definitions).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62556bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Checking for match tables ===\n",
      "Total tables found: 27\n",
      "Rows with score pattern (\\d+:\\d+): 342\n",
      "\n",
      "=== First match row HTML sample ===\n",
      "<tr class=\"bg_blau_20\">\n",
      "<td class=\"show-for-small\" colspan=\"7\">\n",
      "                                            Sat                                                    <a href=\"/aktuell/waspassiertheute/aktuell/new/datum/2023-08-26\">26/08/23</a>6:00 PM                                        </td>\n",
      "</tr>\n",
      "\n",
      "Team links found in first row: 0\n",
      "Score found: 236:00\n"
     ]
    }
   ],
   "source": [
    "# Debug: Inspect Transfermarkt HTML structure for 2023 season\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url_2023 = 'https://www.transfermarkt.com/ligat-haal/gesamtspielplan/wettbewerb/ISR1?saison_id=2023'\n",
    "HEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}\n",
    "resp = requests.get(url_2023, headers=HEADERS, timeout=20)\n",
    "html = resp.text\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Look for match tables\n",
    "print('=== Checking for match tables ===')\n",
    "tables = soup.find_all('table')\n",
    "print(f'Total tables found: {len(tables)}')\n",
    "\n",
    "# Check for rows with scores (pattern: digit:digit)\n",
    "import re\n",
    "all_rows_with_scores = []\n",
    "for table in tables:\n",
    "    for tr in table.find_all('tr'):\n",
    "        txt = tr.get_text()\n",
    "        if re.search(r'\\d+:\\d+', txt):\n",
    "            all_rows_with_scores.append(tr)\n",
    "\n",
    "print(f'Rows with score pattern (\\\\d+:\\\\d+): {len(all_rows_with_scores)}')\n",
    "\n",
    "# Inspect first few match rows\n",
    "if all_rows_with_scores:\n",
    "    print('\\n=== First match row HTML sample ===')\n",
    "    print(str(all_rows_with_scores[0])[:800])\n",
    "    \n",
    "    # Try to extract team names and scores from first row\n",
    "    first_row = all_rows_with_scores[0]\n",
    "    team_links = first_row.find_all('a', href=re.compile(r'/verein/'))\n",
    "    print(f'\\nTeam links found in first row: {len(team_links)}')\n",
    "    for i, link in enumerate(team_links[:4]):\n",
    "        print(f'  Team {i+1}: {link.get_text(strip=True)}')\n",
    "    \n",
    "    # Find score\n",
    "    score_match = re.search(r'(\\d+):(\\d+)', first_row.get_text())\n",
    "    if score_match:\n",
    "        print(f'Score found: {score_match.group(0)}')\n",
    "else:\n",
    "    print('No rows with scores found - checking page structure...')\n",
    "    print('\\nFirst 2000 chars of HTML:')\n",
    "    print(html[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de69515b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Match rows with 2+ team links: 182\n",
      "\n",
      "=== Sample match row HTML ===\n",
      "<tr>\n",
      "<td class=\"hide-for-small\">\n",
      "                                        Sat                                                <a href=\"/aktuell/waspassiertheute/aktuell/new/datum/2023-08-26\">26/08/23</a> </td>\n",
      "<td class=\"zentriert hide-for-small\">\n",
      "                                                6:00 PM                                    </td>\n",
      "<td class=\"text-right no-border-rechts hauptlink\"><a href=\"/ihud-bnei-sachnin/spielplan/verein/4769/saison_id/2023\" title=\"Ihud Bnei Sakhnin\">Bnei Sakhnin</a></td>\n",
      "<td class=\"zentriert no-border-links\"><a href=\"/ihud-bnei-sachnin/spielplan/verein/4769/saison_id/2023\" title=\"Ihud Bnei Sakhnin\"><img alt=\"Ihud Bnei Sakhnin\" class=\"tiny_wappen\" src=\"https://tmssl.akamaized.net//images/wappen/tiny/4769.png?lm=1423260464\" title=\"Ihud Bnei Sakhnin\"/></a></td>\n",
      "<td class=\"zentriert hauptlink\">¬†<a class=\"ergebnis-link\" href=\"/ihud-bnei-sakhnin_hapoel-tel-aviv/index/spielbericht/4118835\" id=\"4118835\" title=\"\">1:1</a>¬†</td>\n",
      "<td class=\"zentriert no-border-rechts\"><a href=\"/hapoel-tel-aviv/spielplan/verein/1017/saison_id/2023\" title=\"Hapoel Tel Aviv\"><img alt=\"Hapoel Tel Aviv\" class=\"\" src=\"https://tmssl.akamaized.net//images/wappen/tiny/1017_1658409966.png?l\n",
      "\n",
      "Teams: Bnei Sakhnin vs \n",
      "Score: 6:00\n",
      "\n",
      "=== Looking for matchday headers ===\n",
      "Found 0 potential headers in table\n"
     ]
    }
   ],
   "source": [
    "# Find actual match rows (with 2 team links)\n",
    "match_rows = []\n",
    "for row in all_rows_with_scores:\n",
    "    team_links = row.find_all('a', href=re.compile(r'/verein/'))\n",
    "    if len(team_links) >= 2:\n",
    "        match_rows.append(row)\n",
    "\n",
    "print(f'\\nMatch rows with 2+ team links: {len(match_rows)}')\n",
    "\n",
    "if match_rows:\n",
    "    print('\\n=== Sample match row HTML ===')\n",
    "    sample_row = match_rows[0]\n",
    "    print(str(sample_row)[:1200])\n",
    "    \n",
    "    # Extract teams\n",
    "    team_links = sample_row.find_all('a', href=re.compile(r'/verein/'))\n",
    "    print(f'\\nTeams: {team_links[0].get_text(strip=True)} vs {team_links[1].get_text(strip=True)}')\n",
    "    \n",
    "    # Extract score\n",
    "    score_match = re.search(r'(\\d+):(\\d+)', sample_row.get_text())\n",
    "    if score_match:\n",
    "        print(f'Score: {score_match.group(0)}')\n",
    "    \n",
    "    # Check for round/matchday info in nearby elements\n",
    "    print('\\n=== Looking for matchday headers ===')\n",
    "    # Find parent table or section\n",
    "    parent = sample_row.find_parent('table')\n",
    "    if parent:\n",
    "        # Look for headers before this row\n",
    "        prev_elements = parent.find_all(['h2', 'h3', 'div'], class_=re.compile(r'box-headline|table-header|spieltag'))\n",
    "        print(f'Found {len(prev_elements)} potential headers in table')\n",
    "        if prev_elements:\n",
    "            print(f'First header: {prev_elements[0].get_text(strip=True)[:100]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94b29e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Looking for matchday structure ===\n",
      "Total headings: 1\n",
      "\n",
      "Matchday-related headings found: 0\n",
      "\n",
      "Div.box elements: 27\n",
      "Match rows in first box: 0\n"
     ]
    }
   ],
   "source": [
    "# Look for matchday/round structure in page\n",
    "print('=== Looking for matchday structure ===')\n",
    "\n",
    "# Check all headings in the page\n",
    "headings = soup.find_all(['h1', 'h2', 'h3', 'h4'])\n",
    "print(f'Total headings: {len(headings)}')\n",
    "\n",
    "matchday_headings = []\n",
    "for h in headings:\n",
    "    txt = h.get_text(strip=True)\n",
    "    if re.search(r'Matchday|Spieltag|Round|Championship|Relegation', txt, re.IGNORECASE):\n",
    "        matchday_headings.append(txt)\n",
    "        \n",
    "print(f'\\nMatchday-related headings found: {len(matchday_headings)}')\n",
    "for i, h in enumerate(matchday_headings[:10]):\n",
    "    print(f'  {i+1}. {h}')\n",
    "\n",
    "# Check divs with 'box' class that might contain sections\n",
    "boxes = soup.find_all('div', class_='box')\n",
    "print(f'\\nDiv.box elements: {len(boxes)}')\n",
    "\n",
    "if boxes:\n",
    "    first_box = boxes[0]\n",
    "    h2 = first_box.find(['h2', 'h3'])\n",
    "    if h2:\n",
    "        print(f'First box header: {h2.get_text(strip=True)}')\n",
    "    # Count match rows in first box\n",
    "    box_tables = first_box.find_all('table')\n",
    "    box_match_rows = 0\n",
    "    for t in box_tables:\n",
    "        for tr in t.find_all('tr'):\n",
    "            if len(tr.find_all('a', href=re.compile(r'/verein/'))) >= 2:\n",
    "                box_match_rows += 1\n",
    "    print(f'Match rows in first box: {box_match_rows}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a02af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved 182 matches -> matches_2023_24_ligat_haal_transfermarkt.csv\n",
      "\n",
      "Successfully scraped 182 matches for 2023/24\n",
      "Columns: ['round', 'home', 'score', 'away']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>home</th>\n",
       "      <th>score</th>\n",
       "      <th>away</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bnei Sakhnin</td>\n",
       "      <td>1:1</td>\n",
       "      <td>Hapoel Tel Aviv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M. Petah Tikva</td>\n",
       "      <td>1:1</td>\n",
       "      <td>H. Jerusalem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Maccabi Netanya</td>\n",
       "      <td>1:1</td>\n",
       "      <td>M. Bnei Reineh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>H. Beer Sheva</td>\n",
       "      <td>3:0</td>\n",
       "      <td>Hapoel Hadera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M. Tel Aviv</td>\n",
       "      <td>4:1</td>\n",
       "      <td>FC Ashdod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>B. Jerusalem</td>\n",
       "      <td>1:2</td>\n",
       "      <td>Hapoel Haifa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Maccabi Haifa</td>\n",
       "      <td>2:1</td>\n",
       "      <td>H. Petah Tikva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>M. Bnei Reineh</td>\n",
       "      <td>1:1</td>\n",
       "      <td>H. Beer Sheva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>H. Petah Tikva</td>\n",
       "      <td>1:1</td>\n",
       "      <td>Bnei Sakhnin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Hapoel Haifa</td>\n",
       "      <td>2:2</td>\n",
       "      <td>M. Petah Tikva</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   round             home score             away\n",
       "0      1     Bnei Sakhnin   1:1  Hapoel Tel Aviv\n",
       "1      2   M. Petah Tikva   1:1     H. Jerusalem\n",
       "2      3  Maccabi Netanya   1:1   M. Bnei Reineh\n",
       "3      4    H. Beer Sheva   3:0    Hapoel Hadera\n",
       "4      5      M. Tel Aviv   4:1        FC Ashdod\n",
       "5      6     B. Jerusalem   1:2     Hapoel Haifa\n",
       "6      7    Maccabi Haifa   2:1   H. Petah Tikva\n",
       "7      8   M. Bnei Reineh   1:1    H. Beer Sheva\n",
       "8      9   H. Petah Tikva   1:1     Bnei Sakhnin\n",
       "9     10     Hapoel Haifa   2:2   M. Petah Tikva"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>home</th>\n",
       "      <th>score</th>\n",
       "      <th>away</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>178</td>\n",
       "      <td>Maccabi Netanya</td>\n",
       "      <td>1:3</td>\n",
       "      <td>Hapoel Hadera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>179</td>\n",
       "      <td>M. Petah Tikva</td>\n",
       "      <td>0:3</td>\n",
       "      <td>B. Jerusalem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>180</td>\n",
       "      <td>Bnei Sakhnin</td>\n",
       "      <td>0:0</td>\n",
       "      <td>M. Bnei Reineh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>181</td>\n",
       "      <td>M. Tel Aviv</td>\n",
       "      <td>3:1</td>\n",
       "      <td>Hapoel Haifa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>182</td>\n",
       "      <td>Maccabi Haifa</td>\n",
       "      <td>0:0</td>\n",
       "      <td>Hapoel Tel Aviv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     round             home score             away\n",
       "177    178  Maccabi Netanya   1:3    Hapoel Hadera\n",
       "178    179   M. Petah Tikva   0:3     B. Jerusalem\n",
       "179    180     Bnei Sakhnin   0:0   M. Bnei Reineh\n",
       "180    181      M. Tel Aviv   3:1     Hapoel Haifa\n",
       "181    182    Maccabi Haifa   0:0  Hapoel Tel Aviv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the fixed scraper on 2023 season\n",
    "df_test = scrape_transfermarkt_regular(2023)\n",
    "if df_test is not None:\n",
    "    print(f'\\nSuccessfully scraped {len(df_test)} matches for 2023/24')\n",
    "    print(f'Columns: {list(df_test.columns)}')\n",
    "    display(df_test.head(10))\n",
    "    display(df_test.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953c623e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to scrape 20 seasons from Transfermarkt...\n",
      "Time started: 00:50:40\n",
      "================================================================================\n",
      "\n",
      "[1/20] Scraping 2006/07...\n",
      "‚úÖ Saved 198 matches -> matches_2006_07_ligat_haal_transfermarkt.csv\n",
      "‚úÖ Saved 198 matches -> matches_2006_07_ligat_haal_transfermarkt.csv\n",
      "\n",
      "[2/20] Scraping 2007/08...\n",
      "\n",
      "[2/20] Scraping 2007/08...\n",
      "‚úÖ Saved 198 matches -> matches_2007_08_ligat_haal_transfermarkt.csv\n",
      "‚úÖ Saved 198 matches -> matches_2007_08_ligat_haal_transfermarkt.csv\n",
      "\n",
      "[3/20] Scraping 2008/09...\n",
      "\n",
      "[3/20] Scraping 2008/09...\n",
      "‚úÖ Saved 198 matches -> matches_2008_09_ligat_haal_transfermarkt.csv\n",
      "‚úÖ Saved 198 matches -> matches_2008_09_ligat_haal_transfermarkt.csv\n",
      "\n",
      "[4/20] Scraping 2009/10...\n",
      "\n",
      "[4/20] Scraping 2009/10...\n",
      "‚úÖ Saved 240 matches -> matches_2009_10_ligat_haal_transfermarkt.csv\n",
      "‚úÖ Saved 240 matches -> matches_2009_10_ligat_haal_transfermarkt.csv\n",
      "\n",
      "[5/20] Scraping 2010/11...\n",
      "\n",
      "[5/20] Scraping 2010/11...\n",
      "‚úÖ Saved 240 matches -> matches_2010_11_ligat_haal_transfermarkt.csv\n",
      "‚úÖ Saved 240 matches -> matches_2010_11_ligat_haal_transfermarkt.csv\n",
      "\n",
      "[6/20] Scraping 2011/12...\n",
      "\n",
      "[6/20] Scraping 2011/12...\n",
      "‚úÖ Saved 240 matches -> matches_2011_12_ligat_haal_transfermarkt.csv\n",
      "‚úÖ Saved 240 matches -> matches_2011_12_ligat_haal_transfermarkt.csv\n",
      "\n",
      "[7/20] Scraping 2012/13...\n",
      "\n",
      "[7/20] Scraping 2012/13...\n",
      "‚úÖ Saved 182 matches -> matches_2012_13_ligat_haal_transfermarkt.csv\n",
      "‚úÖ Saved 182 matches -> matches_2012_13_ligat_haal_transfermarkt.csv\n",
      "\n",
      "[8/20] Scraping 2013/14...\n",
      "\n",
      "[8/20] Scraping 2013/14...\n",
      "‚úÖ Saved 182 matches -> matches_2013_14_ligat_haal_transfermarkt.csv\n",
      "‚úÖ Saved 182 matches -> matches_2013_14_ligat_haal_transfermarkt.csv\n",
      "\n",
      "[9/20] Scraping 2014/15...\n",
      "\n",
      "[9/20] Scraping 2014/15...\n",
      "‚úÖ Saved 182 matches -> matches_2014_15_ligat_haal_transfermarkt.csv\n",
      "‚úÖ Saved 182 matches -> matches_2014_15_ligat_haal_transfermarkt.csv\n",
      "\n",
      "[10/20] Scraping 2015/16...\n",
      "\n",
      "[10/20] Scraping 2015/16...\n",
      "‚úÖ Saved 182 matches -> matches_2015_16_ligat_haal_transfermarkt.csv\n",
      "‚úÖ Saved 182 matches -> matches_2015_16_ligat_haal_transfermarkt.csv\n",
      "\n",
      "[11/20] Scraping 2016/17...\n",
      "\n",
      "[11/20] Scraping 2016/17...\n",
      "‚úÖ Saved 182 matches -> matches_2016_17_ligat_haal_transfermarkt.csv\n",
      "‚úÖ Saved 182 matches -> matches_2016_17_ligat_haal_transfermarkt.csv\n",
      "\n",
      "[12/20] Scraping 2017/18...\n",
      "\n",
      "[12/20] Scraping 2017/18...\n",
      "‚úÖ Saved 182 matches -> matches_2017_18_ligat_haal_transfermarkt.csv\n",
      "‚úÖ Saved 182 matches -> matches_2017_18_ligat_haal_transfermarkt.csv\n",
      "\n",
      "[13/20] Scraping 2018/19...\n",
      "\n",
      "[13/20] Scraping 2018/19...\n",
      "‚úÖ Saved 182 matches -> matches_2018_19_ligat_haal_transfermarkt.csv\n",
      "‚úÖ Saved 182 matches -> matches_2018_19_ligat_haal_transfermarkt.csv\n",
      "\n",
      "[14/20] Scraping 2019/20...\n",
      "\n",
      "[14/20] Scraping 2019/20...\n",
      "‚úÖ Saved 182 matches -> matches_2019_20_ligat_haal_transfermarkt.csv\n",
      "‚úÖ Saved 182 matches -> matches_2019_20_ligat_haal_transfermarkt.csv\n",
      "\n",
      "[15/20] Scraping 2020/21...\n",
      "\n",
      "[15/20] Scraping 2020/21...\n",
      "‚úÖ Saved 182 matches -> matches_2020_21_ligat_haal_transfermarkt.csv\n",
      "‚úÖ Saved 182 matches -> matches_2020_21_ligat_haal_transfermarkt.csv\n",
      "\n",
      "[16/20] Scraping 2021/22...\n",
      "\n",
      "[16/20] Scraping 2021/22...\n",
      "‚úÖ Saved 182 matches -> matches_2021_22_ligat_haal_transfermarkt.csv\n",
      "‚úÖ Saved 182 matches -> matches_2021_22_ligat_haal_transfermarkt.csv\n",
      "\n",
      "[17/20] Scraping 2022/23...\n",
      "\n",
      "[17/20] Scraping 2022/23...\n",
      "‚úÖ Saved 182 matches -> matches_2022_23_ligat_haal_transfermarkt.csv\n",
      "‚úÖ Saved 182 matches -> matches_2022_23_ligat_haal_transfermarkt.csv\n",
      "\n",
      "[18/20] Scraping 2023/24...\n",
      "\n",
      "[18/20] Scraping 2023/24...\n",
      "‚úÖ Saved 182 matches -> matches_2023_24_ligat_haal_transfermarkt.csv\n",
      "‚úÖ Saved 182 matches -> matches_2023_24_ligat_haal_transfermarkt.csv\n",
      "\n",
      "[19/20] Scraping 2024/25...\n",
      "\n",
      "[19/20] Scraping 2024/25...\n",
      "‚úÖ Saved 182 matches -> matches_2024_25_ligat_haal_transfermarkt.csv\n",
      "‚úÖ Saved 182 matches -> matches_2024_25_ligat_haal_transfermarkt.csv\n",
      "\n",
      "[20/20] Scraping 2025/26...\n",
      "\n",
      "[20/20] Scraping 2025/26...\n",
      "‚úÖ Saved 69 matches -> matches_2025_26_ligat_haal_transfermarkt.csv\n",
      "\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Successfully scraped: 20 seasons\n",
      "‚ùå Failed: 0 seasons\n",
      "\n",
      "‚úÖ Scraping Summary:\n",
      "‚úÖ Saved 69 matches -> matches_2025_26_ligat_haal_transfermarkt.csv\n",
      "\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Successfully scraped: 20 seasons\n",
      "‚ùå Failed: 0 seasons\n",
      "\n",
      "‚úÖ Scraping Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Matches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007/08</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008/09</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009/10</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010/11</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2011/12</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2012/13</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013/14</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2014/15</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015/16</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2016/17</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017/18</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018/19</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019/20</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020/21</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2021/22</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2022/23</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2024/25</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2025/26</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Season  Matches\n",
       "0   2006/07      198\n",
       "1   2007/08      198\n",
       "2   2008/09      198\n",
       "3   2009/10      240\n",
       "4   2010/11      240\n",
       "5   2011/12      240\n",
       "6   2012/13      182\n",
       "7   2013/14      182\n",
       "8   2014/15      182\n",
       "9   2015/16      182\n",
       "10  2016/17      182\n",
       "11  2017/18      182\n",
       "12  2018/19      182\n",
       "13  2019/20      182\n",
       "14  2020/21      182\n",
       "15  2021/22      182\n",
       "16  2022/23      182\n",
       "17  2023/24      182\n",
       "18  2024/25      182\n",
       "19  2025/26       69"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total matches scraped: 3749\n",
      "Time finished: 00:51:41\n"
     ]
    }
   ],
   "source": [
    "# Scrape all 20 seasons from Transfermarkt (2006-2025)\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "seasons = list(range(2006, 2026))  # 2006/07 through 2025/26\n",
    "results = {}\n",
    "failed = []\n",
    "\n",
    "print(f'Starting to scrape {len(seasons)} seasons from Transfermarkt...')\n",
    "print(f'Time started: {datetime.now().strftime(\"%H:%M:%S\")}')\n",
    "print('=' * 80)\n",
    "\n",
    "for i, season_year in enumerate(seasons, 1):\n",
    "    print(f'\\n[{i}/{len(seasons)}] Scraping {season_year}/{str(season_year+1)[-2:]}...')\n",
    "    \n",
    "    try:\n",
    "        df = scrape_transfermarkt_regular(season_year)\n",
    "        if df is not None:\n",
    "            results[season_year] = len(df)\n",
    "        else:\n",
    "            failed.append(season_year)\n",
    "    except Exception as e:\n",
    "        print(f'  ‚ùå Error: {e}')\n",
    "        failed.append(season_year)\n",
    "    \n",
    "    # Be polite - wait between requests\n",
    "    if i < len(seasons):\n",
    "        time.sleep(2)\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "print(f'\\n‚úÖ Successfully scraped: {len(results)} seasons')\n",
    "print(f'‚ùå Failed: {len(failed)} seasons')\n",
    "if failed:\n",
    "    print(f'  Failed seasons: {failed}')\n",
    "\n",
    "# Show summary\n",
    "if results:\n",
    "    import pandas as pd\n",
    "    summary = pd.DataFrame(list(results.items()), columns=['Season', 'Matches'])\n",
    "    summary['Season'] = summary['Season'].apply(lambda x: f\"{x}/{str(x+1)[-2:]}\")\n",
    "    print('\\n‚úÖ Scraping Summary:')\n",
    "    display(summary)\n",
    "    \n",
    "    print(f'\\nTotal matches scraped: {sum(results.values())}')\n",
    "    print(f'Time finished: {datetime.now().strftime(\"%H:%M:%S\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9e09de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 20 Transfermarkt CSV files\n",
      "\n",
      "Files:\n",
      "  - matches_2006_07_ligat_haal_transfermarkt.csv\n",
      "  - matches_2007_08_ligat_haal_transfermarkt.csv\n",
      "  - matches_2008_09_ligat_haal_transfermarkt.csv\n",
      "  - matches_2009_10_ligat_haal_transfermarkt.csv\n",
      "  - matches_2010_11_ligat_haal_transfermarkt.csv\n",
      "  - matches_2011_12_ligat_haal_transfermarkt.csv\n",
      "  - matches_2012_13_ligat_haal_transfermarkt.csv\n",
      "  - matches_2013_14_ligat_haal_transfermarkt.csv\n",
      "  - matches_2014_15_ligat_haal_transfermarkt.csv\n",
      "  - matches_2015_16_ligat_haal_transfermarkt.csv\n",
      "  - matches_2016_17_ligat_haal_transfermarkt.csv\n",
      "  - matches_2017_18_ligat_haal_transfermarkt.csv\n",
      "  - matches_2018_19_ligat_haal_transfermarkt.csv\n",
      "  - matches_2019_20_ligat_haal_transfermarkt.csv\n",
      "  - matches_2020_21_ligat_haal_transfermarkt.csv\n",
      "  - matches_2021_22_ligat_haal_transfermarkt.csv\n",
      "  - matches_2022_23_ligat_haal_transfermarkt.csv\n",
      "  - matches_2023_24_ligat_haal_transfermarkt.csv\n",
      "  - matches_2024_25_ligat_haal_transfermarkt.csv\n",
      "  - matches_2025_26_ligat_haal_transfermarkt.csv\n",
      "\n",
      "‚úÖ Sample file: matches_2006_07_ligat_haal_transfermarkt.csv\n",
      "  Columns: ['round', 'home', 'score', 'away']\n",
      "  Shape: (198, 4)\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>home</th>\n",
       "      <th>score</th>\n",
       "      <th>away</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>H. Kfar Saba</td>\n",
       "      <td>4:1</td>\n",
       "      <td>H. Petah Tikva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M. Petah Tikva</td>\n",
       "      <td>0:0</td>\n",
       "      <td>Hakoah Amidar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>FC Ashdod</td>\n",
       "      <td>1:0</td>\n",
       "      <td>Maccabi Herzlya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Maccabi Netanya</td>\n",
       "      <td>3:1</td>\n",
       "      <td>Maccabi Haifa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M. Tel Aviv</td>\n",
       "      <td>1:2</td>\n",
       "      <td>B. Jerusalem</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   round             home score             away\n",
       "0      1     H. Kfar Saba   4:1   H. Petah Tikva\n",
       "1      2   M. Petah Tikva   0:0    Hakoah Amidar\n",
       "2      3        FC Ashdod   1:0  Maccabi Herzlya\n",
       "3      4  Maccabi Netanya   3:1    Maccabi Haifa\n",
       "4      5      M. Tel Aviv   1:2     B. Jerusalem"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data quality check:\n",
      "  Missing home teams: 0\n",
      "  Missing away teams: 0\n",
      "  Missing scores: 0\n",
      "\n",
      "‚úÖ Wikipedia sample: matches_2006_07_ligat_haal_wikipedia.csv\n",
      "  Columns: ['season', 'season_year', 'home_team', 'away_team', 'home_goals', 'away_goals', 'goal_diff', 'result', 'home_points', 'away_points']\n",
      "\n",
      "First 3 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>season_year</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>home_goals</th>\n",
       "      <th>away_goals</th>\n",
       "      <th>goal_diff</th>\n",
       "      <th>result</th>\n",
       "      <th>home_points</th>\n",
       "      <th>away_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>2006</td>\n",
       "      <td>Beitar Jerusalem</td>\n",
       "      <td>BnY</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>2006</td>\n",
       "      <td>Beitar Jerusalem</td>\n",
       "      <td>ASH</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>H</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>2006</td>\n",
       "      <td>Beitar Jerusalem</td>\n",
       "      <td>HAK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    season  season_year         home_team away_team  home_goals  away_goals  \\\n",
       "0  2006/07         2006  Beitar Jerusalem       BnY           0           0   \n",
       "1  2006/07         2006  Beitar Jerusalem       ASH           2           0   \n",
       "2  2006/07         2006  Beitar Jerusalem       HAK           0           0   \n",
       "\n",
       "   goal_diff result  home_points  away_points  \n",
       "0          0      D            1            1  \n",
       "1          2      H            3            0  \n",
       "2          0      D            1            1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Format comparison:\n",
      "  Transfermarkt columns: ['round', 'home', 'score', 'away']\n",
      "  Wikipedia columns: ['season', 'season_year', 'home_team', 'away_team', 'home_goals', 'away_goals', 'goal_diff', 'result', 'home_points', 'away_points']\n",
      "  Match: False\n"
     ]
    }
   ],
   "source": [
    "# Verify scraped data and compare with Wikipedia format\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# List all Transfermarkt CSVs\n",
    "DATA_DIR = Path(ROOT) / 'data' / 'raw'\n",
    "transfermarkt_files = sorted(DATA_DIR.glob('matches_*_ligat_haal_transfermarkt.csv'))\n",
    "\n",
    "print(f'‚úÖ Found {len(transfermarkt_files)} Transfermarkt CSV files')\n",
    "print('\\nFiles:')\n",
    "for f in transfermarkt_files:\n",
    "    print(f'  - {f.name}')\n",
    "\n",
    "# Load and check format of first file\n",
    "if transfermarkt_files:\n",
    "    sample_file = transfermarkt_files[0]\n",
    "    df_sample = pd.read_csv(sample_file)\n",
    "    \n",
    "    print(f'\\n‚úÖ Sample file: {sample_file.name}')\n",
    "    print(f'  Columns: {list(df_sample.columns)}')\n",
    "    print(f'  Shape: {df_sample.shape}')\n",
    "    print(f'\\nFirst 5 rows:')\n",
    "    display(df_sample.head())\n",
    "    \n",
    "    # Check for any missing data\n",
    "    print(f'\\nData quality check:')\n",
    "    print(f'  Missing home teams: {df_sample[\"home\"].isna().sum()}')\n",
    "    print(f'  Missing away teams: {df_sample[\"away\"].isna().sum()}')\n",
    "    print(f'  Missing scores: {df_sample[\"score\"].isna().sum()}')\n",
    "\n",
    "# Compare with Wikipedia format\n",
    "wiki_files = sorted(DATA_DIR.glob('matches_*_ligat_haal_wikipedia.csv'))\n",
    "if wiki_files:\n",
    "    wiki_sample = pd.read_csv(wiki_files[0])\n",
    "    print(f'\\n‚úÖ Wikipedia sample: {wiki_files[0].name}')\n",
    "    print(f'  Columns: {list(wiki_sample.columns)}')\n",
    "    print(f'\\nFirst 3 rows:')\n",
    "    display(wiki_sample.head(3))\n",
    "    \n",
    "    print('\\n‚úÖ Format comparison:')\n",
    "    print(f'  Transfermarkt columns: {list(df_sample.columns)}')\n",
    "    print(f'  Wikipedia columns: {list(wiki_sample.columns)}')\n",
    "    print(f'  Match: {list(df_sample.columns) == list(wiki_sample.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e59962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ TRANSFERMARKT SCRAPING COMPLETE ‚úÖ\n",
      "================================================================================\n",
      "\n",
      "Successfully scraped 20 seasons from Transfermarkt\n",
      "Seasons: 2006/07 to 2025/26\n",
      "Format: round, home, score, away (same as Wikipedia)\n",
      "\n",
      "‚úÖ Season Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Rounds</th>\n",
       "      <th>Teams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007/08</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008/09</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009/10</td>\n",
       "      <td>240</td>\n",
       "      <td>240</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010/11</td>\n",
       "      <td>240</td>\n",
       "      <td>240</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2011/12</td>\n",
       "      <td>240</td>\n",
       "      <td>240</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2012/13</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013/14</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2014/15</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015/16</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2016/17</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017/18</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018/19</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019/20</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020/21</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2021/22</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2022/23</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2024/25</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2025/26</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Season  Matches  Rounds  Teams\n",
       "0   2006/07      198     198     12\n",
       "1   2007/08      198     198     12\n",
       "2   2008/09      198     198     12\n",
       "3   2009/10      240     240     16\n",
       "4   2010/11      240     240     16\n",
       "5   2011/12      240     240     16\n",
       "6   2012/13      182     182     14\n",
       "7   2013/14      182     182     14\n",
       "8   2014/15      182     182     14\n",
       "9   2015/16      182     182     14\n",
       "10  2016/17      182     182     14\n",
       "11  2017/18      182     182     14\n",
       "12  2018/19      182     182     14\n",
       "13  2019/20      182     182     14\n",
       "14  2020/21      182     182     14\n",
       "15  2021/22      182     182     14\n",
       "16  2022/23      182     182     14\n",
       "17  2023/24      182     182     14\n",
       "18  2024/25      182     182     14\n",
       "19  2025/26       69      69     14"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Total Statistics:\n",
      "  Total matches: 3749\n",
      "  Average matches per season: 187\n",
      "  Max rounds in a season: 240\n",
      "  Min rounds in a season: 69\n",
      "\n",
      "‚úÖ Data Location:\n",
      "  Directory: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\n",
      "  Files: matches_YYYY_YY_ligat_haal_transfermarkt.csv\n",
      "\n",
      "‚úÖ Next Steps:\n",
      "  - Data is ready for analysis\n",
      "  - Same format as Wikipedia data (round, home, score, away)\n",
      "  - Can be combined or analyzed separately\n",
      "  - Playoff data available in gesamtspielplan pages (Championship/Relegation rounds)\n"
     ]
    }
   ],
   "source": [
    "# Final Summary: All 20 Seasons from Transfermarkt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(ROOT) / 'data' / 'raw'\n",
    "transfermarkt_files = sorted(DATA_DIR.glob('matches_*_ligat_haal_transfermarkt.csv'))\n",
    "\n",
    "print('‚úÖ TRANSFERMARKT SCRAPING COMPLETE \\u2705')\n",
    "print('=' * 80)\n",
    "print(f'\\nSuccessfully scraped {len(transfermarkt_files)} seasons from Transfermarkt')\n",
    "print(f'Seasons: 2006/07 to 2025/26')\n",
    "print(f'Format: round, home, score, away (same as Wikipedia)')\n",
    "\n",
    "# Load all files and create summary\n",
    "all_data = []\n",
    "season_summary = []\n",
    "\n",
    "for csv_file in transfermarkt_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    season = csv_file.stem.split('_')[1:3]  # Extract season from filename\n",
    "    season_str = f\"{season[0]}/{season[1]}\"\n",
    "    \n",
    "    season_summary.append({\n",
    "        'Season': season_str,\n",
    "        'Matches': len(df),\n",
    "        'Rounds': df['round'].max(),\n",
    "        'Teams': len(set(df['home'].tolist() + df['away'].tolist()))\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(season_summary)\n",
    "\n",
    "print('\\n‚úÖ Season Summary:')\n",
    "display(summary_df)\n",
    "\n",
    "print(f'\\n‚úÖ Total Statistics:')\n",
    "print(f'  Total matches: {summary_df[\"Matches\"].sum()}')\n",
    "print(f'  Average matches per season: {summary_df[\"Matches\"].mean():.0f}')\n",
    "print(f'  Max rounds in a season: {summary_df[\"Rounds\"].max()}')\n",
    "print(f'  Min rounds in a season: {summary_df[\"Rounds\"].min()}')\n",
    "\n",
    "print('\\n‚úÖ Data Location:')\n",
    "print(f'  Directory: {DATA_DIR}')\n",
    "print(f'  Files: matches_YYYY_YY_ligat_haal_transfermarkt.csv')\n",
    "\n",
    "print('\\n‚úÖ Next Steps:')\n",
    "print('  - Data is ready for analysis')\n",
    "print('  - Same format as Wikipedia data (round, home, score, away)')\n",
    "print('  - Can be combined or analyzed separately')\n",
    "print('  - Playoff data available in gesamtspielplan pages (Championship/Relegation rounds)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc10741e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfermarkt Playoff Scraper (Restored) - outputs round, home, score, away\n",
    "import re, time, requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure ROOT and DATA_DIR exist\n",
    "try:\n",
    "    ROOT\n",
    "except NameError:\n",
    "    ROOT = Path.cwd()\n",
    "DATA_DIR = Path(ROOT) / 'data' / 'raw'\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "HEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}\n",
    "\n",
    "def http_get(url, retries=3, sleep=1.5):\n",
    "    for attempt in range(1, retries+1):\n",
    "        try:\n",
    "            resp = requests.get(url, headers=HEADERS, timeout=20)\n",
    "            if resp.status_code == 200:\n",
    "                return resp.text\n",
    "            else:\n",
    "                print(f\"HTTP {resp.status_code} for {url}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt} failed for {url}: {e}\")\n",
    "        time.sleep(sleep)\n",
    "    return ''\n",
    "\n",
    "def scrape_transfermarkt_playoffs(season_year):\n",
    "    season_tag = f\"{season_year}_{str(season_year+1)[-2:]}\"\n",
    "    out_csv = DATA_DIR / f\"matches_{season_tag}_ligat_haal_transfermarkt_playoffs.csv\"\n",
    "    base_url = f\"https://www.transfermarkt.com/ligat-haal/gesamtspielplan/wettbewerb/ISR1?saison_id={season_year}\"\n",
    "    # Note: League playoffs are included in gesamtspielplan as separate sections (e.g., Championship Round)\n",
    "    html = http_get(base_url)\n",
    "    if not html:\n",
    "        print(f\"‚ùå No HTML for playoffs {season_year}\")\n",
    "        return None\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    rows_out = []\n",
    "    playoff_round = 0\n",
    "    for box in soup.select('div.box'):\n",
    "        h2 = box.select_one('h2, h3')\n",
    "        if not h2:\n",
    "            continue\n",
    "        title = h2.get_text(strip=True)\n",
    "        # Identify playoff sections by keywords\n",
    "        if not re.search(r'Championship|Relegation|Play-?off|Upper|Lower', title, re.IGNORECASE):\n",
    "            continue\n",
    "        table = box.select_one('table.items') or box.select_one('table')\n",
    "        if not table:\n",
    "            continue\n",
    "        for tr in table.select('tbody tr'):\n",
    "            tds = tr.find_all('td')\n",
    "            if len(tds) < 5:\n",
    "                continue\n",
    "            home_a = tr.select_one('td.verein-heim a, td.heim a, td:nth-of-type(2) a[href*=\"/verein/\"]')\n",
    "            away_a = tr.select_one('td.verein-gast a, td.gast a, td:nth-of-type(6) a[href*=\"/verein/\"]')\n",
    "            if not home_a or not away_a:\n",
    "                team_links = [a for a in tr.select('a[href*=\"/verein/\"]') if a.get_text(strip=True)]\n",
    "                if len(team_links) >= 2:\n",
    "                    home_a, away_a = team_links[0], team_links[1]\n",
    "                else:\n",
    "                    continue\n",
    "            home = home_a.get_text(strip=True)\n",
    "            away = away_a.get_text(strip=True)\n",
    "            score_cell = tr.select_one('td.ergebnis a, td.ergebnis, td:nth-of-type(5)')\n",
    "            score_txt = score_cell.get_text(\" \", strip=True) if score_cell else ''\n",
    "            mscore = re.search(r'(\\d+\\s*:\\s*\\d+)', score_txt)\n",
    "            score = mscore.group(1).replace(' ','') if mscore else ''\n",
    "            if not score:\n",
    "                continue\n",
    "            playoff_round += 1\n",
    "            rows_out.append({'round': playoff_round, 'home': home, 'score': score, 'away': away})\n",
    "    if not rows_out:\n",
    "        print(f\"‚ö†Ô∏è No playoff matches parsed for {season_year}\")\n",
    "        return None\n",
    "    df = pd.DataFrame(rows_out)\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(f\"‚úÖ Saved {len(df)} playoff matches -> {out_csv.name}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83b20854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular season scraper updated with fixed team extraction.\n"
     ]
    }
   ],
   "source": [
    "# Transfermarkt Regular Season Scraper (Fixed) - outputs Wikipedia-style columns: round, home, score, away\n",
    "import re, time, requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure ROOT and DATA_DIR exist\n",
    "try:\n",
    "    ROOT\n",
    "except NameError:\n",
    "    ROOT = Path.cwd()\n",
    "DATA_DIR = Path(ROOT) / 'data' / 'raw'\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "HEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}\n",
    "\n",
    "def http_get(url, retries=3, sleep=1.5):\n",
    "    for attempt in range(1, retries+1):\n",
    "        try:\n",
    "            resp = requests.get(url, headers=HEADERS, timeout=20)\n",
    "            if resp.status_code == 200:\n",
    "                return resp.text\n",
    "        except Exception as e:\n",
    "            if attempt == retries:\n",
    "                print(f\"Failed after {retries} attempts: {e}\")\n",
    "        if attempt < retries:\n",
    "            time.sleep(sleep)\n",
    "    return ''\n",
    "\n",
    "def scrape_transfermarkt_regular(season_year):\n",
    "    \"\"\"Scrape regular season matches from Transfermarkt gesamtspielplan page.\"\"\"\n",
    "    season_tag = f\"{season_year}_{str(season_year+1)[-2:]}\"\n",
    "    out_csv = DATA_DIR / f\"matches_{season_tag}_ligat_haal_transfermarkt.csv\"\n",
    "    \n",
    "    url = f\"https://www.transfermarkt.com/ligat-haal/gesamtspielplan/wettbewerb/ISR1?saison_id={season_year}\"\n",
    "    html = http_get(url)\n",
    "    if not html:\n",
    "        print(f\"‚ùå No HTML for season {season_year}\")\n",
    "        return None\n",
    "    \n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    rows_out = []\n",
    "    round_num = 0\n",
    "    \n",
    "    # Find all tables on the page\n",
    "    tables = soup.find_all('table')\n",
    "    \n",
    "    for table in tables:\n",
    "        # Look for match rows (rows with 2 team links)\n",
    "        for tr in table.find_all('tr'):\n",
    "            # Find all cells\n",
    "            cells = tr.find_all('td')\n",
    "            if len(cells) < 5:\n",
    "                continue\n",
    "            \n",
    "            # Find score first to confirm this is a match row\n",
    "            score_link = tr.find('a', class_='ergebnis-link')\n",
    "            if not score_link:\n",
    "                continue\n",
    "            \n",
    "            score_text = score_link.get_text(strip=True)\n",
    "            # Validate score format (d:d)\n",
    "            if not re.match(r'^\\d+:\\d+$', score_text):\n",
    "                continue\n",
    "            \n",
    "            # Now find team links - typically in cells before and after score\n",
    "            all_team_links = []\n",
    "            for cell in cells:\n",
    "                team_link = cell.find('a', href=re.compile(r'/verein/'))\n",
    "                if team_link:\n",
    "                    team_name = team_link.get_text(strip=True)\n",
    "                    if team_name and team_name not in [link.get_text(strip=True) for link in all_team_links]:\n",
    "                        all_team_links.append(team_link)\n",
    "            \n",
    "            if len(all_team_links) < 2:\n",
    "                continue\n",
    "            \n",
    "            home = all_team_links[0].get_text(strip=True)\n",
    "            away = all_team_links[1].get_text(strip=True)\n",
    "            \n",
    "            # Increment round for each match found\n",
    "            round_num += 1\n",
    "            \n",
    "            rows_out.append({\n",
    "                'round': round_num,\n",
    "                'home': home,\n",
    "                'score': score_text,\n",
    "                'away': away\n",
    "            })\n",
    "    \n",
    "    if not rows_out:\n",
    "        print(f\"‚ö†Ô∏è No matches parsed for {season_year}\")\n",
    "        return None\n",
    "    \n",
    "    df = pd.DataFrame(rows_out)\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(f\"‚úÖ Saved {len(df)} matches -> {out_csv.name}\")\n",
    "    return df\n",
    "\n",
    "print('Regular season scraper updated with fixed team extraction.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eab7b13",
   "metadata": {},
   "source": [
    "## Validation: Test All Transfermarkt Scrapers\n",
    "\n",
    "Now that the scraper functions are defined, let's validate them by scraping all 20 seasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad08dd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run restored Transfermarkt scrapers for all seasons and validate coverage\n",
    "seasons = list(range(2006, 2026))\n",
    "regular_counts = {}\n",
    "playoff_counts = {}\n",
    "\n",
    "for sy in seasons:\n",
    "    r = scrape_transfermarkt_regular(sy)\n",
    "    if r is not None:\n",
    "        regular_counts[sy] = len(r)\n",
    "    \n",
    "    p = scrape_transfermarkt_playoffs(sy)\n",
    "    if p is not None:\n",
    "        playoff_counts[sy] = len(p)\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('VALIDATION SUMMARY')\n",
    "print('='*80)\n",
    "print(f'Regular seasons scraped: {len(regular_counts)}')\n",
    "print(f'Playoff seasons scraped: {len(playoff_counts)}')\n",
    "\n",
    "import pandas as pd\n",
    "summary_df = pd.DataFrame({\n",
    "    'season_year': list(regular_counts.keys()), \n",
    "    'regular_matches': list(regular_counts.values())\n",
    "}).sort_values('season_year')\n",
    "\n",
    "print('\\nDetailed breakdown:')\n",
    "display(summary_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
