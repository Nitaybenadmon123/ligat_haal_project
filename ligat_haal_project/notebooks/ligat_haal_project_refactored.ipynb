{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3205b0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Environment setup complete\n",
      "   ROOT: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\n",
      "   DATA_DIR: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\n"
     ]
    }
   ],
   "source": [
    "# Environment setup (API-Sports removed)\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    DOTENV_AVAILABLE = True\n",
    "except Exception:\n",
    "    DOTENV_AVAILABLE = False\n",
    "\n",
    "# Feature flags (only Wikipedia + Transfermarkt pipeline)\n",
    "USE_APISPORTS = False  # deprecated; kept for compatibility but not used\n",
    "\n",
    "# Helper to find project root\n",
    "def _find_root(start: Optional[Path] = None) -> Path:\n",
    "    p = start or Path.cwd()\n",
    "    for _ in range(6):\n",
    "        if (p / 'data').exists() or (p / '.git').exists() or (p / 'notebooks').exists():\n",
    "            return p\n",
    "        p = p.parent\n",
    "    return Path.cwd()\n",
    "\n",
    "# Resolve project directories consistently\n",
    "ROOT = _find_root()\n",
    "DATA_DIR = ROOT / 'data' / 'raw'\n",
    "INTERIM_DIR = ROOT / 'data' / 'interim'\n",
    "PROCESSED_DIR = ROOT / 'data' / 'processed'\n",
    "FIG_DIR = ROOT / 'reports' / 'figures'\n",
    "for d in [DATA_DIR, INTERIM_DIR, PROCESSED_DIR, FIG_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"\\nüéØ Environment setup complete\")\n",
    "print(f\"   ROOT: {ROOT}\")\n",
    "print(f\"   DATA_DIR: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50cbcf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\.venv\\Lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Helpers to make the notebook resilient across machines (kept)\n",
    "from typing import Optional\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "_USER_AGENTS = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0 Safari/537.36\",\n",
    "]\n",
    "\n",
    "def find_repo_root(start: Optional[Path] = None) -> Path:\n",
    "    p = start or Path.cwd()\n",
    "    for _ in range(6):\n",
    "        if (p / 'data').exists() or (p / '.git').exists() or (p / 'notebooks').exists():\n",
    "            return p\n",
    "        p = p.parent\n",
    "    return Path.cwd()\n",
    "\n",
    "def ensure_environment():\n",
    "    global ROOT, DATA_DIR, INTERIM_DIR, PROCESSED_DIR, FIG_DIR\n",
    "    if 'ROOT' not in globals() or not isinstance(ROOT, Path) or not (ROOT / 'data').exists():\n",
    "        root_guess = find_repo_root(Path.cwd())\n",
    "        if not (root_guess / 'data').exists() and (root_guess.parent / 'data').exists():\n",
    "            root_guess = root_guess.parent\n",
    "        ROOT = root_guess\n",
    "    DATA_DIR = ROOT / 'data' / 'raw'\n",
    "    INTERIM_DIR = ROOT / 'data' / 'interim'\n",
    "    PROCESSED_DIR = ROOT / 'data' / 'processed'\n",
    "    FIG_DIR = ROOT / 'reports' / 'figures'\n",
    "    for d in [DATA_DIR, INTERIM_DIR, PROCESSED_DIR, FIG_DIR]:\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "    return ROOT, DATA_DIR, INTERIM_DIR, PROCESSED_DIR, FIG_DIR\n",
    "\n",
    "\n",
    "def http_get(url: str, headers: Optional[dict] = None, retries: int = 3, timeout: int = 30) -> str:\n",
    "    last_err = None\n",
    "    sess = requests.Session()\n",
    "    for attempt in range(1, retries + 1):\n",
    "        ua = random.choice(_USER_AGENTS)\n",
    "        hdrs = {\"User-Agent\": ua, \"Accept-Language\": \"en-US,en;q=0.9\"}\n",
    "        if headers:\n",
    "            hdrs.update(headers)\n",
    "        try:\n",
    "            resp = sess.get(url, headers=hdrs, timeout=timeout)\n",
    "            resp.raise_for_status()\n",
    "            return resp.text\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            time.sleep(0.8 * attempt)\n",
    "    raise last_err  # type: ignore\n",
    "\n",
    "\n",
    "def save_csv(df: 'pd.DataFrame', path: Path, **to_csv_kwargs):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(path, index=False, encoding=to_csv_kwargs.get('encoding', 'utf-8-sig'))\n",
    "    print(f\"Saved: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c089fed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping 20 seasons from Wikipedia (2006/07 to 2025/26)...\n",
      "Fetching 2006/07... ‚úì (132 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2006_07_ligat_haal_wikipedia.csv\n",
      "Fetching 2007/08... ‚úì (132 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2007_08_ligat_haal_wikipedia.csv\n",
      "Fetching 2008/09... ‚úì (132 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2008_09_ligat_haal_wikipedia.csv\n",
      "Fetching 2009/10... ‚úì (239 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2009_10_ligat_haal_wikipedia.csv\n",
      "Fetching 2010/11... ‚úì (234 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2010_11_ligat_haal_wikipedia.csv\n",
      "Fetching 2011/12... ‚úì (240 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2011_12_ligat_haal_wikipedia.csv\n",
      "Fetching 2012/13... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2012_13_ligat_haal_wikipedia.csv\n",
      "Fetching 2013/14... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2013_14_ligat_haal_wikipedia.csv\n",
      "Fetching 2014/15... ‚úì (181 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2014_15_ligat_haal_wikipedia.csv\n",
      "Fetching 2015/16... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2015_16_ligat_haal_wikipedia.csv\n",
      "Fetching 2016/17... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2016_17_ligat_haal_wikipedia.csv\n",
      "Fetching 2017/18... ‚úì (181 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2017_18_ligat_haal_wikipedia.csv\n",
      "Fetching 2018/19... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2018_19_ligat_haal_wikipedia.csv\n",
      "Fetching 2019/20... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2019_20_ligat_haal_wikipedia.csv\n",
      "Fetching 2020/21... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2020_21_ligat_haal_wikipedia.csv\n",
      "Fetching 2021/22... ‚úì (181 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2021_22_ligat_haal_wikipedia.csv\n",
      "Fetching 2022/23... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2022_23_ligat_haal_wikipedia.csv\n",
      "Fetching 2023/24... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2023_24_ligat_haal_wikipedia.csv\n",
      "Fetching 2024/25... ‚úì (179 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2024_25_ligat_haal_wikipedia.csv\n",
      "Fetching 2025/26... ‚úì (64 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2025_26_ligat_haal_wikipedia.csv\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_all_seasons_ligat_haal_wikipedia.csv\n",
      "\n",
      "Summary:\n",
      "- Successfully scraped 20 seasons\n",
      "- Total matches: 3533\n",
      "\n",
      "Matches per season:\n",
      "  ‚Ä¢ 2006/07: 132 matches\n",
      "  ‚Ä¢ 2007/08: 132 matches\n",
      "  ‚Ä¢ 2008/09: 132 matches\n",
      "  ‚Ä¢ 2009/10: 239 matches\n",
      "  ‚Ä¢ 2010/11: 234 matches\n",
      "  ‚Ä¢ 2011/12: 240 matches\n",
      "  ‚Ä¢ 2012/13: 182 matches\n",
      "  ‚Ä¢ 2013/14: 182 matches\n",
      "  ‚Ä¢ 2014/15: 181 matches\n",
      "  ‚Ä¢ 2015/16: 182 matches\n",
      "  ‚Ä¢ 2016/17: 182 matches\n",
      "  ‚Ä¢ 2017/18: 181 matches\n",
      "  ‚Ä¢ 2018/19: 182 matches\n",
      "  ‚Ä¢ 2019/20: 182 matches\n",
      "  ‚Ä¢ 2020/21: 182 matches\n",
      "  ‚Ä¢ 2021/22: 181 matches\n",
      "  ‚Ä¢ 2022/23: 182 matches\n",
      "  ‚Ä¢ 2023/24: 182 matches\n",
      "  ‚Ä¢ 2024/25: 179 matches\n",
      "  ‚Ä¢ 2025/26:  64 matches\n",
      "\n",
      "All matches saved to: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_all_seasons_ligat_haal_wikipedia.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>season_year</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>home_goals</th>\n",
       "      <th>away_goals</th>\n",
       "      <th>goal_diff</th>\n",
       "      <th>result</th>\n",
       "      <th>home_points</th>\n",
       "      <th>away_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>2006</td>\n",
       "      <td>Beitar Jerusalem</td>\n",
       "      <td>BnY</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>2006</td>\n",
       "      <td>Beitar Jerusalem</td>\n",
       "      <td>ASH</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>H</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>2006</td>\n",
       "      <td>Beitar Jerusalem</td>\n",
       "      <td>HAK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>2006</td>\n",
       "      <td>Beitar Jerusalem</td>\n",
       "      <td>HKS</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>H</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>2006</td>\n",
       "      <td>Beitar Jerusalem</td>\n",
       "      <td>HPT</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>H</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    season  season_year         home_team away_team  home_goals  away_goals  \\\n",
       "0  2006/07         2006  Beitar Jerusalem       BnY           0           0   \n",
       "1  2006/07         2006  Beitar Jerusalem       ASH           2           0   \n",
       "2  2006/07         2006  Beitar Jerusalem       HAK           0           0   \n",
       "3  2006/07         2006  Beitar Jerusalem       HKS           2           0   \n",
       "4  2006/07         2006  Beitar Jerusalem       HPT           2           0   \n",
       "\n",
       "   goal_diff result  home_points  away_points  \n",
       "0          0      D            1            1  \n",
       "1          2      H            3            0  \n",
       "2          0      D            1            1  \n",
       "3          2      H            3            0  \n",
       "4          2      H            3            0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scrape multiple seasons of Ligat Ha'al from Wikipedia\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "ensure_environment()\n",
    "\n",
    "def scrape_season(season_year):\n",
    "    \"\"\"\n",
    "    Scrape a single season's matches from Wikipedia.\n",
    "    season_year: starting year (e.g., 2016 for 2016/17 season)\n",
    "    \"\"\"\n",
    "    season_str = f\"{season_year}/{str(season_year+1)[-2:]}\"\n",
    "    url = f\"https://en.wikipedia.org/wiki/{season_year}%E2%80%93{str(season_year+1)[-2:]}_Israeli_Premier_League\"\n",
    "    \n",
    "    print(f\"Fetching {season_str}... \", end=\"\", flush=True)\n",
    "    try:\n",
    "        html = http_get(url)\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "        \n",
    "        # Find results matrix\n",
    "        results_table = None\n",
    "        for table in soup.find_all(\"table\", class_=\"wikitable\"):\n",
    "            first_row = table.find(\"tr\")\n",
    "            if first_row:\n",
    "                first_cell = first_row.find(\"th\")\n",
    "                if first_cell and (\"Home \\\\ Away\" in first_cell.text or \"Home / Away\" in first_cell.text):\n",
    "                    results_table = table\n",
    "                    break\n",
    "        \n",
    "        if not results_table:\n",
    "            print(\"‚ùå (no results matrix)\")\n",
    "            return None\n",
    "            \n",
    "        # Parse teams and build matches\n",
    "        rows = results_table.find_all(\"tr\")\n",
    "        team_names = [td.get_text(strip=True) for td in rows[0].find_all(\"th\")][1:]\n",
    "        \n",
    "        matches = []\n",
    "        for i, row in enumerate(rows[1:]):\n",
    "            cells = row.find_all([\"th\", \"td\"])\n",
    "            home_team = cells[0].get_text(strip=True)\n",
    "            for j, cell in enumerate(cells[1:]):\n",
    "                away_team = team_names[j]\n",
    "                score = cell.get_text(strip=True)\n",
    "                if re.match(r\"^\\d+\\s*[‚Äì-]\\s*\\d+$\", score):\n",
    "                    home_goals, away_goals = re.split(r\"[‚Äì-]\", score)\n",
    "                    matches.append({\n",
    "                        \"season\": season_str,\n",
    "                        \"season_year\": season_year,\n",
    "                        \"home_team\": home_team,\n",
    "                        \"away_team\": away_team,\n",
    "                        \"home_goals\": int(home_goals.strip()),\n",
    "                        \"away_goals\": int(away_goals.strip())\n",
    "                    })\n",
    "        \n",
    "        if not matches:\n",
    "            print(\"‚ùå (no matches found)\")\n",
    "            return None\n",
    "            \n",
    "        # Convert to DataFrame and add derived columns\n",
    "        df = pd.DataFrame(matches)\n",
    "        df['goal_diff'] = df['home_goals'] - df['away_goals']\n",
    "        df['result'] = df['goal_diff'].apply(lambda x: \"H\" if x>0 else (\"A\" if x<0 else \"D\"))\n",
    "        df['home_points'] = df['result'].map({\"H\":3, \"D\":1, \"A\":0}).fillna(0).astype(int)\n",
    "        df['away_points'] = df['result'].map({\"A\":3, \"D\":1, \"H\":0}).fillna(0).astype(int)\n",
    "        \n",
    "        # Select and order columns\n",
    "        keep_cols = ['season', 'season_year', 'home_team', 'away_team', 'home_goals', \n",
    "                     'away_goals', 'goal_diff', 'result', 'home_points', 'away_points']\n",
    "        df = df[keep_cols]\n",
    "        \n",
    "        print(f\"‚úì ({len(df)} matches)\")\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ({str(e)[:50]}...)\")\n",
    "        return None\n",
    "\n",
    "# List of seasons to scrape (last 20 seasons)\n",
    "current_year = datetime.now().year\n",
    "if datetime.now().month < 8:  # If before August, last season started in previous year\n",
    "    current_year -= 1\n",
    "seasons = list(range(current_year - 19, current_year + 1))\n",
    "\n",
    "print(f\"Scraping {len(seasons)} seasons from Wikipedia ({seasons[0]}/{str(seasons[0]+1)[-2:]} to {seasons[-1]}/{str(seasons[-1]+1)[-2:]})...\")\n",
    "\n",
    "# Scrape each season\n",
    "all_matches = []\n",
    "for season_year in seasons:\n",
    "    df = scrape_season(season_year)\n",
    "    if df is not None:\n",
    "        # Save individual season\n",
    "        season_path = DATA_DIR / f\"matches_{season_year}_{str(season_year+1)[-2:]}_ligat_haal_wikipedia.csv\"\n",
    "        save_csv(df, season_path)\n",
    "        all_matches.append(df)\n",
    "    time.sleep(1)  # Be nice to Wikipedia\n",
    "\n",
    "if all_matches:\n",
    "    # Combine all seasons\n",
    "    combined_df = pd.concat(all_matches, ignore_index=True)\n",
    "    combined_path = DATA_DIR / \"matches_all_seasons_ligat_haal_wikipedia.csv\"\n",
    "    save_csv(combined_df, combined_path)\n",
    "    \n",
    "    print(\"\\nSummary:\")\n",
    "    print(f\"- Successfully scraped {len(all_matches)} seasons\")\n",
    "    print(f\"- Total matches: {len(combined_df)}\")\n",
    "    print(f\"\\nMatches per season:\")\n",
    "    season_counts = combined_df.groupby('season').size().sort_index()\n",
    "    for season, count in season_counts.items():\n",
    "        print(f\"  ‚Ä¢ {season}: {count:3d} matches\")\n",
    "    print(f\"\\nAll matches saved to: {combined_path}\")\n",
    "    display(combined_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7954400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping attendance from: https://www.transfermarkt.com/ligat-haal/besucherzahlen/wettbewerb/ISR1/saison_id/2023\n",
      "  ‚úÖ Scraped 14 teams for 2023/24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>team</th>\n",
       "      <th>stadium</th>\n",
       "      <th>capacity</th>\n",
       "      <th>total_spectators</th>\n",
       "      <th>average_attendance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Maccabi Tel Aviv</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>29150</td>\n",
       "      <td>213565</td>\n",
       "      <td>17797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Maccabi Haifa</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>30780</td>\n",
       "      <td>171948</td>\n",
       "      <td>17195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Beitar Jerusalem</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>33500</td>\n",
       "      <td>144830</td>\n",
       "      <td>13166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Hapoel Beer Sheva</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>16126</td>\n",
       "      <td>122024</td>\n",
       "      <td>10169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Hapoel Tel Aviv</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>29150</td>\n",
       "      <td>101049</td>\n",
       "      <td>9186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Maccabi Netanya</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>13610</td>\n",
       "      <td>70127</td>\n",
       "      <td>5844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Hapoel Petah Tikva</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>11500</td>\n",
       "      <td>60759</td>\n",
       "      <td>5524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Hapoel Haifa</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>30820</td>\n",
       "      <td>42559</td>\n",
       "      <td>3869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Hapoel Jerusalem</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>33500</td>\n",
       "      <td>40070</td>\n",
       "      <td>3643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Maccabi Petah Tikva</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>11500</td>\n",
       "      <td>39337</td>\n",
       "      <td>3576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Hapoel Hadera</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>3000</td>\n",
       "      <td>34207</td>\n",
       "      <td>3421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Ihud Bnei Sakhnin</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>8500</td>\n",
       "      <td>24984</td>\n",
       "      <td>2271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Maccabi Bnei Reineh</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>5200</td>\n",
       "      <td>19400</td>\n",
       "      <td>1940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>FC Ashdod</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>8200</td>\n",
       "      <td>16713</td>\n",
       "      <td>2089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     season                 team  stadium  capacity  total_spectators  \\\n",
       "0   2023/24     Maccabi Tel Aviv  Unknown     29150            213565   \n",
       "1   2023/24        Maccabi Haifa  Unknown     30780            171948   \n",
       "2   2023/24     Beitar Jerusalem  Unknown     33500            144830   \n",
       "3   2023/24    Hapoel Beer Sheva  Unknown     16126            122024   \n",
       "4   2023/24      Hapoel Tel Aviv  Unknown     29150            101049   \n",
       "5   2023/24      Maccabi Netanya  Unknown     13610             70127   \n",
       "6   2023/24   Hapoel Petah Tikva  Unknown     11500             60759   \n",
       "7   2023/24         Hapoel Haifa  Unknown     30820             42559   \n",
       "8   2023/24     Hapoel Jerusalem  Unknown     33500             40070   \n",
       "9   2023/24  Maccabi Petah Tikva  Unknown     11500             39337   \n",
       "10  2023/24        Hapoel Hadera  Unknown      3000             34207   \n",
       "11  2023/24    Ihud Bnei Sakhnin  Unknown      8500             24984   \n",
       "12  2023/24  Maccabi Bnei Reineh  Unknown      5200             19400   \n",
       "13  2023/24            FC Ashdod  Unknown      8200             16713   \n",
       "\n",
       "    average_attendance  \n",
       "0                17797  \n",
       "1                17195  \n",
       "2                13166  \n",
       "3                10169  \n",
       "4                 9186  \n",
       "5                 5844  \n",
       "6                 5524  \n",
       "7                 3869  \n",
       "8                 3643  \n",
       "9                 3576  \n",
       "10                3421  \n",
       "11                2271  \n",
       "12                1940  \n",
       "13                2089  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def scrape_transfermarkt_attendance(season_year: int) -> 'pd.DataFrame':\n",
    "    \"\"\"\n",
    "    Scrape team attendance data from Transfermarkt for a given season.\n",
    "    \n",
    "    Args:\n",
    "        season_year: Starting year of season (e.g., 2023 for 2023/24)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with columns: season, team, stadium, capacity, total_spectators, average_attendance\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "    \n",
    "    url = f\"https://www.transfermarkt.com/ligat-haal/besucherzahlen/wettbewerb/ISR1/saison_id/{season_year}\"\n",
    "    print(f\"Scraping attendance from: {url}\")\n",
    "    \n",
    "    try:\n",
    "        html = http_get(url)\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        \n",
    "        # Find the attendance table\n",
    "        tables = soup.find_all(\"table\", class_=\"items\")\n",
    "        if not tables:\n",
    "            print(f\"  ‚ö†Ô∏è  No attendance tables found for {season_year}/{str(season_year+1)[-2:]}\")\n",
    "            return None\n",
    "        \n",
    "        table = tables[0]\n",
    "        tbody = table.find(\"tbody\")\n",
    "        if not tbody:\n",
    "            print(f\"  ‚ö†Ô∏è  No tbody found in attendance table for {season_year}/{str(season_year+1)[-2:]}\")\n",
    "            return None\n",
    "        \n",
    "        rows = tbody.find_all(\"tr\", recursive=False)\n",
    "        \n",
    "        attendance_data = []\n",
    "        season_str = f\"{season_year}/{str(season_year+1)[-2:]}\"\n",
    "        \n",
    "        for row in rows:\n",
    "            cells = row.find_all(\"td\")\n",
    "            if len(cells) < 5:\n",
    "                continue\n",
    "            \n",
    "            # First cell is rank (skip \"Total\" row)\n",
    "            rank_text = cells[0].get_text(strip=True)\n",
    "            if not rank_text.isdigit():\n",
    "                continue\n",
    "            \n",
    "            # Second cell contains inline table with stadium and team info\n",
    "            inline_table = cells[1].find(\"table\", class_=\"inline-table\")\n",
    "            if not inline_table:\n",
    "                continue\n",
    "            \n",
    "            # Extract stadium name (first link in inline table)\n",
    "            stadium_link = inline_table.find(\"a\", class_=\"hauptlink\")\n",
    "            stadium = stadium_link.get_text(strip=True) if stadium_link else \"Unknown\"\n",
    "            \n",
    "            # Extract team name (second row of inline table)\n",
    "            team_links = inline_table.find_all(\"a\", title=True)\n",
    "            team = \"Unknown\"\n",
    "            for link in team_links:\n",
    "                title = link.get(\"title\", \"\")\n",
    "                if title and \"spielplan\" in link.get(\"href\", \"\"):\n",
    "                    team = title\n",
    "                    break\n",
    "            \n",
    "            # Extract capacity, total spectators, average (last 3 cells)\n",
    "            # Note: Numbers use European format (dots for thousands)\n",
    "            capacity_text = cells[-3].get_text(strip=True)\n",
    "            total_text = cells[-2].get_text(strip=True)\n",
    "            average_text = cells[-1].get_text(strip=True)\n",
    "            \n",
    "            # Convert European number format (remove dots, handle empty values)\n",
    "            def parse_number(text):\n",
    "                if not text or text == \"-\":\n",
    "                    return None\n",
    "                return int(text.replace(\".\", \"\").replace(\",\", \"\"))\n",
    "            \n",
    "            capacity = parse_number(capacity_text)\n",
    "            total_spectators = parse_number(total_text)\n",
    "            average_attendance = parse_number(average_text)\n",
    "            \n",
    "            attendance_data.append({\n",
    "                \"season\": season_str,\n",
    "                \"team\": team,\n",
    "                \"stadium\": stadium,\n",
    "                \"capacity\": capacity,\n",
    "                \"total_spectators\": total_spectators,\n",
    "                \"average_attendance\": average_attendance\n",
    "            })\n",
    "        \n",
    "        if not attendance_data:\n",
    "            print(f\"  ‚ö†Ô∏è  No attendance data extracted for {season_year}/{str(season_year+1)[-2:]}\")\n",
    "            return None\n",
    "        \n",
    "        df = pd.DataFrame(attendance_data)\n",
    "        print(f\"  ‚úÖ Scraped {len(df)} teams for {season_str}\")\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Error scraping {season_year}/{str(season_year+1)[-2:]}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test the function\n",
    "ensure_environment()\n",
    "test_df = scrape_transfermarkt_attendance(2023)\n",
    "if test_df is not None:\n",
    "    display(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3922c964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping attendance from: https://www.transfermarkt.com/ligat-haal/besucherzahlen/wettbewerb/ISR1/saison_id/2023\n",
      "  ‚úÖ Scraped 14 teams for 2023/24\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\attendance_2023_24_ligat_haal_transfermarkt.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>team</th>\n",
       "      <th>stadium</th>\n",
       "      <th>capacity</th>\n",
       "      <th>total_spectators</th>\n",
       "      <th>average_attendance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Maccabi Tel Aviv</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>29150</td>\n",
       "      <td>213565</td>\n",
       "      <td>17797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Maccabi Haifa</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>30780</td>\n",
       "      <td>171948</td>\n",
       "      <td>17195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Beitar Jerusalem</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>33500</td>\n",
       "      <td>144830</td>\n",
       "      <td>13166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Hapoel Beer Sheva</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>16126</td>\n",
       "      <td>122024</td>\n",
       "      <td>10169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Hapoel Tel Aviv</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>29150</td>\n",
       "      <td>101049</td>\n",
       "      <td>9186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Maccabi Netanya</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>13610</td>\n",
       "      <td>70127</td>\n",
       "      <td>5844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Hapoel Petah Tikva</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>11500</td>\n",
       "      <td>60759</td>\n",
       "      <td>5524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Hapoel Haifa</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>30820</td>\n",
       "      <td>42559</td>\n",
       "      <td>3869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Hapoel Jerusalem</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>33500</td>\n",
       "      <td>40070</td>\n",
       "      <td>3643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Maccabi Petah Tikva</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>11500</td>\n",
       "      <td>39337</td>\n",
       "      <td>3576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Hapoel Hadera</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>3000</td>\n",
       "      <td>34207</td>\n",
       "      <td>3421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Ihud Bnei Sakhnin</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>8500</td>\n",
       "      <td>24984</td>\n",
       "      <td>2271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>Maccabi Bnei Reineh</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>5200</td>\n",
       "      <td>19400</td>\n",
       "      <td>1940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>FC Ashdod</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>8200</td>\n",
       "      <td>16713</td>\n",
       "      <td>2089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     season                 team  stadium  capacity  total_spectators  \\\n",
       "0   2023/24     Maccabi Tel Aviv  Unknown     29150            213565   \n",
       "1   2023/24        Maccabi Haifa  Unknown     30780            171948   \n",
       "2   2023/24     Beitar Jerusalem  Unknown     33500            144830   \n",
       "3   2023/24    Hapoel Beer Sheva  Unknown     16126            122024   \n",
       "4   2023/24      Hapoel Tel Aviv  Unknown     29150            101049   \n",
       "5   2023/24      Maccabi Netanya  Unknown     13610             70127   \n",
       "6   2023/24   Hapoel Petah Tikva  Unknown     11500             60759   \n",
       "7   2023/24         Hapoel Haifa  Unknown     30820             42559   \n",
       "8   2023/24     Hapoel Jerusalem  Unknown     33500             40070   \n",
       "9   2023/24  Maccabi Petah Tikva  Unknown     11500             39337   \n",
       "10  2023/24        Hapoel Hadera  Unknown      3000             34207   \n",
       "11  2023/24    Ihud Bnei Sakhnin  Unknown      8500             24984   \n",
       "12  2023/24  Maccabi Bnei Reineh  Unknown      5200             19400   \n",
       "13  2023/24            FC Ashdod  Unknown      8200             16713   \n",
       "\n",
       "    average_attendance  \n",
       "0                17797  \n",
       "1                17195  \n",
       "2                13166  \n",
       "3                10169  \n",
       "4                 9186  \n",
       "5                 5844  \n",
       "6                 5524  \n",
       "7                 3869  \n",
       "8                 3643  \n",
       "9                 3576  \n",
       "10                3421  \n",
       "11                2271  \n",
       "12                1940  \n",
       "13                2089  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Quick test: scrape 2023/24 season attendance\n",
    "ensure_environment()\n",
    "season_year = 2023\n",
    "_df_2023 = scrape_transfermarkt_attendance(season_year)\n",
    "if _df_2023 is not None:\n",
    "    _csv_2023 = DATA_DIR / f\"attendance_{season_year}_{str(season_year+1)[-2:]}_ligat_haal_transfermarkt.csv\"\n",
    "    save_csv(_df_2023, _csv_2023)\n",
    "    display(_df_2023.head(20))\n",
    "else:\n",
    "    print(\"Failed to scrape 2023/24 attendance from Transfermarkt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "345fde91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping attendance data for 20 seasons (2006/2007-2025/26)\n",
      "\n",
      "================================================================================\n",
      "\n",
      "[2006/07]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2006_07_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 12 teams\n",
      "\n",
      "[2007/08]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2007_08_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 12 teams\n",
      "\n",
      "[2008/09]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2008_09_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 12 teams\n",
      "\n",
      "[2009/10]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2009_10_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 16 teams\n",
      "\n",
      "[2010/11]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2010_11_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 16 teams\n",
      "\n",
      "[2011/12]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2011_12_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 16 teams\n",
      "\n",
      "[2012/13]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2012_13_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 14 teams\n",
      "\n",
      "[2013/14]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2013_14_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 14 teams\n",
      "\n",
      "[2014/15]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2014_15_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 14 teams\n",
      "\n",
      "[2015/16]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2015_16_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 14 teams\n",
      "\n",
      "[2016/17]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2016_17_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 14 teams\n",
      "\n",
      "[2017/18]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2017_18_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 14 teams\n",
      "\n",
      "[2018/19]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2018_19_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 14 teams\n",
      "\n",
      "[2019/20]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2019_20_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 14 teams\n",
      "\n",
      "[2020/21]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2020_21_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 14 teams\n",
      "\n",
      "[2021/22]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2021_22_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 14 teams\n",
      "\n",
      "[2022/23]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2022_23_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 14 teams\n",
      "\n",
      "[2023/24]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2023_24_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 14 teams\n",
      "\n",
      "[2024/25]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2024_25_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 14 teams\n",
      "\n",
      "[2025/26]\n",
      "  ‚ÑπÔ∏è  File already exists: attendance_2025_26_ligat_haal_transfermarkt.csv\n",
      "  ‚úÖ Loaded existing data: 14 teams\n",
      "\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Successfully scraped/loaded: 20 seasons\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\attendance_all_seasons_ligat_haal_transfermarkt.csv\n",
      "\n",
      "üìä Combined attendance data:\n",
      "   Total records: 280\n",
      "   Seasons: 20\n",
      "   Teams: 29\n",
      "\n",
      "   Saved to: attendance_all_seasons_ligat_haal_transfermarkt.csv\n",
      "\n",
      "   Season Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teams</th>\n",
       "      <th>Total Spectators</th>\n",
       "      <th>Avg Attendance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>season</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006/07</th>\n",
       "      <td>12</td>\n",
       "      <td>119700</td>\n",
       "      <td>3136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007/08</th>\n",
       "      <td>12</td>\n",
       "      <td>362600</td>\n",
       "      <td>5738.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008/09</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009/10</th>\n",
       "      <td>16</td>\n",
       "      <td>939155</td>\n",
       "      <td>3926.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010/11</th>\n",
       "      <td>16</td>\n",
       "      <td>318450</td>\n",
       "      <td>4867.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011/12</th>\n",
       "      <td>16</td>\n",
       "      <td>911780</td>\n",
       "      <td>3891.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012/13</th>\n",
       "      <td>14</td>\n",
       "      <td>916940</td>\n",
       "      <td>5038.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013/14</th>\n",
       "      <td>14</td>\n",
       "      <td>970781</td>\n",
       "      <td>5444.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014/15</th>\n",
       "      <td>14</td>\n",
       "      <td>935937</td>\n",
       "      <td>7630.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015/16</th>\n",
       "      <td>14</td>\n",
       "      <td>1247497</td>\n",
       "      <td>6854.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016/17</th>\n",
       "      <td>14</td>\n",
       "      <td>1139400</td>\n",
       "      <td>6261.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/18</th>\n",
       "      <td>14</td>\n",
       "      <td>1079479</td>\n",
       "      <td>6072.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018/19</th>\n",
       "      <td>14</td>\n",
       "      <td>1142281</td>\n",
       "      <td>6298.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019/20</th>\n",
       "      <td>14</td>\n",
       "      <td>1345409</td>\n",
       "      <td>7392.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020/21</th>\n",
       "      <td>14</td>\n",
       "      <td>24790</td>\n",
       "      <td>1771.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021/22</th>\n",
       "      <td>14</td>\n",
       "      <td>1313511</td>\n",
       "      <td>7267.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022/23</th>\n",
       "      <td>14</td>\n",
       "      <td>1533006</td>\n",
       "      <td>8654.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023/24</th>\n",
       "      <td>14</td>\n",
       "      <td>1101572</td>\n",
       "      <td>7121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024/25</th>\n",
       "      <td>14</td>\n",
       "      <td>1245045</td>\n",
       "      <td>7337.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025/26</th>\n",
       "      <td>14</td>\n",
       "      <td>618435</td>\n",
       "      <td>9971.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Teams  Total Spectators  Avg Attendance\n",
       "season                                          \n",
       "2006/07     12            119700          3136.0\n",
       "2007/08     12            362600          5738.0\n",
       "2008/09     12                 0             0.0\n",
       "2009/10     16            939155          3926.0\n",
       "2010/11     16            318450          4867.0\n",
       "2011/12     16            911780          3891.0\n",
       "2012/13     14            916940          5038.0\n",
       "2013/14     14            970781          5444.0\n",
       "2014/15     14            935937          7630.0\n",
       "2015/16     14           1247497          6854.0\n",
       "2016/17     14           1139400          6261.0\n",
       "2017/18     14           1079479          6072.0\n",
       "2018/19     14           1142281          6298.0\n",
       "2019/20     14           1345409          7392.0\n",
       "2020/21     14             24790          1771.0\n",
       "2021/22     14           1313511          7267.0\n",
       "2022/23     14           1533006          8654.0\n",
       "2023/24     14           1101572          7121.0\n",
       "2024/25     14           1245045          7337.0\n",
       "2025/26     14            618435          9971.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scrape attendance data for all 20 seasons (2006-2025)\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "ensure_environment()\n",
    "\n",
    "# Define seasons to scrape\n",
    "start_year = 2006\n",
    "end_year = 2025\n",
    "seasons = list(range(start_year, end_year + 1))\n",
    "\n",
    "print(f\"Scraping attendance data for {len(seasons)} seasons ({start_year}/{start_year+1}-{end_year}/{str(end_year+1)[-2:]})\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "all_attendance = []\n",
    "failed = []\n",
    "\n",
    "for season_year in seasons:\n",
    "    season_str = f\"{season_year}/{str(season_year+1)[-2:]}\"\n",
    "    print(f\"\\n[{season_str}]\")\n",
    "    \n",
    "    # Check if already exists\n",
    "    csv_path = DATA_DIR / f\"attendance_{season_year}_{str(season_year+1)[-2:]}_ligat_haal_transfermarkt.csv\"\n",
    "    if csv_path.exists():\n",
    "        print(f\"  ‚ÑπÔ∏è  File already exists: {csv_path.name}\")\n",
    "        try:\n",
    "            existing_df = pd.read_csv(csv_path)\n",
    "            all_attendance.append(existing_df)\n",
    "            print(f\"  ‚úÖ Loaded existing data: {len(existing_df)} teams\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è  Error loading existing file: {e}\")\n",
    "            # Try scraping anyway\n",
    "            df = scrape_transfermarkt_attendance(season_year)\n",
    "            if df is not None:\n",
    "                save_csv(df, csv_path)\n",
    "                all_attendance.append(df)\n",
    "            else:\n",
    "                failed.append(season_str)\n",
    "    else:\n",
    "        # Scrape new data\n",
    "        df = scrape_transfermarkt_attendance(season_year)\n",
    "        if df is not None:\n",
    "            save_csv(df, csv_path)\n",
    "            all_attendance.append(df)\n",
    "        else:\n",
    "            failed.append(season_str)\n",
    "        \n",
    "        # Be polite to the server\n",
    "        time.sleep(1.2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"\\n‚úÖ Successfully scraped/loaded: {len(all_attendance)} seasons\")\n",
    "if failed:\n",
    "    print(f\"‚ùå Failed: {len(failed)} seasons: {', '.join(failed)}\")\n",
    "\n",
    "# Combine all data\n",
    "if all_attendance:\n",
    "    combined_attendance = pd.concat(all_attendance, ignore_index=True)\n",
    "    combined_path = DATA_DIR / \"attendance_all_seasons_ligat_haal_transfermarkt.csv\"\n",
    "    save_csv(combined_attendance, combined_path)\n",
    "    \n",
    "    print(f\"\\nüìä Combined attendance data:\")\n",
    "    print(f\"   Total records: {len(combined_attendance)}\")\n",
    "    print(f\"   Seasons: {combined_attendance['season'].nunique()}\")\n",
    "    print(f\"   Teams: {combined_attendance['team'].nunique()}\")\n",
    "    print(f\"\\n   Saved to: {combined_path.name}\")\n",
    "    \n",
    "    # Show summary by season\n",
    "    summary = combined_attendance.groupby('season').agg({\n",
    "        'team': 'count',\n",
    "        'total_spectators': 'sum',\n",
    "        'average_attendance': 'mean'\n",
    "    }).round(0)\n",
    "    summary.columns = ['Teams', 'Total Spectators', 'Avg Attendance']\n",
    "    print(\"\\n   Season Summary:\")\n",
    "    display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b79d0730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Team Name Mapping Loaded:\n",
      "  ‚Ä¢ 32 abbreviations\n",
      "  ‚Ä¢ 31 unique teams\n"
     ]
    }
   ],
   "source": [
    "# Team Name Mapping - Normalizes abbreviations and variants to full names\n",
    "# This mapping consolidates Wikipedia's inconsistent team naming across 20 seasons\n",
    "\n",
    "TEAM_NAME_MAP = {\n",
    "    # Abbreviations to full names\n",
    "    'ASH': 'F.C. Ashdod',\n",
    "    'BEI': 'Beitar Jerusalem',\n",
    "    'BnS': 'Bnei Sakhnin',\n",
    "    'BnY': 'Bnei Yehuda',\n",
    "    'HAS': 'Hapoel Ashkelon',\n",
    "    'HBS': \"Hapoel Be'er Sheva\",\n",
    "    'HHA': 'Hapoel Haifa',\n",
    "    'HKS': 'Hapoel Kfar Saba',\n",
    "    'HRA': \"Hapoel Ra'anana\",\n",
    "    'HTA': 'Hapoel Tel Aviv',\n",
    "    'IKS': 'Ironi Kiryat Shmona',\n",
    "    'MHA': 'Maccabi Haifa',\n",
    "    'MPT': 'Maccabi Petah Tikva',\n",
    "    'MTA': 'Maccabi Tel Aviv',\n",
    "    'HPT': 'Hapoel Petah Tikva',\n",
    "    'HRG': 'Hapoel Ramat Gan',\n",
    "    'HRH': 'Hapoel Ramat HaSharon',\n",
    "    'HRL': 'Rishon LeZion',\n",
    "    'MAN': 'Maccabi Ahi Nazareth',\n",
    "    'MBR': 'Maccabi Bnei Reineh',\n",
    "    'SNZ': 'Sektzia Ness Ziona',\n",
    "    'HAK': 'Hapoel Acre',\n",
    "    'MHE': 'Maccabi Herzliya',\n",
    "    'MNE': 'Maccabi Netanya',\n",
    "    'HAR': 'Hapoel Raanana',\n",
    "    'HAC': 'Hapoel Acre',\n",
    "    'IRH': 'Ironi Ramat HaSharon',\n",
    "    'HAH': 'Hapoel Hadera',\n",
    "    'NES': 'Ness Ziona',\n",
    "    'HJE': 'Hapoel Jerusalem',\n",
    "    'HNG': 'Hapoel Nof HaGalil',\n",
    "    'ITI': 'Ironi Tiberias',\n",
    "    \n",
    "    # Name variants to canonical names\n",
    "    'Ashdod': 'F.C. Ashdod',\n",
    "    'F.C. Ironi Ashdod': 'F.C. Ashdod',\n",
    "    'Ness Ziona': 'Sektzia Ness Ziona',\n",
    "    'Ironi Nir Ramat HaSharon': 'Ironi Ramat HaSharon',\n",
    "    'Hakoah Amidar Ramat Gan': 'Hapoel Ramat Gan',\n",
    "    'Hapoel Rishon LeZion': 'Rishon LeZion',\n",
    "    'Hapoel Raanana': \"Hapoel Ra'anana\",\n",
    "    \n",
    "    # Full names map to themselves\n",
    "    'F.C. Ashdod': 'F.C. Ashdod',\n",
    "    'Beitar Jerusalem': 'Beitar Jerusalem',\n",
    "    'Bnei Sakhnin': 'Bnei Sakhnin',\n",
    "    'Bnei Yehuda': 'Bnei Yehuda',\n",
    "    'Hapoel Ashkelon': 'Hapoel Ashkelon',\n",
    "    \"Hapoel Be'er Sheva\": \"Hapoel Be'er Sheva\",\n",
    "    'Hapoel Haifa': 'Hapoel Haifa',\n",
    "    'Hapoel Kfar Saba': 'Hapoel Kfar Saba',\n",
    "    \"Hapoel Ra'anana\": \"Hapoel Ra'anana\",\n",
    "    'Hapoel Tel Aviv': 'Hapoel Tel Aviv',\n",
    "    'Ironi Kiryat Shmona': 'Ironi Kiryat Shmona',\n",
    "    'Maccabi Haifa': 'Maccabi Haifa',\n",
    "    'Maccabi Petah Tikva': 'Maccabi Petah Tikva',\n",
    "    'Maccabi Tel Aviv': 'Maccabi Tel Aviv',\n",
    "    'Hapoel Petah Tikva': 'Hapoel Petah Tikva',\n",
    "    'Hapoel Ramat Gan': 'Hapoel Ramat Gan',\n",
    "    'Hapoel Ramat HaSharon': 'Hapoel Ramat HaSharon',\n",
    "    'Rishon LeZion': 'Rishon LeZion',\n",
    "    'Maccabi Ahi Nazareth': 'Maccabi Ahi Nazareth',\n",
    "    'Maccabi Bnei Reineh': 'Maccabi Bnei Reineh',\n",
    "    'Sektzia Ness Ziona': 'Sektzia Ness Ziona',\n",
    "    'Hapoel Acre': 'Hapoel Acre',\n",
    "    'Maccabi Herzliya': 'Maccabi Herzliya',\n",
    "    'Maccabi Netanya': 'Maccabi Netanya',\n",
    "    'Ironi Ramat HaSharon': 'Ironi Ramat HaSharon',\n",
    "    'Hapoel Hadera': 'Hapoel Hadera',\n",
    "    'Hapoel Jerusalem': 'Hapoel Jerusalem',\n",
    "    'Hapoel Nof HaGalil': 'Hapoel Nof HaGalil',\n",
    "    'Ironi Tiberias': 'Ironi Tiberias',\n",
    "}\n",
    "\n",
    "def normalize_team_names(df, name_map=TEAM_NAME_MAP):\n",
    "    \"\"\"\n",
    "    Normalize team names by converting abbreviations and variants to full names.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with 'home_team' and 'away_team' columns\n",
    "        name_map: Dictionary mapping abbreviations/variants to standardized names\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with normalized team names\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['home_team'] = df['home_team'].map(lambda x: name_map.get(x, x))\n",
    "    df['away_team'] = df['away_team'].map(lambda x: name_map.get(x, x))\n",
    "    return df\n",
    "\n",
    "def apply_season_specific_fixes(df, season):\n",
    "    \"\"\"\n",
    "    Apply season-specific Wikipedia data corrections.\n",
    "    Wikipedia sometimes uses incorrect team names in their results matrices.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with match data\n",
    "        season: Season string (e.g., '2006/07')\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with season-specific fixes applied\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    if season == '2006/07':\n",
    "        df.loc[df['home_team'] == 'Hapoel Ramat Gan', 'home_team'] = 'Hapoel Acre'\n",
    "    elif season == '2008/09':\n",
    "        df.loc[df['home_team'] == 'Hapoel Ramat Gan', 'home_team'] = \"Hapoel Ra'anana\"\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"‚úÖ Team Name Mapping Loaded:\")\n",
    "print(f\"  ‚Ä¢ {len([k for k in TEAM_NAME_MAP.keys() if len(k) <= 3])} abbreviations\")\n",
    "print(f\"  ‚Ä¢ {len(set(TEAM_NAME_MAP.values()))} unique teams\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03c7916a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATA SOURCES COMPARISON\n",
      "================================================================================\n",
      "\n",
      "üìä Match Data Files:\n",
      "  Transfermarkt: 20 seasons\n",
      "  Wikipedia: 21 seasons\n",
      "\n",
      "üîç Sample Analysis: matches_2006_07_ligat_haal_transfermarkt.csv\n",
      "  Total matches: 198\n",
      "  Columns: ['round', 'home', 'score', 'away']\n",
      "  Rounds: 1 to 198\n",
      "  Unique teams: 12\n",
      "\n",
      "  üìù For 12 teams:\n",
      "     Expected regular season: 132 matches\n",
      "     Found in Transfermarkt: 198 matches\n",
      "     ‚ö†Ô∏è  Match count doesn't match expected regular season\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üí° RECOMMENDATION:\n",
      "   Use WIKIPEDIA for complete match data (regular season + playoffs)\n",
      "   Use TRANSFERMARKT for attendance data\n",
      "\n",
      "   Your existing Wikipedia data already includes:\n",
      "   ‚úÖ Regular season matches\n",
      "   ‚úÖ Championship playoff matches\n",
      "   ‚úÖ Relegation playoff matches\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Summary: Compare data availability between Transfermarkt and Wikipedia\n",
    "import pandas as pd\n",
    "ensure_environment()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DATA SOURCES COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check what files we have\n",
    "transfermarkt_files = list(DATA_DIR.glob(\"matches_*_transfermarkt.csv\"))\n",
    "wiki_files = list(DATA_DIR.glob(\"matches_*_wikipedia.csv\"))\n",
    "\n",
    "print(f\"\\nüìä Match Data Files:\")\n",
    "print(f\"  Transfermarkt: {len(transfermarkt_files)} seasons\")\n",
    "print(f\"  Wikipedia: {len(wiki_files)} seasons\")\n",
    "\n",
    "# Sample one season to show the difference\n",
    "if transfermarkt_files:\n",
    "    sample_file = transfermarkt_files[0]\n",
    "    df_transfermarkt = pd.read_csv(sample_file)\n",
    "    \n",
    "    print(f\"\\nüîç Sample Analysis: {sample_file.name}\")\n",
    "    print(f\"  Total matches: {len(df_transfermarkt)}\")\n",
    "    print(f\"  Columns: {list(df_transfermarkt.columns)}\")\n",
    "    \n",
    "    # Check if it has round info\n",
    "    if 'round' in df_transfermarkt.columns:\n",
    "        print(f\"  Rounds: {df_transfermarkt['round'].min()} to {df_transfermarkt['round'].max()}\")\n",
    "    \n",
    "    # Count teams\n",
    "    teams_home = set(df_transfermarkt['home'].unique()) if 'home' in df_transfermarkt.columns else set()\n",
    "    teams_away = set(df_transfermarkt['away'].unique()) if 'away' in df_transfermarkt.columns else set()\n",
    "    all_teams = teams_home.union(teams_away)\n",
    "    \n",
    "    print(f\"  Unique teams: {len(all_teams)}\")\n",
    "    \n",
    "    # Calculate expected matches\n",
    "    num_teams = len(all_teams)\n",
    "    expected_regular = (num_teams - 1) * 2 * (num_teams // 2)\n",
    "    \n",
    "    print(f\"\\n  üìù For {num_teams} teams:\")\n",
    "    print(f\"     Expected regular season: {expected_regular} matches\")\n",
    "    print(f\"     Found in Transfermarkt: {len(df_transfermarkt)} matches\")\n",
    "    \n",
    "    if len(df_transfermarkt) == expected_regular:\n",
    "        print(f\"     ‚úÖ Confirmed: Regular season only (no playoffs)\")\n",
    "    else:\n",
    "        print(f\"     ‚ö†Ô∏è  Match count doesn't match expected regular season\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nüí° RECOMMENDATION:\")\n",
    "print(\"   Use WIKIPEDIA for complete match data (regular season + playoffs)\")\n",
    "print(\"   Use TRANSFERMARKT for attendance data\")\n",
    "print(\"\\n   Your existing Wikipedia data already includes:\")\n",
    "print(\"   ‚úÖ Regular season matches\")\n",
    "print(\"   ‚úÖ Championship playoff matches\")  \n",
    "print(\"   ‚úÖ Relegation playoff matches\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "137203bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Ñπ Processing 2016/17: 182 matches, 14 teams\n",
      "\n",
      "üìä League Leadership Analysis - 2016/17 (REGULAR SEASON)\n",
      "============================================================\n",
      "\n",
      "üèÜ Leadership Changes: 3\n",
      "   (Initial leader doesn't count as a 'change')\n",
      "\n",
      "Round-by-round first place:\n",
      "  ‚Ä¢ Round  1: F.C. Ashdod\n",
      "  ‚Ä¢ Round  3: Beitar Jerusalem\n",
      "  ‚Ä¢ Round  8: Bnei Sakhnin\n",
      "  ‚Ä¢ Round 10: Hapoel Be'er Sheva\n",
      "\n",
      "üìã Final Standings After Round 26 (Regular Season):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>position</th>\n",
       "      <th>team</th>\n",
       "      <th>played</th>\n",
       "      <th>won</th>\n",
       "      <th>drawn</th>\n",
       "      <th>lost</th>\n",
       "      <th>gf</th>\n",
       "      <th>ga</th>\n",
       "      <th>gd</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Hapoel Be'er Sheva</td>\n",
       "      <td>26</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>13</td>\n",
       "      <td>41</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>Maccabi Tel Aviv</td>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>Maccabi Petah Tikva</td>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Beitar Jerusalem</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Bnei Sakhnin</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>Maccabi Haifa</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>Ironi Kiryat Shmona</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>35</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>Hapoel Haifa</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>29</td>\n",
       "      <td>36</td>\n",
       "      <td>-7</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>F.C. Ashdod</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>26</td>\n",
       "      <td>-11</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>Hapoel Ra'anana</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>29</td>\n",
       "      <td>-15</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    position                 team  played  won  drawn  lost  gf  ga  gd  \\\n",
       "5          1   Hapoel Be'er Sheva      26   18      5     3  54  13  41   \n",
       "13         2     Maccabi Tel Aviv      26   17      5     4  45  19  26   \n",
       "12         3  Maccabi Petah Tikva      26   13      9     4  36  23  13   \n",
       "0          4     Beitar Jerusalem      26   10     10     6  34  27   7   \n",
       "1          5         Bnei Sakhnin      26   10      9     7  26  26   0   \n",
       "11         6        Maccabi Haifa      26   10      8     8  30  25   5   \n",
       "10         7  Ironi Kiryat Shmona      26    9      8     9  35  33   2   \n",
       "6          8         Hapoel Haifa      26    8      4    14  29  36  -7   \n",
       "3          9          F.C. Ashdod      26    6     10    10  15  26 -11   \n",
       "8         10      Hapoel Ra'anana      26    7      7    12  14  29 -15   \n",
       "\n",
       "    points  \n",
       "5       59  \n",
       "13      56  \n",
       "12      48  \n",
       "0       40  \n",
       "1       39  \n",
       "11      38  \n",
       "10      35  \n",
       "6       28  \n",
       "3       28  \n",
       "8       28  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Season Statistics:\n",
      "  ‚Ä¢ Rounds analyzed: 26 (Regular Season only)\n",
      "  ‚Ä¢ Teams: 14\n",
      "  ‚Ä¢ Total matches: 182\n",
      "  ‚Ä¢ Leader after regular season: Hapoel Be'er Sheva (59 pts, 26 games)\n",
      "  ‚Ä¢ Runner-up: Maccabi Tel Aviv (56 pts, 26 games)\n",
      "  ‚Ä¢ Points gap: 3 pts\n",
      "\n",
      "‚ö†Ô∏è IMPORTANT NOTE:\n",
      "   Wikipedia results matrix only shows REGULAR SEASON matches (26 rounds).\n",
      "   Ligat Ha'al has additional Championship/Relegation playoffs (~10 rounds).\n",
      "   Full season totals: ~36 matches, ~87 points for champion (as you mentioned).\n",
      "   This analysis tracks leadership changes during the regular season only.\n",
      "\n",
      "‚úÖ All team names are now normalized (full names used throughout).\n"
     ]
    }
   ],
   "source": [
    "# Calculate league standings after each matchday and track leadership changes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ensure_environment()\n",
    "\n",
    "def calculate_league_table_by_round(matches_df, season_str=\"2016/17\"):\n",
    "    \"\"\"\n",
    "    Calculate league standings after each round/matchday.\n",
    "    \n",
    "    Args:\n",
    "        matches_df: DataFrame with match results (with normalized team names)\n",
    "        season_str: Season to analyze (e.g., \"2016/17\")\n",
    "    \n",
    "    Returns:\n",
    "        - standings_by_round: dict mapping round_num -> DataFrame of standings\n",
    "        - leadership_changes: list of tuples (round_num, new_leader)\n",
    "    \n",
    "    Note: Team names should already be normalized (full names, not abbreviations).\n",
    "    \"\"\"\n",
    "    # Filter for the specific season\n",
    "    season_matches = matches_df[matches_df['season'] == season_str].copy()\n",
    "    \n",
    "    # Get all unique teams - count ONLY home teams (each team has home games)\n",
    "    # This avoids duplicate counting from abbreviations in away_team column\n",
    "    teams = sorted(season_matches['home_team'].unique())\n",
    "    n_teams = len(teams)\n",
    "    \n",
    "    print(f\"‚Ñπ Processing {season_str}: {len(season_matches)} matches, {n_teams} teams\")\n",
    "    \n",
    "    # In Ligat Ha'al, 14 teams play 26 rounds in regular season, then split into championship/relegation\n",
    "    # For the regular season: each team plays 13 opponents √ó 2 (home/away) = 26 matches\n",
    "    # Total matches in regular season = (14 teams √ó 26 matches) / 2 = 182 matches\n",
    "    \n",
    "    # Assign round numbers by ordering matches\n",
    "    # Since we don't have dates, distribute evenly assuming each round has n_teams/2 matches\n",
    "    season_matches = season_matches.reset_index(drop=True)\n",
    "    \n",
    "    # Each round has 7 matches (14 teams / 2)\n",
    "    matches_per_round = n_teams // 2 if n_teams % 2 == 0 else (n_teams + 1) // 2\n",
    "    \n",
    "    # Assign rounds based on position in dataset\n",
    "    season_matches['round_num'] = (season_matches.index // matches_per_round) + 1\n",
    "    max_round = season_matches['round_num'].max()\n",
    "    \n",
    "    # Initialize standings tracker\n",
    "    standings_by_round = {}\n",
    "    current_leader = None\n",
    "    leadership_changes = []\n",
    "    \n",
    "    # Calculate standings after each round\n",
    "    for round_num in sorted(season_matches['round_num'].unique()):\n",
    "        # Get all matches up to and including this round\n",
    "        matches_so_far = season_matches[season_matches['round_num'] <= round_num]\n",
    "        \n",
    "        # Initialize team stats\n",
    "        stats = {team: {'played': 0, 'won': 0, 'drawn': 0, 'lost': 0, \n",
    "                        'gf': 0, 'ga': 0, 'gd': 0, 'points': 0} \n",
    "                 for team in teams}\n",
    "        \n",
    "        # Calculate stats from matches\n",
    "        for _, match in matches_so_far.iterrows():\n",
    "            home = match['home_team']\n",
    "            away = match['away_team']\n",
    "            home_goals = match['home_goals']\n",
    "            away_goals = match['away_goals']\n",
    "            \n",
    "            # Update home team\n",
    "            stats[home]['played'] += 1\n",
    "            stats[home]['gf'] += home_goals\n",
    "            stats[home]['ga'] += away_goals\n",
    "            stats[home]['gd'] = stats[home]['gf'] - stats[home]['ga']\n",
    "            \n",
    "            # Update away team\n",
    "            stats[away]['played'] += 1\n",
    "            stats[away]['gf'] += away_goals\n",
    "            stats[away]['ga'] += home_goals\n",
    "            stats[away]['gd'] = stats[away]['gf'] - stats[away]['ga']\n",
    "            \n",
    "            # Update points\n",
    "            if home_goals > away_goals:  # Home win\n",
    "                stats[home]['won'] += 1\n",
    "                stats[home]['points'] += 3\n",
    "                stats[away]['lost'] += 1\n",
    "            elif away_goals > home_goals:  # Away win\n",
    "                stats[away]['won'] += 1\n",
    "                stats[away]['points'] += 3\n",
    "                stats[home]['lost'] += 1\n",
    "            else:  # Draw\n",
    "                stats[home]['drawn'] += 1\n",
    "                stats[away]['drawn'] += 1\n",
    "                stats[home]['points'] += 1\n",
    "                stats[away]['points'] += 1\n",
    "        \n",
    "        # Convert to DataFrame and sort\n",
    "        standings = pd.DataFrame.from_dict(stats, orient='index')\n",
    "        standings.index.name = 'team'\n",
    "        standings = standings.reset_index()\n",
    "        standings = standings.sort_values(['points', 'gd', 'gf'], ascending=[False, False, False])\n",
    "        standings['position'] = range(1, len(standings) + 1)\n",
    "        \n",
    "        standings_by_round[int(round_num)] = standings\n",
    "        \n",
    "        # Track leader\n",
    "        new_leader = standings.iloc[0]['team']\n",
    "        if new_leader != current_leader:\n",
    "            leadership_changes.append((int(round_num), new_leader))\n",
    "            current_leader = new_leader\n",
    "    \n",
    "    return standings_by_round, leadership_changes\n",
    "\n",
    "# Load the combined matches data\n",
    "matches_path = DATA_DIR / \"matches_all_seasons_ligat_haal_wikipedia.csv\"\n",
    "if not matches_path.exists():\n",
    "    print(f\"‚ùå Combined matches file not found: {matches_path}\")\n",
    "    print(\"Please run the multi-season Wikipedia scraper first (cell 17)\")\n",
    "else:\n",
    "    all_matches = pd.read_csv(matches_path)\n",
    "    \n",
    "    # Normalize team names (convert abbreviations to full names)\n",
    "    all_matches = normalize_team_names(all_matches, TEAM_NAME_MAP)\n",
    "    \n",
    "    # Apply season-specific fixes\n",
    "    for season_name in all_matches['season'].unique():\n",
    "        season_data = all_matches[all_matches['season'] == season_name]\n",
    "        all_matches.loc[all_matches['season'] == season_name] = apply_season_specific_fixes(season_data, season_name)\n",
    "    \n",
    "    # Analyze 2016/17 season\n",
    "    season = \"2016/17\"\n",
    "    standings_by_round, leadership_changes = calculate_league_table_by_round(all_matches, season)\n",
    "    \n",
    "    print(f\"\\nüìä League Leadership Analysis - {season} (REGULAR SEASON)\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\nüèÜ Leadership Changes: {len(leadership_changes) - 1}\")\n",
    "    print(f\"   (Initial leader doesn't count as a 'change')\\n\")\n",
    "    \n",
    "    print(\"Round-by-round first place:\")\n",
    "    for round_num, leader in leadership_changes:\n",
    "        print(f\"  ‚Ä¢ Round {round_num:2d}: {leader}\")\n",
    "    \n",
    "    # Show final standings\n",
    "    print(f\"\\nüìã Final Standings After Round {max(standings_by_round.keys())} (Regular Season):\")\n",
    "    final = standings_by_round[max(standings_by_round.keys())]\n",
    "    display(final[['position', 'team', 'played', 'won', 'drawn', 'lost', 'gf', 'ga', 'gd', 'points']].head(10))\n",
    "    \n",
    "    # Calculate some interesting stats\n",
    "    print(f\"\\nüìà Season Statistics:\")\n",
    "    print(f\"  ‚Ä¢ Rounds analyzed: {len(standings_by_round)} (Regular Season only)\")\n",
    "    print(f\"  ‚Ä¢ Teams: {len(final)}\")\n",
    "    print(f\"  ‚Ä¢ Total matches: {len(all_matches[all_matches['season'] == season])}\")\n",
    "    print(f\"  ‚Ä¢ Leader after regular season: {final.iloc[0]['team']} ({final.iloc[0]['points']:.0f} pts, {final.iloc[0]['played']:.0f} games)\")\n",
    "    print(f\"  ‚Ä¢ Runner-up: {final.iloc[1]['team']} ({final.iloc[1]['points']:.0f} pts, {final.iloc[1]['played']:.0f} games)\")\n",
    "    print(f\"  ‚Ä¢ Points gap: {final.iloc[0]['points'] - final.iloc[1]['points']:.0f} pts\")\n",
    "    \n",
    "    print(f\"\\n‚ö†Ô∏è IMPORTANT NOTE:\")\n",
    "    print(f\"   Wikipedia results matrix only shows REGULAR SEASON matches (26 rounds).\")\n",
    "    print(f\"   Ligat Ha'al has additional Championship/Relegation playoffs (~10 rounds).\")\n",
    "    print(f\"   Full season totals: ~36 matches, ~87 points for champion (as you mentioned).\")\n",
    "    print(f\"   This analysis tracks leadership changes during the regular season only.\")\n",
    "    print(f\"\\n‚úÖ All team names are now normalized (full names used throughout).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f9e09de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 20 Transfermarkt CSV files\n",
      "\n",
      "Files:\n",
      "  - matches_2006_07_ligat_haal_transfermarkt.csv\n",
      "  - matches_2007_08_ligat_haal_transfermarkt.csv\n",
      "  - matches_2008_09_ligat_haal_transfermarkt.csv\n",
      "  - matches_2009_10_ligat_haal_transfermarkt.csv\n",
      "  - matches_2010_11_ligat_haal_transfermarkt.csv\n",
      "  - matches_2011_12_ligat_haal_transfermarkt.csv\n",
      "  - matches_2012_13_ligat_haal_transfermarkt.csv\n",
      "  - matches_2013_14_ligat_haal_transfermarkt.csv\n",
      "  - matches_2014_15_ligat_haal_transfermarkt.csv\n",
      "  - matches_2015_16_ligat_haal_transfermarkt.csv\n",
      "  - matches_2016_17_ligat_haal_transfermarkt.csv\n",
      "  - matches_2017_18_ligat_haal_transfermarkt.csv\n",
      "  - matches_2018_19_ligat_haal_transfermarkt.csv\n",
      "  - matches_2019_20_ligat_haal_transfermarkt.csv\n",
      "  - matches_2020_21_ligat_haal_transfermarkt.csv\n",
      "  - matches_2021_22_ligat_haal_transfermarkt.csv\n",
      "  - matches_2022_23_ligat_haal_transfermarkt.csv\n",
      "  - matches_2023_24_ligat_haal_transfermarkt.csv\n",
      "  - matches_2024_25_ligat_haal_transfermarkt.csv\n",
      "  - matches_2025_26_ligat_haal_transfermarkt.csv\n",
      "\n",
      "‚úÖ Sample file: matches_2006_07_ligat_haal_transfermarkt.csv\n",
      "  Columns: ['round', 'home', 'score', 'away']\n",
      "  Shape: (198, 4)\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>home</th>\n",
       "      <th>score</th>\n",
       "      <th>away</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>H. Kfar Saba</td>\n",
       "      <td>4:1</td>\n",
       "      <td>H. Petah Tikva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M. Petah Tikva</td>\n",
       "      <td>0:0</td>\n",
       "      <td>Hakoah Amidar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>FC Ashdod</td>\n",
       "      <td>1:0</td>\n",
       "      <td>Maccabi Herzlya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Maccabi Netanya</td>\n",
       "      <td>3:1</td>\n",
       "      <td>Maccabi Haifa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M. Tel Aviv</td>\n",
       "      <td>1:2</td>\n",
       "      <td>B. Jerusalem</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   round             home score             away\n",
       "0      1     H. Kfar Saba   4:1   H. Petah Tikva\n",
       "1      2   M. Petah Tikva   0:0    Hakoah Amidar\n",
       "2      3        FC Ashdod   1:0  Maccabi Herzlya\n",
       "3      4  Maccabi Netanya   3:1    Maccabi Haifa\n",
       "4      5      M. Tel Aviv   1:2     B. Jerusalem"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data quality check:\n",
      "  Missing home teams: 0\n",
      "  Missing away teams: 0\n",
      "  Missing scores: 0\n",
      "\n",
      "‚úÖ Wikipedia sample: matches_2006_07_ligat_haal_wikipedia.csv\n",
      "  Columns: ['season', 'season_year', 'home_team', 'away_team', 'home_goals', 'away_goals', 'goal_diff', 'result', 'home_points', 'away_points']\n",
      "\n",
      "First 3 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>season_year</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>home_goals</th>\n",
       "      <th>away_goals</th>\n",
       "      <th>goal_diff</th>\n",
       "      <th>result</th>\n",
       "      <th>home_points</th>\n",
       "      <th>away_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>2006</td>\n",
       "      <td>Beitar Jerusalem</td>\n",
       "      <td>BnY</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>2006</td>\n",
       "      <td>Beitar Jerusalem</td>\n",
       "      <td>ASH</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>H</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>2006</td>\n",
       "      <td>Beitar Jerusalem</td>\n",
       "      <td>HAK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    season  season_year         home_team away_team  home_goals  away_goals  \\\n",
       "0  2006/07         2006  Beitar Jerusalem       BnY           0           0   \n",
       "1  2006/07         2006  Beitar Jerusalem       ASH           2           0   \n",
       "2  2006/07         2006  Beitar Jerusalem       HAK           0           0   \n",
       "\n",
       "   goal_diff result  home_points  away_points  \n",
       "0          0      D            1            1  \n",
       "1          2      H            3            0  \n",
       "2          0      D            1            1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Format comparison:\n",
      "  Transfermarkt columns: ['round', 'home', 'score', 'away']\n",
      "  Wikipedia columns: ['season', 'season_year', 'home_team', 'away_team', 'home_goals', 'away_goals', 'goal_diff', 'result', 'home_points', 'away_points']\n",
      "  Match: False\n"
     ]
    }
   ],
   "source": [
    "# Verify scraped data and compare with Wikipedia format\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# List all Transfermarkt CSVs\n",
    "DATA_DIR = Path(ROOT) / 'data' / 'raw'\n",
    "transfermarkt_files = sorted(DATA_DIR.glob('matches_*_ligat_haal_transfermarkt.csv'))\n",
    "\n",
    "print(f'‚úÖ Found {len(transfermarkt_files)} Transfermarkt CSV files')\n",
    "print('\\nFiles:')\n",
    "for f in transfermarkt_files:\n",
    "    print(f'  - {f.name}')\n",
    "\n",
    "# Load and check format of first file\n",
    "if transfermarkt_files:\n",
    "    sample_file = transfermarkt_files[0]\n",
    "    df_sample = pd.read_csv(sample_file)\n",
    "    \n",
    "    print(f'\\n‚úÖ Sample file: {sample_file.name}')\n",
    "    print(f'  Columns: {list(df_sample.columns)}')\n",
    "    print(f'  Shape: {df_sample.shape}')\n",
    "    print(f'\\nFirst 5 rows:')\n",
    "    display(df_sample.head())\n",
    "    \n",
    "    # Check for any missing data\n",
    "    print(f'\\nData quality check:')\n",
    "    print(f'  Missing home teams: {df_sample[\"home\"].isna().sum()}')\n",
    "    print(f'  Missing away teams: {df_sample[\"away\"].isna().sum()}')\n",
    "    print(f'  Missing scores: {df_sample[\"score\"].isna().sum()}')\n",
    "\n",
    "# Compare with Wikipedia format\n",
    "wiki_files = sorted(DATA_DIR.glob('matches_*_ligat_haal_wikipedia.csv'))\n",
    "if wiki_files:\n",
    "    wiki_sample = pd.read_csv(wiki_files[0])\n",
    "    print(f'\\n‚úÖ Wikipedia sample: {wiki_files[0].name}')\n",
    "    print(f'  Columns: {list(wiki_sample.columns)}')\n",
    "    print(f'\\nFirst 3 rows:')\n",
    "    display(wiki_sample.head(3))\n",
    "    \n",
    "    print('\\n‚úÖ Format comparison:')\n",
    "    print(f'  Transfermarkt columns: {list(df_sample.columns)}')\n",
    "    print(f'  Wikipedia columns: {list(wiki_sample.columns)}')\n",
    "    print(f'  Match: {list(df_sample.columns) == list(wiki_sample.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51e59962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ TRANSFERMARKT SCRAPING COMPLETE ‚úÖ\n",
      "================================================================================\n",
      "\n",
      "Successfully scraped 20 seasons from Transfermarkt\n",
      "Seasons: 2006/07 to 2025/26\n",
      "Format: round, home, score, away (same as Wikipedia)\n",
      "\n",
      "‚úÖ Season Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Rounds</th>\n",
       "      <th>Teams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007/08</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008/09</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009/10</td>\n",
       "      <td>240</td>\n",
       "      <td>240</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010/11</td>\n",
       "      <td>240</td>\n",
       "      <td>240</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2011/12</td>\n",
       "      <td>240</td>\n",
       "      <td>240</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2012/13</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013/14</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2014/15</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015/16</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2016/17</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017/18</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018/19</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019/20</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020/21</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2021/22</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2022/23</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023/24</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2024/25</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2025/26</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Season  Matches  Rounds  Teams\n",
       "0   2006/07      198     198     12\n",
       "1   2007/08      198     198     12\n",
       "2   2008/09      198     198     12\n",
       "3   2009/10      240     240     16\n",
       "4   2010/11      240     240     16\n",
       "5   2011/12      240     240     16\n",
       "6   2012/13      182     182     14\n",
       "7   2013/14      182     182     14\n",
       "8   2014/15      182     182     14\n",
       "9   2015/16      182     182     14\n",
       "10  2016/17      182     182     14\n",
       "11  2017/18      182     182     14\n",
       "12  2018/19      182     182     14\n",
       "13  2019/20      182     182     14\n",
       "14  2020/21      182     182     14\n",
       "15  2021/22      182     182     14\n",
       "16  2022/23      182     182     14\n",
       "17  2023/24      182     182     14\n",
       "18  2024/25      182     182     14\n",
       "19  2025/26       69      69     14"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Total Statistics:\n",
      "  Total matches: 3749\n",
      "  Average matches per season: 187\n",
      "  Max rounds in a season: 240\n",
      "  Min rounds in a season: 69\n",
      "\n",
      "‚úÖ Data Location:\n",
      "  Directory: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\n",
      "  Files: matches_YYYY_YY_ligat_haal_transfermarkt.csv\n",
      "\n",
      "‚úÖ Next Steps:\n",
      "  - Data is ready for analysis\n",
      "  - Same format as Wikipedia data (round, home, score, away)\n",
      "  - Can be combined or analyzed separately\n",
      "  - Playoff data available in gesamtspielplan pages (Championship/Relegation rounds)\n"
     ]
    }
   ],
   "source": [
    "# Final Summary: All 20 Seasons from Transfermarkt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(ROOT) / 'data' / 'raw'\n",
    "transfermarkt_files = sorted(DATA_DIR.glob('matches_*_ligat_haal_transfermarkt.csv'))\n",
    "\n",
    "print('‚úÖ TRANSFERMARKT SCRAPING COMPLETE \\u2705')\n",
    "print('=' * 80)\n",
    "print(f'\\nSuccessfully scraped {len(transfermarkt_files)} seasons from Transfermarkt')\n",
    "print(f'Seasons: 2006/07 to 2025/26')\n",
    "print(f'Format: round, home, score, away (same as Wikipedia)')\n",
    "\n",
    "# Load all files and create summary\n",
    "all_data = []\n",
    "season_summary = []\n",
    "\n",
    "for csv_file in transfermarkt_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    season = csv_file.stem.split('_')[1:3]  # Extract season from filename\n",
    "    season_str = f\"{season[0]}/{season[1]}\"\n",
    "    \n",
    "    season_summary.append({\n",
    "        'Season': season_str,\n",
    "        'Matches': len(df),\n",
    "        'Rounds': df['round'].max(),\n",
    "        'Teams': len(set(df['home'].tolist() + df['away'].tolist()))\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(season_summary)\n",
    "\n",
    "print('\\n‚úÖ Season Summary:')\n",
    "display(summary_df)\n",
    "\n",
    "print(f'\\n‚úÖ Total Statistics:')\n",
    "print(f'  Total matches: {summary_df[\"Matches\"].sum()}')\n",
    "print(f'  Average matches per season: {summary_df[\"Matches\"].mean():.0f}')\n",
    "print(f'  Max rounds in a season: {summary_df[\"Rounds\"].max()}')\n",
    "print(f'  Min rounds in a season: {summary_df[\"Rounds\"].min()}')\n",
    "\n",
    "print('\\n‚úÖ Data Location:')\n",
    "print(f'  Directory: {DATA_DIR}')\n",
    "print(f'  Files: matches_YYYY_YY_ligat_haal_transfermarkt.csv')\n",
    "\n",
    "print('\\n‚úÖ Next Steps:')\n",
    "print('  - Data is ready for analysis')\n",
    "print('  - Same format as Wikipedia data (round, home, score, away)')\n",
    "print('  - Can be combined or analyzed separately')\n",
    "print('  - Playoff data available in gesamtspielplan pages (Championship/Relegation rounds)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc10741e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfermarkt Playoff Scraper (Restored) - outputs round, home, score, away\n",
    "import re, time, requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure ROOT and DATA_DIR exist\n",
    "try:\n",
    "    ROOT\n",
    "except NameError:\n",
    "    ROOT = Path.cwd()\n",
    "DATA_DIR = Path(ROOT) / 'data' / 'raw'\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "HEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}\n",
    "\n",
    "def http_get(url, retries=3, sleep=1.5):\n",
    "    for attempt in range(1, retries+1):\n",
    "        try:\n",
    "            resp = requests.get(url, headers=HEADERS, timeout=20)\n",
    "            if resp.status_code == 200:\n",
    "                return resp.text\n",
    "            else:\n",
    "                print(f\"HTTP {resp.status_code} for {url}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt} failed for {url}: {e}\")\n",
    "        time.sleep(sleep)\n",
    "    return ''\n",
    "\n",
    "def scrape_transfermarkt_playoffs(season_year):\n",
    "    season_tag = f\"{season_year}_{str(season_year+1)[-2:]}\"\n",
    "    out_csv = DATA_DIR / f\"matches_{season_tag}_ligat_haal_transfermarkt_playoffs.csv\"\n",
    "    base_url = f\"https://www.transfermarkt.com/ligat-haal/gesamtspielplan/wettbewerb/ISR1?saison_id={season_year}\"\n",
    "    # Note: League playoffs are included in gesamtspielplan as separate sections (e.g., Championship Round)\n",
    "    html = http_get(base_url)\n",
    "    if not html:\n",
    "        print(f\"‚ùå No HTML for playoffs {season_year}\")\n",
    "        return None\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    rows_out = []\n",
    "    playoff_round = 0\n",
    "    for box in soup.select('div.box'):\n",
    "        h2 = box.select_one('h2, h3')\n",
    "        if not h2:\n",
    "            continue\n",
    "        title = h2.get_text(strip=True)\n",
    "        # Identify playoff sections by keywords\n",
    "        if not re.search(r'Championship|Relegation|Play-?off|Upper|Lower', title, re.IGNORECASE):\n",
    "            continue\n",
    "        table = box.select_one('table.items') or box.select_one('table')\n",
    "        if not table:\n",
    "            continue\n",
    "        for tr in table.select('tbody tr'):\n",
    "            tds = tr.find_all('td')\n",
    "            if len(tds) < 5:\n",
    "                continue\n",
    "            home_a = tr.select_one('td.verein-heim a, td.heim a, td:nth-of-type(2) a[href*=\"/verein/\"]')\n",
    "            away_a = tr.select_one('td.verein-gast a, td.gast a, td:nth-of-type(6) a[href*=\"/verein/\"]')\n",
    "            if not home_a or not away_a:\n",
    "                team_links = [a for a in tr.select('a[href*=\"/verein/\"]') if a.get_text(strip=True)]\n",
    "                if len(team_links) >= 2:\n",
    "                    home_a, away_a = team_links[0], team_links[1]\n",
    "                else:\n",
    "                    continue\n",
    "            home = home_a.get_text(strip=True)\n",
    "            away = away_a.get_text(strip=True)\n",
    "            score_cell = tr.select_one('td.ergebnis a, td.ergebnis, td:nth-of-type(5)')\n",
    "            score_txt = score_cell.get_text(\" \", strip=True) if score_cell else ''\n",
    "            mscore = re.search(r'(\\d+\\s*:\\s*\\d+)', score_txt)\n",
    "            score = mscore.group(1).replace(' ','') if mscore else ''\n",
    "            if not score:\n",
    "                continue\n",
    "            playoff_round += 1\n",
    "            rows_out.append({'round': playoff_round, 'home': home, 'score': score, 'away': away})\n",
    "    if not rows_out:\n",
    "        print(f\"‚ö†Ô∏è No playoff matches parsed for {season_year}\")\n",
    "        return None\n",
    "    df = pd.DataFrame(rows_out)\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(f\"‚úÖ Saved {len(df)} playoff matches -> {out_csv.name}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83b20854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular season scraper updated with fixed team extraction.\n"
     ]
    }
   ],
   "source": [
    "# Transfermarkt Regular Season Scraper (Fixed) - outputs Wikipedia-style columns: round, home, score, away\n",
    "import re, time, requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure ROOT and DATA_DIR exist\n",
    "try:\n",
    "    ROOT\n",
    "except NameError:\n",
    "    ROOT = Path.cwd()\n",
    "DATA_DIR = Path(ROOT) / 'data' / 'raw'\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "HEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}\n",
    "\n",
    "def http_get(url, retries=3, sleep=1.5):\n",
    "    for attempt in range(1, retries+1):\n",
    "        try:\n",
    "            resp = requests.get(url, headers=HEADERS, timeout=20)\n",
    "            if resp.status_code == 200:\n",
    "                return resp.text\n",
    "        except Exception as e:\n",
    "            if attempt == retries:\n",
    "                print(f\"Failed after {retries} attempts: {e}\")\n",
    "        if attempt < retries:\n",
    "            time.sleep(sleep)\n",
    "    return ''\n",
    "\n",
    "def scrape_transfermarkt_regular(season_year):\n",
    "    \"\"\"Scrape regular season matches from Transfermarkt gesamtspielplan page.\"\"\"\n",
    "    season_tag = f\"{season_year}_{str(season_year+1)[-2:]}\"\n",
    "    out_csv = DATA_DIR / f\"matches_{season_tag}_ligat_haal_transfermarkt.csv\"\n",
    "    \n",
    "    url = f\"https://www.transfermarkt.com/ligat-haal/gesamtspielplan/wettbewerb/ISR1?saison_id={season_year}\"\n",
    "    html = http_get(url)\n",
    "    if not html:\n",
    "        print(f\"‚ùå No HTML for season {season_year}\")\n",
    "        return None\n",
    "    \n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    rows_out = []\n",
    "    round_num = 0\n",
    "    \n",
    "    # Find all tables on the page\n",
    "    tables = soup.find_all('table')\n",
    "    \n",
    "    for table in tables:\n",
    "        # Look for match rows (rows with 2 team links)\n",
    "        for tr in table.find_all('tr'):\n",
    "            # Find all cells\n",
    "            cells = tr.find_all('td')\n",
    "            if len(cells) < 5:\n",
    "                continue\n",
    "            \n",
    "            # Find score first to confirm this is a match row\n",
    "            score_link = tr.find('a', class_='ergebnis-link')\n",
    "            if not score_link:\n",
    "                continue\n",
    "            \n",
    "            score_text = score_link.get_text(strip=True)\n",
    "            # Validate score format (d:d)\n",
    "            if not re.match(r'^\\d+:\\d+$', score_text):\n",
    "                continue\n",
    "            \n",
    "            # Now find team links - typically in cells before and after score\n",
    "            all_team_links = []\n",
    "            for cell in cells:\n",
    "                team_link = cell.find('a', href=re.compile(r'/verein/'))\n",
    "                if team_link:\n",
    "                    team_name = team_link.get_text(strip=True)\n",
    "                    if team_name and team_name not in [link.get_text(strip=True) for link in all_team_links]:\n",
    "                        all_team_links.append(team_link)\n",
    "            \n",
    "            if len(all_team_links) < 2:\n",
    "                continue\n",
    "            \n",
    "            home = all_team_links[0].get_text(strip=True)\n",
    "            away = all_team_links[1].get_text(strip=True)\n",
    "            \n",
    "            # Increment round for each match found\n",
    "            round_num += 1\n",
    "            \n",
    "            rows_out.append({\n",
    "                'round': round_num,\n",
    "                'home': home,\n",
    "                'score': score_text,\n",
    "                'away': away\n",
    "            })\n",
    "    \n",
    "    if not rows_out:\n",
    "        print(f\"‚ö†Ô∏è No matches parsed for {season_year}\")\n",
    "        return None\n",
    "    \n",
    "    df = pd.DataFrame(rows_out)\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(f\"‚úÖ Saved {len(df)} matches -> {out_csv.name}\")\n",
    "    return df\n",
    "\n",
    "print('Regular season scraper updated with fixed team extraction.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad08dd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved 198 matches -> matches_2006_07_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2006\n",
      "‚úÖ Saved 198 matches -> matches_2007_08_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2007\n",
      "‚úÖ Saved 198 matches -> matches_2008_09_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2008\n",
      "‚úÖ Saved 240 matches -> matches_2009_10_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2009\n",
      "‚úÖ Saved 240 matches -> matches_2010_11_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2010\n",
      "‚úÖ Saved 240 matches -> matches_2011_12_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2011\n",
      "‚úÖ Saved 182 matches -> matches_2012_13_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2012\n",
      "‚úÖ Saved 182 matches -> matches_2013_14_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2013\n",
      "‚úÖ Saved 182 matches -> matches_2014_15_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2014\n",
      "‚úÖ Saved 182 matches -> matches_2015_16_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2015\n",
      "‚úÖ Saved 182 matches -> matches_2016_17_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2016\n",
      "‚úÖ Saved 182 matches -> matches_2017_18_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2017\n",
      "‚úÖ Saved 182 matches -> matches_2018_19_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2018\n",
      "‚úÖ Saved 182 matches -> matches_2019_20_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2019\n",
      "‚úÖ Saved 182 matches -> matches_2020_21_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2020\n",
      "‚úÖ Saved 182 matches -> matches_2021_22_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2021\n",
      "‚úÖ Saved 182 matches -> matches_2022_23_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2022\n",
      "‚úÖ Saved 182 matches -> matches_2023_24_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2023\n",
      "‚úÖ Saved 182 matches -> matches_2024_25_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2024\n",
      "‚úÖ Saved 69 matches -> matches_2025_26_ligat_haal_transfermarkt.csv\n",
      "‚ö†Ô∏è No playoff matches parsed for 2025\n",
      "\n",
      "================================================================================\n",
      "VALIDATION SUMMARY\n",
      "================================================================================\n",
      "Regular seasons scraped: 20\n",
      "Playoff seasons scraped: 0\n",
      "\n",
      "Detailed breakdown:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season_year</th>\n",
       "      <th>regular_matches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2011</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2012</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2014</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2016</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2021</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2022</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2024</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2025</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    season_year  regular_matches\n",
       "0          2006              198\n",
       "1          2007              198\n",
       "2          2008              198\n",
       "3          2009              240\n",
       "4          2010              240\n",
       "5          2011              240\n",
       "6          2012              182\n",
       "7          2013              182\n",
       "8          2014              182\n",
       "9          2015              182\n",
       "10         2016              182\n",
       "11         2017              182\n",
       "12         2018              182\n",
       "13         2019              182\n",
       "14         2020              182\n",
       "15         2021              182\n",
       "16         2022              182\n",
       "17         2023              182\n",
       "18         2024              182\n",
       "19         2025               69"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run restored Transfermarkt scrapers for all seasons and validate coverage\n",
    "seasons = list(range(2006, 2026))\n",
    "regular_counts = {}\n",
    "playoff_counts = {}\n",
    "\n",
    "for sy in seasons:\n",
    "    r = scrape_transfermarkt_regular(sy)\n",
    "    if r is not None:\n",
    "        regular_counts[sy] = len(r)\n",
    "    \n",
    "    p = scrape_transfermarkt_playoffs(sy)\n",
    "    if p is not None:\n",
    "        playoff_counts[sy] = len(p)\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('VALIDATION SUMMARY')\n",
    "print('='*80)\n",
    "print(f'Regular seasons scraped: {len(regular_counts)}')\n",
    "print(f'Playoff seasons scraped: {len(playoff_counts)}')\n",
    "\n",
    "import pandas as pd\n",
    "summary_df = pd.DataFrame({\n",
    "    'season_year': list(regular_counts.keys()), \n",
    "    'regular_matches': list(regular_counts.values())\n",
    "}).sort_values('season_year')\n",
    "\n",
    "print('\\nDetailed breakdown:')\n",
    "display(summary_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
