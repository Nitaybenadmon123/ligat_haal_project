{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce608d64",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8906a98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Environment setup complete\n",
      "   ROOT: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\n",
      "   DATA_DIR: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\n"
     ]
    }
   ],
   "source": [
    "# Environment setup\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    DOTENV_AVAILABLE = True\n",
    "except Exception:\n",
    "    DOTENV_AVAILABLE = False\n",
    "\n",
    "# Helper to find project root\n",
    "def _find_root(start: Optional[Path] = None) -> Path:\n",
    "    p = start or Path.cwd()\n",
    "    for _ in range(6):\n",
    "        if (p / 'data').exists() or (p / '.git').exists() or (p / 'notebooks').exists():\n",
    "            return p\n",
    "        p = p.parent\n",
    "    return Path.cwd()\n",
    "\n",
    "# Resolve project directories consistently\n",
    "ROOT = _find_root()\n",
    "DATA_DIR = ROOT / 'data' / 'raw'\n",
    "INTERIM_DIR = ROOT / 'data' / 'interim'\n",
    "PROCESSED_DIR = ROOT / 'data' / 'processed'\n",
    "FIG_DIR = ROOT / 'reports' / 'figures'\n",
    "for d in [DATA_DIR, INTERIM_DIR, PROCESSED_DIR, FIG_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"\\nüéØ Environment setup complete\")\n",
    "print(f\"   ROOT: {ROOT}\")\n",
    "print(f\"   DATA_DIR: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7871e7",
   "metadata": {},
   "source": [
    "## 2. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31f34834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Helper functions loaded\n"
     ]
    }
   ],
   "source": [
    "# Helper functions for scraping\n",
    "from typing import Optional\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "_USER_AGENTS = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0 Safari/537.36\",\n",
    "]\n",
    "\n",
    "def find_repo_root(start: Optional[Path] = None) -> Path:\n",
    "    p = start or Path.cwd()\n",
    "    for _ in range(6):\n",
    "        if (p / 'data').exists() or (p / '.git').exists() or (p / 'notebooks').exists():\n",
    "            return p\n",
    "        p = p.parent\n",
    "    return Path.cwd()\n",
    "\n",
    "def ensure_environment():\n",
    "    global ROOT, DATA_DIR, INTERIM_DIR, PROCESSED_DIR, FIG_DIR\n",
    "    if 'ROOT' not in globals() or not isinstance(ROOT, Path) or not (ROOT / 'data').exists():\n",
    "        root_guess = find_repo_root(Path.cwd())\n",
    "        if not (root_guess / 'data').exists() and (root_guess.parent / 'data').exists():\n",
    "            root_guess = root_guess.parent\n",
    "        ROOT = root_guess\n",
    "    DATA_DIR = ROOT / 'data' / 'raw'\n",
    "    INTERIM_DIR = ROOT / 'data' / 'interim'\n",
    "    PROCESSED_DIR = ROOT / 'data' / 'processed'\n",
    "    FIG_DIR = ROOT / 'reports' / 'figures'\n",
    "    for d in [DATA_DIR, INTERIM_DIR, PROCESSED_DIR, FIG_DIR]:\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "    return ROOT, DATA_DIR, INTERIM_DIR, PROCESSED_DIR, FIG_DIR\n",
    "\n",
    "\n",
    "def http_get(url: str, headers: Optional[dict] = None, retries: int = 3, timeout: int = 30) -> str:\n",
    "    last_err = None\n",
    "    sess = requests.Session()\n",
    "    for attempt in range(1, retries + 1):\n",
    "        ua = random.choice(_USER_AGENTS)\n",
    "        hdrs = {\"User-Agent\": ua, \"Accept-Language\": \"en-US,en;q=0.9\"}\n",
    "        if headers:\n",
    "            hdrs.update(headers)\n",
    "        try:\n",
    "            resp = sess.get(url, headers=hdrs, timeout=timeout)\n",
    "            resp.raise_for_status()\n",
    "            return resp.text\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            time.sleep(0.8 * attempt)\n",
    "    raise last_err  # type: ignore\n",
    "\n",
    "\n",
    "def save_csv(df: 'pd.DataFrame', path: Path, **to_csv_kwargs):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(path, index=False, encoding=to_csv_kwargs.get('encoding', 'utf-8-sig'))\n",
    "    print(f\"Saved: {path}\")\n",
    "\n",
    "print(\"‚úÖ Helper functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3161c26e",
   "metadata": {},
   "source": [
    "## 3. Wikipedia Match Results Scraper\n",
    "\n",
    "Scrapes match results from Wikipedia results matrix (\"Home \\\\ Away\" table).\n",
    "\n",
    "**Method:**\n",
    "- Finds results matrix on season page\n",
    "- Extracts team names from headers\n",
    "- Parses scores from each cell (format: \"X‚ÄìY\" or \"X-Y\")\n",
    "- Calculates points and result for each match\n",
    "\n",
    "**Note:** Wikipedia uses results matrix format, not match-by-match list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3f6b767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Wikipedia scraper function (robust) ready\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from datetime import datetime\n",
    "import urllib.parse\n",
    "\n",
    "# Robust Wikipedia season scraper\n",
    "# Differences vs original: improved table detection using regex (handles variations like 'Home \\\\ Away', 'Home / Away')\n",
    "\n",
    "def _season_title(season_year: int) -> str:\n",
    "    # Use Israeli Premier League season page naming\n",
    "    end_two = str(season_year + 1)[-2:]\n",
    "    return f\"{season_year}\\u2013{end_two} Israeli Premier League\"\n",
    "\n",
    "def _build_wiki_url(season_year: int) -> str:\n",
    "    title = _season_title(season_year)\n",
    "    encoded = urllib.parse.quote(title, safe='')\n",
    "    return f\"https://en.wikipedia.org/wiki/{encoded}\"\n",
    "\n",
    "\n",
    "def scrape_season(season_year: int):\n",
    "    \"\"\"\n",
    "    Scrape a single season's matches from Wikipedia results matrix.\n",
    "\n",
    "    Args:\n",
    "        season_year: Starting year (e.g., 2016 for 2016/17 season)\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with match results (season, teams, goals, points) or None on failure.\n",
    "    \"\"\"\n",
    "    season_str = f\"{season_year}/{str(season_year+1)[-2:]}\"\n",
    "    url = _build_wiki_url(season_year)\n",
    "\n",
    "    print(f\"Fetching {season_str}... \", end=\"\", flush=True)\n",
    "    try:\n",
    "        html = http_get(url)\n",
    "        if not html:\n",
    "            print(\"‚ùå (empty HTML)\")\n",
    "            return None\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "        # Find results matrix (first wikitable whose first header cell mentions Home & Away)\n",
    "        results_table = None\n",
    "        for table in soup.find_all(\"table\", class_=\"wikitable\"):\n",
    "            first_row = table.find(\"tr\")\n",
    "            if not first_row:\n",
    "                continue\n",
    "            first_cell = first_row.find(\"th\")\n",
    "            if not first_cell:\n",
    "                continue\n",
    "            header_text = first_cell.get_text(\" \", strip=True)\n",
    "            if re.search(r\"Home.*Away\", header_text, re.IGNORECASE):\n",
    "                results_table = table\n",
    "                break\n",
    "\n",
    "        if not results_table:\n",
    "            print(\"‚ùå (no results matrix)\")\n",
    "            return None\n",
    "\n",
    "        rows = results_table.find_all(\"tr\")\n",
    "        if len(rows) < 2:\n",
    "            print(\"‚ùå (matrix has no data rows)\")\n",
    "            return None\n",
    "        # First header row: team names (skip first corner cell)\n",
    "        team_names = [th.get_text(strip=True) for th in rows[0].find_all(\"th\")][1:]\n",
    "        if not team_names:\n",
    "            print(\"‚ùå (no team headers)\")\n",
    "            return None\n",
    "\n",
    "        matches = []\n",
    "        for row in rows[1:]:\n",
    "            cells = row.find_all([\"th\", \"td\"])\n",
    "            if len(cells) < len(team_names) + 1:\n",
    "                # Probably a separator or malformed row\n",
    "                continue\n",
    "            home_team = cells[0].get_text(strip=True)\n",
    "            # Iterate over away teams\n",
    "            for idx, cell in enumerate(cells[1:]):\n",
    "                if idx >= len(team_names):\n",
    "                    break\n",
    "                away_team = team_names[idx]\n",
    "                score_text = cell.get_text(strip=True)\n",
    "                # Accept formats like '1‚Äì0', '2-1' (different dash characters)\n",
    "                if re.match(r\"^\\d+\\s*[‚Äì-]\\s*\\d+$\", score_text):\n",
    "                    home_goals, away_goals = re.split(r\"[‚Äì-]\", score_text)\n",
    "                    matches.append({\n",
    "                        \"season\": season_str,\n",
    "                        \"season_year\": season_year,\n",
    "                        \"home_team\": home_team,\n",
    "                        \"away_team\": away_team,\n",
    "                        \"home_goals\": int(home_goals.strip()),\n",
    "                        \"away_goals\": int(away_goals.strip())\n",
    "                    })\n",
    "\n",
    "        if not matches:\n",
    "            print(\"‚ùå (no matches found)\")\n",
    "            return None\n",
    "\n",
    "        df = pd.DataFrame(matches)\n",
    "        # Derived columns\n",
    "        df['goal_diff'] = df['home_goals'] - df['away_goals']\n",
    "        df['result'] = df['goal_diff'].apply(lambda x: 'H' if x > 0 else ('A' if x < 0 else 'D'))\n",
    "        df['home_points'] = df['result'].map({'H': 3, 'D': 1, 'A': 0}).astype(int)\n",
    "        df['away_points'] = df['result'].map({'A': 3, 'D': 1, 'H': 0}).astype(int)\n",
    "\n",
    "        keep_cols = ['season', 'season_year', 'home_team', 'away_team', 'home_goals', 'away_goals', 'goal_diff', 'result', 'home_points', 'away_points']\n",
    "        df = df[keep_cols]\n",
    "        print(f\"‚úì ({len(df)} matches)\")\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ({str(e)[:60]}...)\")\n",
    "        return None\n",
    "\n",
    "print(\"‚úÖ Wikipedia scraper function (robust) ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a0287d",
   "metadata": {},
   "source": [
    "## 4. Multi-Season Collection (Wikipedia)\n",
    "\n",
    "Scrapes match results for last 20 seasons from Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed4eb397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping 20 seasons from Wikipedia (2006/07 to 2025/26)...\n",
      "================================================================================\n",
      "Fetching 2006/07... ‚úì (132 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2006_07_ligat_haal_wikipedia.csv\n",
      "‚úì (132 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2006_07_ligat_haal_wikipedia.csv\n",
      "Fetching 2007/08... Fetching 2007/08... ‚úì (132 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2007_08_ligat_haal_wikipedia.csv\n",
      "‚úì (132 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2007_08_ligat_haal_wikipedia.csv\n",
      "Fetching 2008/09... Fetching 2008/09... ‚úì (132 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2008_09_ligat_haal_wikipedia.csv\n",
      "‚úì (132 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2008_09_ligat_haal_wikipedia.csv\n",
      "Fetching 2009/10... Fetching 2009/10... ‚úì (239 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2009_10_ligat_haal_wikipedia.csv\n",
      "‚úì (239 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2009_10_ligat_haal_wikipedia.csv\n",
      "Fetching 2010/11... Fetching 2010/11... ‚úì (234 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2010_11_ligat_haal_wikipedia.csv\n",
      "‚úì (234 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2010_11_ligat_haal_wikipedia.csv\n",
      "Fetching 2011/12... Fetching 2011/12... ‚úì (240 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2011_12_ligat_haal_wikipedia.csv\n",
      "‚úì (240 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2011_12_ligat_haal_wikipedia.csv\n",
      "Fetching 2012/13... Fetching 2012/13... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2012_13_ligat_haal_wikipedia.csv\n",
      "‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2012_13_ligat_haal_wikipedia.csv\n",
      "Fetching 2013/14... Fetching 2013/14... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2013_14_ligat_haal_wikipedia.csv\n",
      "‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2013_14_ligat_haal_wikipedia.csv\n",
      "Fetching 2014/15... Fetching 2014/15... ‚úì (181 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2014_15_ligat_haal_wikipedia.csv\n",
      "‚úì (181 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2014_15_ligat_haal_wikipedia.csv\n",
      "Fetching 2015/16... Fetching 2015/16... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2015_16_ligat_haal_wikipedia.csv\n",
      "‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2015_16_ligat_haal_wikipedia.csv\n",
      "Fetching 2016/17... Fetching 2016/17... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2016_17_ligat_haal_wikipedia.csv\n",
      "‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2016_17_ligat_haal_wikipedia.csv\n",
      "Fetching 2017/18... Fetching 2017/18... ‚úì (181 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2017_18_ligat_haal_wikipedia.csv\n",
      "‚úì (181 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2017_18_ligat_haal_wikipedia.csv\n",
      "Fetching 2018/19... Fetching 2018/19... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2018_19_ligat_haal_wikipedia.csv\n",
      "‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2018_19_ligat_haal_wikipedia.csv\n",
      "Fetching 2019/20... Fetching 2019/20... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2019_20_ligat_haal_wikipedia.csv\n",
      "‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2019_20_ligat_haal_wikipedia.csv\n",
      "Fetching 2020/21... Fetching 2020/21... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2020_21_ligat_haal_wikipedia.csv\n",
      "‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2020_21_ligat_haal_wikipedia.csv\n",
      "Fetching 2021/22... Fetching 2021/22... ‚úì (181 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2021_22_ligat_haal_wikipedia.csv\n",
      "‚úì (181 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2021_22_ligat_haal_wikipedia.csv\n",
      "Fetching 2022/23... Fetching 2022/23... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2022_23_ligat_haal_wikipedia.csv\n",
      "‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2022_23_ligat_haal_wikipedia.csv\n",
      "Fetching 2023/24... Fetching 2023/24... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2023_24_ligat_haal_wikipedia.csv\n",
      "‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2023_24_ligat_haal_wikipedia.csv\n",
      "Fetching 2024/25... Fetching 2024/25... ‚úì (179 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2024_25_ligat_haal_wikipedia.csv\n",
      "‚úì (179 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2024_25_ligat_haal_wikipedia.csv\n",
      "Fetching 2025/26... Fetching 2025/26... ‚úì (64 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2025_26_ligat_haal_wikipedia.csv\n",
      "‚úì (64 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2025_26_ligat_haal_wikipedia.csv\n",
      "\n",
      "================================================================================\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_all_seasons_ligat_haal_wikipedia.csv\n",
      "\n",
      "üìä Summary:\n",
      "   Successfully scraped: 20 seasons\n",
      "   Total matches: 3533\n",
      "\n",
      "   Matches per season:\n",
      "      ‚Ä¢ 2006/07: 132 matches\n",
      "      ‚Ä¢ 2007/08: 132 matches\n",
      "      ‚Ä¢ 2008/09: 132 matches\n",
      "      ‚Ä¢ 2009/10: 239 matches\n",
      "      ‚Ä¢ 2010/11: 234 matches\n",
      "      ‚Ä¢ 2011/12: 240 matches\n",
      "      ‚Ä¢ 2012/13: 182 matches\n",
      "      ‚Ä¢ 2013/14: 182 matches\n",
      "      ‚Ä¢ 2014/15: 181 matches\n",
      "      ‚Ä¢ 2015/16: 182 matches\n",
      "      ‚Ä¢ 2016/17: 182 matches\n",
      "      ‚Ä¢ 2017/18: 181 matches\n",
      "      ‚Ä¢ 2018/19: 182 matches\n",
      "      ‚Ä¢ 2019/20: 182 matches\n",
      "      ‚Ä¢ 2020/21: 182 matches\n",
      "      ‚Ä¢ 2021/22: 181 matches\n",
      "      ‚Ä¢ 2022/23: 182 matches\n",
      "      ‚Ä¢ 2023/24: 182 matches\n",
      "      ‚Ä¢ 2024/25: 179 matches\n",
      "      ‚Ä¢ 2025/26:  64 matches\n",
      "\n",
      "   All matches saved to: matches_all_seasons_ligat_haal_wikipedia.csv\n",
      "\n",
      "   Sample data:\n",
      "\n",
      "================================================================================\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_all_seasons_ligat_haal_wikipedia.csv\n",
      "\n",
      "üìä Summary:\n",
      "   Successfully scraped: 20 seasons\n",
      "   Total matches: 3533\n",
      "\n",
      "   Matches per season:\n",
      "      ‚Ä¢ 2006/07: 132 matches\n",
      "      ‚Ä¢ 2007/08: 132 matches\n",
      "      ‚Ä¢ 2008/09: 132 matches\n",
      "      ‚Ä¢ 2009/10: 239 matches\n",
      "      ‚Ä¢ 2010/11: 234 matches\n",
      "      ‚Ä¢ 2011/12: 240 matches\n",
      "      ‚Ä¢ 2012/13: 182 matches\n",
      "      ‚Ä¢ 2013/14: 182 matches\n",
      "      ‚Ä¢ 2014/15: 181 matches\n",
      "      ‚Ä¢ 2015/16: 182 matches\n",
      "      ‚Ä¢ 2016/17: 182 matches\n",
      "      ‚Ä¢ 2017/18: 181 matches\n",
      "      ‚Ä¢ 2018/19: 182 matches\n",
      "      ‚Ä¢ 2019/20: 182 matches\n",
      "      ‚Ä¢ 2020/21: 182 matches\n",
      "      ‚Ä¢ 2021/22: 181 matches\n",
      "      ‚Ä¢ 2022/23: 182 matches\n",
      "      ‚Ä¢ 2023/24: 182 matches\n",
      "      ‚Ä¢ 2024/25: 179 matches\n",
      "      ‚Ä¢ 2025/26:  64 matches\n",
      "\n",
      "   All matches saved to: matches_all_seasons_ligat_haal_wikipedia.csv\n",
      "\n",
      "   Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>season_year</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>home_goals</th>\n",
       "      <th>away_goals</th>\n",
       "      <th>goal_diff</th>\n",
       "      <th>result</th>\n",
       "      <th>home_points</th>\n",
       "      <th>away_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>2006</td>\n",
       "      <td>Beitar Jerusalem</td>\n",
       "      <td>BnY</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>2006</td>\n",
       "      <td>Beitar Jerusalem</td>\n",
       "      <td>ASH</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>H</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>2006</td>\n",
       "      <td>Beitar Jerusalem</td>\n",
       "      <td>HAK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>2006</td>\n",
       "      <td>Beitar Jerusalem</td>\n",
       "      <td>HKS</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>H</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>2006</td>\n",
       "      <td>Beitar Jerusalem</td>\n",
       "      <td>HPT</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>H</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>2006</td>\n",
       "      <td>Beitar Jerusalem</td>\n",
       "      <td>HTA</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>2006</td>\n",
       "      <td>Beitar Jerusalem</td>\n",
       "      <td>MHA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>2006</td>\n",
       "      <td>Beitar Jerusalem</td>\n",
       "      <td>MHE</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>H</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>2006</td>\n",
       "      <td>Beitar Jerusalem</td>\n",
       "      <td>MNE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2006/07</td>\n",
       "      <td>2006</td>\n",
       "      <td>Beitar Jerusalem</td>\n",
       "      <td>MPT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    season  season_year         home_team away_team  home_goals  away_goals  \\\n",
       "0  2006/07         2006  Beitar Jerusalem       BnY           0           0   \n",
       "1  2006/07         2006  Beitar Jerusalem       ASH           2           0   \n",
       "2  2006/07         2006  Beitar Jerusalem       HAK           0           0   \n",
       "3  2006/07         2006  Beitar Jerusalem       HKS           2           0   \n",
       "4  2006/07         2006  Beitar Jerusalem       HPT           2           0   \n",
       "5  2006/07         2006  Beitar Jerusalem       HTA           2           1   \n",
       "6  2006/07         2006  Beitar Jerusalem       MHA           1           1   \n",
       "7  2006/07         2006  Beitar Jerusalem       MHE           3           0   \n",
       "8  2006/07         2006  Beitar Jerusalem       MNE           0           0   \n",
       "9  2006/07         2006  Beitar Jerusalem       MPT           0           0   \n",
       "\n",
       "   goal_diff result  home_points  away_points  \n",
       "0          0      D            1            1  \n",
       "1          2      H            3            0  \n",
       "2          0      D            1            1  \n",
       "3          2      H            3            0  \n",
       "4          2      H            3            0  \n",
       "5          1      H            3            0  \n",
       "6          0      D            1            1  \n",
       "7          3      H            3            0  \n",
       "8          0      D            1            1  \n",
       "9          0      D            1            1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scrape multiple seasons of Ligat Ha'al from Wikipedia\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "ensure_environment()\n",
    "\n",
    "# List of seasons to scrape (last 20 seasons)\n",
    "current_year = datetime.now().year\n",
    "if datetime.now().month < 8:  # If before August, last season started in previous year\n",
    "    current_year -= 1\n",
    "seasons = list(range(current_year - 19, current_year + 1))\n",
    "\n",
    "print(f\"Scraping {len(seasons)} seasons from Wikipedia ({seasons[0]}/{str(seasons[0]+1)[-2:]} to {seasons[-1]}/{str(seasons[-1]+1)[-2:]})...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Scrape each season\n",
    "all_matches = []\n",
    "for season_year in seasons:\n",
    "    df = scrape_season(season_year)\n",
    "    if df is not None:\n",
    "        # Save individual season\n",
    "        season_path = DATA_DIR / f\"matches_{season_year}_{str(season_year+1)[-2:]}_ligat_haal_wikipedia.csv\"\n",
    "        save_csv(df, season_path)\n",
    "        all_matches.append(df)\n",
    "    time.sleep(1)  # Be nice to Wikipedia\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "if all_matches:\n",
    "    # Combine all seasons\n",
    "    combined_df = pd.concat(all_matches, ignore_index=True)\n",
    "    combined_path = DATA_DIR / \"matches_all_seasons_ligat_haal_wikipedia.csv\"\n",
    "    save_csv(combined_df, combined_path)\n",
    "    \n",
    "    print(f\"\\nüìä Summary:\")\n",
    "    print(f\"   Successfully scraped: {len(all_matches)} seasons\")\n",
    "    print(f\"   Total matches: {len(combined_df)}\")\n",
    "    print(f\"\\n   Matches per season:\")\n",
    "    season_counts = combined_df.groupby('season').size().sort_index()\n",
    "    for season, count in season_counts.items():\n",
    "        print(f\"      ‚Ä¢ {season}: {count:3d} matches\")\n",
    "    print(f\"\\n   All matches saved to: {combined_path.name}\")\n",
    "    \n",
    "    # Display sample\n",
    "    print(f\"\\n   Sample data:\")\n",
    "    display(combined_df.head(10))\n",
    "else:\n",
    "    print(\"\\n‚ùå No matches were successfully scraped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8f6043d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Transfermarkt scraper function defined\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_transfermarkt_regular(season_year):\n",
    "    \"\"\"\n",
    "    Scrape regular season matches from Transfermarkt gesamtspielplan page.\n",
    "    \n",
    "    Args:\n",
    "        season_year: Starting year (e.g., 2023 for 2023/24)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with columns: round, home, score, away\n",
    "    \"\"\"\n",
    "    url = f\"https://www.transfermarkt.com/ligat-haal/gesamtspielplan/wettbewerb/ISR1?saison_id={season_year}\"\n",
    "    print(f\"Scraping Transfermarkt {season_year}/{str(season_year+1)[-2:]}... \", end=\"\", flush=True)\n",
    "    \n",
    "    try:\n",
    "        html = http_get(url)\n",
    "        if not html:\n",
    "            print(\"‚ùå (no HTML)\")\n",
    "            return None\n",
    "        \n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        rows_out = []\n",
    "        round_num = 0\n",
    "        \n",
    "        # Find all tables on the page\n",
    "        tables = soup.find_all('table')\n",
    "        \n",
    "        for table in tables:\n",
    "            # Look for match rows (rows with 2 team links)\n",
    "            for tr in table.find_all('tr'):\n",
    "                # Find all cells\n",
    "                cells = tr.find_all('td')\n",
    "                if len(cells) < 5:\n",
    "                    continue\n",
    "                \n",
    "                # Find score first to confirm this is a match row\n",
    "                score_link = tr.find('a', class_='ergebnis-link')\n",
    "                if not score_link:\n",
    "                    continue\n",
    "                \n",
    "                score_text = score_link.get_text(strip=True)\n",
    "                # Validate score format (d:d)\n",
    "                if not re.match(r'^\\d+:\\d+$', score_text):\n",
    "                    continue\n",
    "                \n",
    "                # Now find team links - typically in cells before and after score\n",
    "                all_team_links = []\n",
    "                for cell in cells:\n",
    "                    team_link = cell.find('a', href=re.compile(r'/verein/'))\n",
    "                    if team_link:\n",
    "                        team_name = team_link.get_text(strip=True)\n",
    "                        if team_name and team_name not in [link.get_text(strip=True) for link in all_team_links]:\n",
    "                            all_team_links.append(team_link)\n",
    "                \n",
    "                if len(all_team_links) < 2:\n",
    "                    continue\n",
    "                \n",
    "                home = all_team_links[0].get_text(strip=True)\n",
    "                away = all_team_links[1].get_text(strip=True)\n",
    "                \n",
    "                # Increment round for each match found\n",
    "                round_num += 1\n",
    "                \n",
    "                rows_out.append({\n",
    "                    'round': round_num,\n",
    "                    'home': home,\n",
    "                    'score': score_text,\n",
    "                    'away': away\n",
    "                })\n",
    "        \n",
    "        if not rows_out:\n",
    "            print(\"‚ö†Ô∏è (no matches)\")\n",
    "            return None\n",
    "        \n",
    "        df = pd.DataFrame(rows_out)\n",
    "        print(f\"‚úì ({len(df)} matches)\")\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ({str(e)[:50]}...)\")\n",
    "        return None\n",
    "\n",
    "print(\"‚úÖ Transfermarkt scraper function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcca5d3",
   "metadata": {},
   "source": [
    "## 5. Transfermarkt Match Results Scraper\n",
    "\n",
    "Scrapes match results from Transfermarkt with round numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "85cfeb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping 20 seasons from Transfermarkt (2006/07 to 2025/26)...\n",
      "================================================================================\n",
      "Scraping Transfermarkt 2006/07... ‚úì (198 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2006_07_ligat_haal_transfermarkt.csv\n",
      "‚úì (198 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2006_07_ligat_haal_transfermarkt.csv\n",
      "Scraping Transfermarkt 2007/08... Scraping Transfermarkt 2007/08... ‚úì (198 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2007_08_ligat_haal_transfermarkt.csv\n",
      "‚úì (198 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2007_08_ligat_haal_transfermarkt.csv\n",
      "Scraping Transfermarkt 2008/09... Scraping Transfermarkt 2008/09... ‚úì (198 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2008_09_ligat_haal_transfermarkt.csv\n",
      "‚úì (198 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2008_09_ligat_haal_transfermarkt.csv\n",
      "Scraping Transfermarkt 2009/10... Scraping Transfermarkt 2009/10... ‚úì (240 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2009_10_ligat_haal_transfermarkt.csv\n",
      "‚úì (240 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2009_10_ligat_haal_transfermarkt.csv\n",
      "Scraping Transfermarkt 2010/11... Scraping Transfermarkt 2010/11... ‚úì (240 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2010_11_ligat_haal_transfermarkt.csv\n",
      "‚úì (240 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2010_11_ligat_haal_transfermarkt.csv\n",
      "Scraping Transfermarkt 2011/12... Scraping Transfermarkt 2011/12... ‚úì (240 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2011_12_ligat_haal_transfermarkt.csv\n",
      "‚úì (240 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2011_12_ligat_haal_transfermarkt.csv\n",
      "Scraping Transfermarkt 2012/13... Scraping Transfermarkt 2012/13... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2012_13_ligat_haal_transfermarkt.csv\n",
      "‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2012_13_ligat_haal_transfermarkt.csv\n",
      "Scraping Transfermarkt 2013/14... Scraping Transfermarkt 2013/14... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2013_14_ligat_haal_transfermarkt.csv\n",
      "‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2013_14_ligat_haal_transfermarkt.csv\n",
      "Scraping Transfermarkt 2014/15... Scraping Transfermarkt 2014/15... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2014_15_ligat_haal_transfermarkt.csv\n",
      "‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2014_15_ligat_haal_transfermarkt.csv\n",
      "Scraping Transfermarkt 2015/16... Scraping Transfermarkt 2015/16... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2015_16_ligat_haal_transfermarkt.csv\n",
      "‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2015_16_ligat_haal_transfermarkt.csv\n",
      "Scraping Transfermarkt 2016/17... Scraping Transfermarkt 2016/17... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2016_17_ligat_haal_transfermarkt.csv\n",
      "‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2016_17_ligat_haal_transfermarkt.csv\n",
      "Scraping Transfermarkt 2017/18... Scraping Transfermarkt 2017/18... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2017_18_ligat_haal_transfermarkt.csv\n",
      "‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2017_18_ligat_haal_transfermarkt.csv\n",
      "Scraping Transfermarkt 2018/19... Scraping Transfermarkt 2018/19... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2018_19_ligat_haal_transfermarkt.csv\n",
      "‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2018_19_ligat_haal_transfermarkt.csv\n",
      "Scraping Transfermarkt 2019/20... Scraping Transfermarkt 2019/20... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2019_20_ligat_haal_transfermarkt.csv\n",
      "‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2019_20_ligat_haal_transfermarkt.csv\n",
      "Scraping Transfermarkt 2020/21... Scraping Transfermarkt 2020/21... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2020_21_ligat_haal_transfermarkt.csv\n",
      "‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2020_21_ligat_haal_transfermarkt.csv\n",
      "Scraping Transfermarkt 2021/22... Scraping Transfermarkt 2021/22... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2021_22_ligat_haal_transfermarkt.csv\n",
      "‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2021_22_ligat_haal_transfermarkt.csv\n",
      "Scraping Transfermarkt 2022/23... Scraping Transfermarkt 2022/23... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2022_23_ligat_haal_transfermarkt.csv\n",
      "‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2022_23_ligat_haal_transfermarkt.csv\n",
      "Scraping Transfermarkt 2023/24... Scraping Transfermarkt 2023/24... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2023_24_ligat_haal_transfermarkt.csv\n",
      "‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2023_24_ligat_haal_transfermarkt.csv\n",
      "Scraping Transfermarkt 2024/25... Scraping Transfermarkt 2024/25... ‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2024_25_ligat_haal_transfermarkt.csv\n",
      "‚úì (182 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2024_25_ligat_haal_transfermarkt.csv\n",
      "Scraping Transfermarkt 2025/26... Scraping Transfermarkt 2025/26... ‚úì (74 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2025_26_ligat_haal_transfermarkt.csv\n",
      "‚úì (74 matches)\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_2025_26_ligat_haal_transfermarkt.csv\n",
      "\n",
      "================================================================================\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_all_seasons_ligat_haal_transfermarkt.csv\n",
      "\n",
      "üìä Transfermarkt Summary:\n",
      "   Successfully scraped: 20 seasons\n",
      "   Total matches: 3754\n",
      "\n",
      "   Matches per season:\n",
      "      ‚Ä¢ 2006/07: 198 matches\n",
      "      ‚Ä¢ 2007/08: 198 matches\n",
      "      ‚Ä¢ 2008/09: 198 matches\n",
      "      ‚Ä¢ 2009/10: 240 matches\n",
      "      ‚Ä¢ 2010/11: 240 matches\n",
      "      ‚Ä¢ 2011/12: 240 matches\n",
      "      ‚Ä¢ 2012/13: 182 matches\n",
      "      ‚Ä¢ 2013/14: 182 matches\n",
      "      ‚Ä¢ 2014/15: 182 matches\n",
      "      ‚Ä¢ 2015/16: 182 matches\n",
      "      ‚Ä¢ 2016/17: 182 matches\n",
      "      ‚Ä¢ 2017/18: 182 matches\n",
      "      ‚Ä¢ 2018/19: 182 matches\n",
      "      ‚Ä¢ 2019/20: 182 matches\n",
      "      ‚Ä¢ 2020/21: 182 matches\n",
      "      ‚Ä¢ 2021/22: 182 matches\n",
      "      ‚Ä¢ 2022/23: 182 matches\n",
      "      ‚Ä¢ 2023/24: 182 matches\n",
      "      ‚Ä¢ 2024/25: 182 matches\n",
      "      ‚Ä¢ 2025/26:  74 matches\n",
      "\n",
      "   All matches saved to: matches_all_seasons_ligat_haal_transfermarkt.csv\n",
      "\n",
      "   Sample data:\n",
      "\n",
      "================================================================================\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\\matches_all_seasons_ligat_haal_transfermarkt.csv\n",
      "\n",
      "üìä Transfermarkt Summary:\n",
      "   Successfully scraped: 20 seasons\n",
      "   Total matches: 3754\n",
      "\n",
      "   Matches per season:\n",
      "      ‚Ä¢ 2006/07: 198 matches\n",
      "      ‚Ä¢ 2007/08: 198 matches\n",
      "      ‚Ä¢ 2008/09: 198 matches\n",
      "      ‚Ä¢ 2009/10: 240 matches\n",
      "      ‚Ä¢ 2010/11: 240 matches\n",
      "      ‚Ä¢ 2011/12: 240 matches\n",
      "      ‚Ä¢ 2012/13: 182 matches\n",
      "      ‚Ä¢ 2013/14: 182 matches\n",
      "      ‚Ä¢ 2014/15: 182 matches\n",
      "      ‚Ä¢ 2015/16: 182 matches\n",
      "      ‚Ä¢ 2016/17: 182 matches\n",
      "      ‚Ä¢ 2017/18: 182 matches\n",
      "      ‚Ä¢ 2018/19: 182 matches\n",
      "      ‚Ä¢ 2019/20: 182 matches\n",
      "      ‚Ä¢ 2020/21: 182 matches\n",
      "      ‚Ä¢ 2021/22: 182 matches\n",
      "      ‚Ä¢ 2022/23: 182 matches\n",
      "      ‚Ä¢ 2023/24: 182 matches\n",
      "      ‚Ä¢ 2024/25: 182 matches\n",
      "      ‚Ä¢ 2025/26:  74 matches\n",
      "\n",
      "   All matches saved to: matches_all_seasons_ligat_haal_transfermarkt.csv\n",
      "\n",
      "   Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>home</th>\n",
       "      <th>score</th>\n",
       "      <th>away</th>\n",
       "      <th>season</th>\n",
       "      <th>season_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>H. Kfar Saba</td>\n",
       "      <td>4:1</td>\n",
       "      <td>H. Petah Tikva</td>\n",
       "      <td>2006/07</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M. Petah Tikva</td>\n",
       "      <td>0:0</td>\n",
       "      <td>Hakoah Amidar</td>\n",
       "      <td>2006/07</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>FC Ashdod</td>\n",
       "      <td>1:0</td>\n",
       "      <td>Maccabi Herzlya</td>\n",
       "      <td>2006/07</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Maccabi Netanya</td>\n",
       "      <td>3:1</td>\n",
       "      <td>Maccabi Haifa</td>\n",
       "      <td>2006/07</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M. Tel Aviv</td>\n",
       "      <td>1:2</td>\n",
       "      <td>B. Jerusalem</td>\n",
       "      <td>2006/07</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Bnei Yehuda</td>\n",
       "      <td>1:1</td>\n",
       "      <td>Hapoel Tel Aviv</td>\n",
       "      <td>2006/07</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Hakoah Amidar</td>\n",
       "      <td>3:2</td>\n",
       "      <td>Bnei Yehuda</td>\n",
       "      <td>2006/07</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Maccabi Herzlya</td>\n",
       "      <td>0:3</td>\n",
       "      <td>M. Petah Tikva</td>\n",
       "      <td>2006/07</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Maccabi Haifa</td>\n",
       "      <td>1:0</td>\n",
       "      <td>FC Ashdod</td>\n",
       "      <td>2006/07</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>H. Petah Tikva</td>\n",
       "      <td>0:0</td>\n",
       "      <td>Maccabi Netanya</td>\n",
       "      <td>2006/07</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   round             home score             away   season  season_year\n",
       "0      1     H. Kfar Saba   4:1   H. Petah Tikva  2006/07         2006\n",
       "1      2   M. Petah Tikva   0:0    Hakoah Amidar  2006/07         2006\n",
       "2      3        FC Ashdod   1:0  Maccabi Herzlya  2006/07         2006\n",
       "3      4  Maccabi Netanya   3:1    Maccabi Haifa  2006/07         2006\n",
       "4      5      M. Tel Aviv   1:2     B. Jerusalem  2006/07         2006\n",
       "5      6      Bnei Yehuda   1:1  Hapoel Tel Aviv  2006/07         2006\n",
       "6      7    Hakoah Amidar   3:2      Bnei Yehuda  2006/07         2006\n",
       "7      8  Maccabi Herzlya   0:3   M. Petah Tikva  2006/07         2006\n",
       "8      9    Maccabi Haifa   1:0        FC Ashdod  2006/07         2006\n",
       "9     10   H. Petah Tikva   0:0  Maccabi Netanya  2006/07         2006"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scrape multiple seasons from Transfermarkt\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "ensure_environment()\n",
    "\n",
    "# Use same season range as Wikipedia\n",
    "print(f\"Scraping {len(seasons)} seasons from Transfermarkt ({seasons[0]}/{str(seasons[0]+1)[-2:]} to {seasons[-1]}/{str(seasons[-1]+1)[-2:]})...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Scrape each season\n",
    "all_transfermarkt = []\n",
    "failed_seasons = []\n",
    "\n",
    "for season_year in seasons:\n",
    "    df = scrape_transfermarkt_regular(season_year)\n",
    "    if df is not None:\n",
    "        # Add season info\n",
    "        df['season'] = f\"{season_year}/{str(season_year+1)[-2:]}\"\n",
    "        df['season_year'] = season_year\n",
    "        \n",
    "        # Save individual season\n",
    "        season_path = DATA_DIR / f\"matches_{season_year}_{str(season_year+1)[-2:]}_ligat_haal_transfermarkt.csv\"\n",
    "        save_csv(df, season_path)\n",
    "        all_transfermarkt.append(df)\n",
    "    else:\n",
    "        failed_seasons.append(f\"{season_year}/{str(season_year+1)[-2:]}\")\n",
    "    \n",
    "    time.sleep(1.2)  # Be polite to Transfermarkt\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "if all_transfermarkt:\n",
    "    # Combine all seasons\n",
    "    combined_tm = pd.concat(all_transfermarkt, ignore_index=True)\n",
    "    combined_path_tm = DATA_DIR / \"matches_all_seasons_ligat_haal_transfermarkt.csv\"\n",
    "    save_csv(combined_tm, combined_path_tm)\n",
    "    \n",
    "    print(f\"\\nüìä Transfermarkt Summary:\")\n",
    "    print(f\"   Successfully scraped: {len(all_transfermarkt)} seasons\")\n",
    "    print(f\"   Total matches: {len(combined_tm)}\")\n",
    "    \n",
    "    if failed_seasons:\n",
    "        print(f\"   ‚ö†Ô∏è  Failed seasons: {', '.join(failed_seasons)}\")\n",
    "    \n",
    "    print(f\"\\n   Matches per season:\")\n",
    "    tm_counts = combined_tm.groupby('season').size().sort_index()\n",
    "    for season, count in tm_counts.items():\n",
    "        print(f\"      ‚Ä¢ {season}: {count:3d} matches\")\n",
    "    print(f\"\\n   All matches saved to: {combined_path_tm.name}\")\n",
    "    \n",
    "    # Display sample\n",
    "    print(f\"\\n   Sample data:\")\n",
    "    display(combined_tm.head(10))\n",
    "else:\n",
    "    print(\"\\n‚ùå No matches were successfully scraped from Transfermarkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fbd008",
   "metadata": {},
   "source": [
    "## 6. Multi-Season Collection (Transfermarkt)\n",
    "\n",
    "Scrapes all seasons from Transfermarkt with round information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d279eaf",
   "metadata": {},
   "source": [
    "## 7. Team Name Normalization\n",
    "\n",
    "Wikipedia uses inconsistent team names across seasons (abbreviations, variants).\n",
    "This mapping consolidates all variations to standardized full names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e64a010d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Team Name Mapping Loaded:\n",
      "  ‚Ä¢ 32 abbreviations\n",
      "  ‚Ä¢ 31 unique teams\n"
     ]
    }
   ],
   "source": [
    "# Team Name Mapping - Normalizes abbreviations and variants to full names\n",
    "# This mapping consolidates Wikipedia's inconsistent team naming across 20 seasons\n",
    "\n",
    "TEAM_NAME_MAP = {\n",
    "    # Abbreviations to full names\n",
    "    'ASH': 'F.C. Ashdod',\n",
    "    'BEI': 'Beitar Jerusalem',\n",
    "    'BnS': 'Bnei Sakhnin',\n",
    "    'BnY': 'Bnei Yehuda',\n",
    "    'HAS': 'Hapoel Ashkelon',\n",
    "    'HBS': \"Hapoel Be'er Sheva\",\n",
    "    'HHA': 'Hapoel Haifa',\n",
    "    'HKS': 'Hapoel Kfar Saba',\n",
    "    'HRA': \"Hapoel Ra'anana\",\n",
    "    'HTA': 'Hapoel Tel Aviv',\n",
    "    'IKS': 'Ironi Kiryat Shmona',\n",
    "    'MHA': 'Maccabi Haifa',\n",
    "    'MPT': 'Maccabi Petah Tikva',\n",
    "    'MTA': 'Maccabi Tel Aviv',\n",
    "    'HPT': 'Hapoel Petah Tikva',\n",
    "    'HRG': 'Hapoel Ramat Gan',\n",
    "    'HRH': 'Hapoel Ramat HaSharon',\n",
    "    'HRL': 'Rishon LeZion',\n",
    "    'MAN': 'Maccabi Ahi Nazareth',\n",
    "    'MBR': 'Maccabi Bnei Reineh',\n",
    "    'SNZ': 'Sektzia Ness Ziona',\n",
    "    'HAK': 'Hapoel Acre',\n",
    "    'MHE': 'Maccabi Herzliya',\n",
    "    'MNE': 'Maccabi Netanya',\n",
    "    'HAR': 'Hapoel Raanana',\n",
    "    'HAC': 'Hapoel Acre',\n",
    "    'IRH': 'Ironi Ramat HaSharon',\n",
    "    'HAH': 'Hapoel Hadera',\n",
    "    'NES': 'Ness Ziona',\n",
    "    'HJE': 'Hapoel Jerusalem',\n",
    "    'HNG': 'Hapoel Nof HaGalil',\n",
    "    'ITI': 'Ironi Tiberias',\n",
    "    \n",
    "    # Name variants to canonical names\n",
    "    'Ashdod': 'F.C. Ashdod',\n",
    "    'F.C. Ironi Ashdod': 'F.C. Ashdod',\n",
    "    'Ness Ziona': 'Sektzia Ness Ziona',\n",
    "    'Ironi Nir Ramat HaSharon': 'Ironi Ramat HaSharon',\n",
    "    'Hakoah Amidar Ramat Gan': 'Hapoel Ramat Gan',\n",
    "    'Hapoel Rishon LeZion': 'Rishon LeZion',\n",
    "    'Hapoel Raanana': \"Hapoel Ra'anana\",\n",
    "    \n",
    "    # Full names map to themselves\n",
    "    'F.C. Ashdod': 'F.C. Ashdod',\n",
    "    'Beitar Jerusalem': 'Beitar Jerusalem',\n",
    "    'Bnei Sakhnin': 'Bnei Sakhnin',\n",
    "    'Bnei Yehuda': 'Bnei Yehuda',\n",
    "    'Hapoel Ashkelon': 'Hapoel Ashkelon',\n",
    "    \"Hapoel Be'er Sheva\": \"Hapoel Be'er Sheva\",\n",
    "    'Hapoel Haifa': 'Hapoel Haifa',\n",
    "    'Hapoel Kfar Saba': 'Hapoel Kfar Saba',\n",
    "    \"Hapoel Ra'anana\": \"Hapoel Ra'anana\",\n",
    "    'Hapoel Tel Aviv': 'Hapoel Tel Aviv',\n",
    "    'Ironi Kiryat Shmona': 'Ironi Kiryat Shmona',\n",
    "    'Maccabi Haifa': 'Maccabi Haifa',\n",
    "    'Maccabi Petah Tikva': 'Maccabi Petah Tikva',\n",
    "    'Maccabi Tel Aviv': 'Maccabi Tel Aviv',\n",
    "    'Hapoel Petah Tikva': 'Hapoel Petah Tikva',\n",
    "    'Hapoel Ramat Gan': 'Hapoel Ramat Gan',\n",
    "    'Hapoel Ramat HaSharon': 'Hapoel Ramat HaSharon',\n",
    "    'Rishon LeZion': 'Rishon LeZion',\n",
    "    'Maccabi Ahi Nazareth': 'Maccabi Ahi Nazareth',\n",
    "    'Maccabi Bnei Reineh': 'Maccabi Bnei Reineh',\n",
    "    'Sektzia Ness Ziona': 'Sektzia Ness Ziona',\n",
    "    'Hapoel Acre': 'Hapoel Acre',\n",
    "    'Maccabi Herzliya': 'Maccabi Herzliya',\n",
    "    'Maccabi Netanya': 'Maccabi Netanya',\n",
    "    'Ironi Ramat HaSharon': 'Ironi Ramat HaSharon',\n",
    "    'Hapoel Hadera': 'Hapoel Hadera',\n",
    "    'Hapoel Jerusalem': 'Hapoel Jerusalem',\n",
    "    'Hapoel Nof HaGalil': 'Hapoel Nof HaGalil',\n",
    "    'Ironi Tiberias': 'Ironi Tiberias',\n",
    "}\n",
    "\n",
    "def normalize_team_names(df, name_map=TEAM_NAME_MAP):\n",
    "    \"\"\"\n",
    "    Normalize team names by converting abbreviations and variants to full names.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with 'home_team' and 'away_team' columns\n",
    "        name_map: Dictionary mapping abbreviations/variants to standardized names\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with normalized team names\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['home_team'] = df['home_team'].map(lambda x: name_map.get(x, x))\n",
    "    df['away_team'] = df['away_team'].map(lambda x: name_map.get(x, x))\n",
    "    return df\n",
    "\n",
    "def apply_season_specific_fixes(df, season):\n",
    "    \"\"\"\n",
    "    Apply season-specific Wikipedia data corrections.\n",
    "    Wikipedia sometimes uses incorrect team names in their results matrices.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with match data\n",
    "        season: Season string (e.g., '2006/07')\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with season-specific fixes applied\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    if season == '2006/07':\n",
    "        df.loc[df['home_team'] == 'Hapoel Ramat Gan', 'home_team'] = 'Hapoel Acre'\n",
    "    elif season == '2008/09':\n",
    "        df.loc[df['home_team'] == 'Hapoel Ramat Gan', 'home_team'] = \"Hapoel Ra'anana\"\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"‚úÖ Team Name Mapping Loaded:\")\n",
    "print(f\"  ‚Ä¢ {len([k for k in TEAM_NAME_MAP.keys() if len(k) <= 3])} abbreviations\")\n",
    "print(f\"  ‚Ä¢ {len(set(TEAM_NAME_MAP.values()))} unique teams\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3b0967",
   "metadata": {},
   "source": [
    "## 8. Data Summary & Statistics\n",
    "\n",
    "Final validation and statistics for all scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5df9ee47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üìä DATA COLLECTION SUMMARY - REGULAR SEASON\n",
      "================================================================================\n",
      "\n",
      "üìÅ Files Collected:\n",
      "   Wikipedia matches: 21 seasons\n",
      "   Transfermarkt matches: 21 seasons\n",
      "\n",
      "‚úÖ Wikipedia Data:\n",
      "   Total matches: 3533\n",
      "   Seasons: 20\n",
      "   Season range: 2006/07 to 2025/26\n",
      "   Unique teams (before normalization): 64\n",
      "   Unique teams (after normalization): 31\n",
      "\n",
      "‚úÖ Transfermarkt Data:\n",
      "   Total matches: 3754\n",
      "   Seasons: 20\n",
      "   Season range: 2006/07 to 2025/26\n",
      "   Rounds: min=1, max=240\n",
      "   Unique teams: 29\n",
      "\n",
      "üìã Summary Table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Total Matches</th>\n",
       "      <th>Seasons</th>\n",
       "      <th>Teams (normalized)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>3533</td>\n",
       "      <td>20</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transfermarkt</td>\n",
       "      <td>3754</td>\n",
       "      <td>20</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Source  Total Matches  Seasons  Teams (normalized)\n",
       "0      Wikipedia           3533       20                  31\n",
       "1  Transfermarkt           3754       20                  29"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "‚úÖ DATA COLLECTION COMPLETE\n",
      "================================================================================\n",
      "\n",
      "üí° Next Steps:\n",
      "   1. Use team normalization functions for consistent analysis\n",
      "   2. Merge with attendance data (already collected)\n",
      "   3. Calculate league standings and rankings\n",
      "   4. Perform statistical analysis\n",
      "   5. Create visualizations\n",
      "\n",
      "üìÇ All data saved to: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\raw\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Final Summary: Combined statistics across all data sources\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "ensure_environment()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üìä DATA COLLECTION SUMMARY - REGULAR SEASON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check all collected files\n",
    "wiki_files = sorted(DATA_DIR.glob(\"matches_*_ligat_haal_wikipedia.csv\"))\n",
    "transfermarkt_files = sorted(DATA_DIR.glob(\"matches_*_ligat_haal_transfermarkt.csv\"))\n",
    "\n",
    "print(f\"\\nüìÅ Files Collected:\")\n",
    "print(f\"   Wikipedia matches: {len(wiki_files)} seasons\")\n",
    "print(f\"   Transfermarkt matches: {len(transfermarkt_files)} seasons\")\n",
    "\n",
    "# Load combined files if available\n",
    "wiki_combined = DATA_DIR / \"matches_all_seasons_ligat_haal_wikipedia.csv\"\n",
    "tm_combined = DATA_DIR / \"matches_all_seasons_ligat_haal_transfermarkt.csv\"\n",
    "\n",
    "stats_summary = []\n",
    "\n",
    "if wiki_combined.exists():\n",
    "    df_wiki = pd.read_csv(wiki_combined)\n",
    "    print(f\"\\n‚úÖ Wikipedia Data:\")\n",
    "    print(f\"   Total matches: {len(df_wiki)}\")\n",
    "    print(f\"   Seasons: {df_wiki['season'].nunique()}\")\n",
    "    print(f\"   Season range: {df_wiki['season'].min()} to {df_wiki['season'].max()}\")\n",
    "    \n",
    "    # Count unique teams\n",
    "    teams_wiki = set(df_wiki['home_team'].unique()) | set(df_wiki['away_team'].unique())\n",
    "    print(f\"   Unique teams (before normalization): {len(teams_wiki)}\")\n",
    "    \n",
    "    # Apply normalization and count again\n",
    "    df_wiki_normalized = normalize_team_names(df_wiki, TEAM_NAME_MAP)\n",
    "    teams_normalized = set(df_wiki_normalized['home_team'].unique()) | set(df_wiki_normalized['away_team'].unique())\n",
    "    print(f\"   Unique teams (after normalization): {len(teams_normalized)}\")\n",
    "    \n",
    "    stats_summary.append({\n",
    "        'Source': 'Wikipedia',\n",
    "        'Total Matches': len(df_wiki),\n",
    "        'Seasons': df_wiki['season'].nunique(),\n",
    "        'Teams (normalized)': len(teams_normalized)\n",
    "    })\n",
    "\n",
    "if tm_combined.exists():\n",
    "    df_tm = pd.read_csv(tm_combined)\n",
    "    print(f\"\\n‚úÖ Transfermarkt Data:\")\n",
    "    print(f\"   Total matches: {len(df_tm)}\")\n",
    "    print(f\"   Seasons: {df_tm['season'].nunique()}\")\n",
    "    print(f\"   Season range: {df_tm['season'].min()} to {df_tm['season'].max()}\")\n",
    "    print(f\"   Rounds: min={df_tm['round'].min()}, max={df_tm['round'].max()}\")\n",
    "    \n",
    "    # Count unique teams\n",
    "    teams_tm = set(df_tm['home'].unique()) | set(df_tm['away'].unique())\n",
    "    print(f\"   Unique teams: {len(teams_tm)}\")\n",
    "    \n",
    "    stats_summary.append({\n",
    "        'Source': 'Transfermarkt',\n",
    "        'Total Matches': len(df_tm),\n",
    "        'Seasons': df_tm['season'].nunique(),\n",
    "        'Teams (normalized)': len(teams_tm)\n",
    "    })\n",
    "\n",
    "if stats_summary:\n",
    "    print(f\"\\nüìã Summary Table:\")\n",
    "    summary_df = pd.DataFrame(stats_summary)\n",
    "    display(summary_df)\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"‚úÖ DATA COLLECTION COMPLETE\")\n",
    "print(f\"=\"*80)\n",
    "print(f\"\\nüí° Next Steps:\")\n",
    "print(f\"   1. Use team normalization functions for consistent analysis\")\n",
    "print(f\"   2. Merge with attendance data (already collected)\")\n",
    "print(f\"   3. Calculate league standings and rankings\")\n",
    "print(f\"   4. Perform statistical analysis\")\n",
    "print(f\"   5. Create visualizations\")\n",
    "print(f\"\\nüìÇ All data saved to: {DATA_DIR}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea81dc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\interim\\matches_2006_07_ligat_haal_regular_corrected.csv\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\interim\\matches_2007_08_ligat_haal_regular_corrected.csv\n",
      "Saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\interim\\matches_2008_09_ligat_haal_regular_corrected.csv\n",
      "\n",
      "Early Seasons Conversion Summary:\n",
      "    season  matches status\n",
      "0  2006/07      198     ok\n",
      "1  2007/08      198     ok\n",
      "2  2008/09      198     ok\n",
      "Combined saved: c:\\Users\\nitib\\dev-lab\\ligat_haal_project\\ligat_haal_project\\notebooks\\data\\interim\\matches_2006_07_2008_09_regular_tm_corrected_combined.csv\n"
     ]
    }
   ],
   "source": [
    "## 9. Early Seasons TM ‚Üí Wikipedia Format\n",
    "\n",
    "# Convert Transfermarkt CSVs (2006/07‚Äì2008/09) to Wikipedia-like columns\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "SEASONS_TM_EARLY = [2006, 2007, 2008]\n",
    "EXPECTED_MATCHES = 198\n",
    "\n",
    "_score_re = re.compile(r\"(\\d+)\\s*[:‚Äì-]\\s*(\\d+)\")\n",
    "\n",
    "def _tm_path(season_year:int) -> Path:\n",
    "    return DATA_DIR / f\"matches_{season_year}_{str(season_year+1)[-2:]}_ligat_haal_transfermarkt.csv\"\n",
    "\n",
    "def _load_tm(season_year:int) -> pd.DataFrame:\n",
    "    p = _tm_path(season_year)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(str(p))\n",
    "    return pd.read_csv(p)\n",
    "\n",
    "def _tm_to_wiki_like(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    home_col = next((c for c in ['home_team','home','HomeTeam','homeTeam'] if c in df.columns), None)\n",
    "    away_col = next((c for c in ['away_team','away','AwayTeam','awayTeam'] if c in df.columns), None)\n",
    "    score_col = next((c for c in ['score','result','Score','Result'] if c in df.columns), None)\n",
    "    if not home_col or not away_col or not score_col:\n",
    "        raise KeyError('TM CSV missing expected columns')\n",
    "    out = pd.DataFrame({\n",
    "        'home_team': df[home_col].map(lambda x: TEAM_NAME_MAP.get(x, x)),\n",
    "        'away_team': df[away_col].map(lambda x: TEAM_NAME_MAP.get(x, x))\n",
    "    })\n",
    "    def _split(s):\n",
    "        m = _score_re.search(str(s))\n",
    "        if not m:\n",
    "            return pd.NA, pd.NA\n",
    "        return int(m.group(1)), int(m.group(2))\n",
    "    goals = df[score_col].apply(_split)\n",
    "    out['home_goals'] = goals.apply(lambda t: t[0])\n",
    "    out['away_goals'] = goals.apply(lambda t: t[1])\n",
    "    out['goal_diff'] = out['home_goals'] - out['away_goals']\n",
    "    out['result'] = out['goal_diff'].apply(lambda x: 'H' if x>0 else ('A' if x<0 else 'D'))\n",
    "    out['home_points'] = out['result'].map({'H':3,'D':1,'A':0}).astype('Int64')\n",
    "    out['away_points'] = out['result'].map({'A':3,'D':1,'H':0}).astype('Int64')\n",
    "    return out\n",
    "\n",
    "summary_rows = []\n",
    "outputs = []\n",
    "for sy in SEASONS_TM_EARLY:\n",
    "    season_tag = f\"{sy}/{str(sy+1)[-2:]}\"\n",
    "    try:\n",
    "        tm_df = _load_tm(sy)\n",
    "        wiki_like = _tm_to_wiki_like(tm_df)\n",
    "        wiki_like['season'] = season_tag\n",
    "        wiki_like['season_year'] = sy\n",
    "        cols = ['season','season_year','home_team','away_team','home_goals','away_goals','goal_diff','result','home_points','away_points']\n",
    "        wiki_like = wiki_like[cols]\n",
    "        out_path = INTERIM_DIR / f\"matches_{sy}_{str(sy+1)[-2:]}_ligat_haal_regular_corrected.csv\"\n",
    "        wiki_like.to_csv(out_path, index=False)\n",
    "        status = 'ok' if len(wiki_like)==EXPECTED_MATCHES else f\"count={len(wiki_like)}\"\n",
    "        summary_rows.append({'season':season_tag,'matches':len(wiki_like),'status':status})\n",
    "        outputs.append(wiki_like)\n",
    "        print(f\"Saved: {out_path}\")\n",
    "    except Exception as e:\n",
    "        summary_rows.append({'season':season_tag,'matches':None,'status':str(e)})\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "print('\\nEarly Seasons Conversion Summary:')\n",
    "print(summary_df)\n",
    "\n",
    "if outputs:\n",
    "    combined = pd.concat(outputs, ignore_index=True)\n",
    "    combined_out = INTERIM_DIR / 'matches_2006_07_2008_09_regular_tm_corrected_combined.csv'\n",
    "    combined.to_csv(combined_out, index=False)\n",
    "    print(f\"Combined saved: {combined_out}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
